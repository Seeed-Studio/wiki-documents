<!doctype html>
<html lang="en-US" dir="ltr" class="docs-wrapper docs-doc-page docs-version-current plugin-docs plugin-id-default docs-doc-id-Sensor/SenseCAP/SenseCAP_LoRaWAN_Sensor/SenseCAP_A1101/Train-Deploy-AI-Model-A1101" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.4.3">
<title data-rh="true">Train and Deploy Your Own AI Model Into SenseCAP A1101 | Seeed Studio Wiki</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://wiki.seeedstudio.com/Train-Deploy-AI-Model-A1101/"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Train and Deploy Your Own AI Model Into SenseCAP A1101 | Seeed Studio Wiki"><meta data-rh="true" name="description" content="Train and Deploy Your Own AI Model Into SenseCAP A1101"><meta data-rh="true" property="og:description" content="Train and Deploy Your Own AI Model Into SenseCAP A1101"><meta data-rh="true" name="keywords" content="SenseCAP"><meta data-rh="true" property="og:image" content="https://files.seeedstudio.com/wiki/wiki-platform/S-tempor.png"><meta data-rh="true" name="twitter:image" content="https://files.seeedstudio.com/wiki/wiki-platform/S-tempor.png"><link data-rh="true" rel="icon" href="/img/S.png"><link data-rh="true" rel="canonical" href="https://wiki.seeedstudio.com/Train-Deploy-AI-Model-A1101/"><link data-rh="true" rel="alternate" href="https://wiki.seeedstudio.com/Train-Deploy-AI-Model-A1101/" hreflang="en-US"><link data-rh="true" rel="alternate" href="https://wiki.seeedstudio.com/Train-Deploy-AI-Model-A1101/" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Seeed Studio Wiki RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Seeed Studio Wiki Atom Feed">

<link rel="preconnect" href="https://www.googletagmanager.com">
<script>window.dataLayer=window.dataLayer||[]</script>
<script>!function(e,t,a,n){e[n]=e[n]||[],e[n].push({"gtm.start":(new Date).getTime(),event:"gtm.js"});var g=t.getElementsByTagName(a)[0],m=t.createElement(a);m.async=!0,m.src="https://www.googletagmanager.com/gtm.js?id=GTM-M4JG2HVB",g.parentNode.insertBefore(m,g)}(window,document,"script","dataLayer")</script>


<link rel="icon" href="/img/S.png">
<link rel="manifest" href="/manifest.json">
<meta name="theme-color" content="rgb(37, 194, 160)">


<link rel="search" type="application/opensearchdescription+xml" title="Seeed Studio Wiki" href="/opensearch.xml">
<script src="https://viewer.altium.com/client/static/js/embed.js" async></script>
<script src="/js/custom.js" async></script><link rel="stylesheet" href="/assets/css/styles.d4a68a25.css">
<link rel="preload" href="/assets/js/runtime~main.7b0f7417.js" as="script">
<link rel="preload" href="/assets/js/main.4c47889c.js" as="script">
</head>
<body class="navigation-with-keyboard">
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-M4JG2HVB" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>

<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}return t}()||function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"dark")}(),document.documentElement.setAttribute("data-announcement-bar-initially-dismissed",function(){try{return"true"===localStorage.getItem("docusaurus.announcement.dismiss")}catch(t){}return!1}())</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><div class="announcementBar_mb4j" style="background-color:#013949;color:#FFFFFF" role="banner"><div class="content_knG7 announcementBarContent_xLdY">Collaborating with us! Join the Seeed Studio <a target="_blank" href="https://wiki.seeedstudio.com/ranger/">Ranger Program</a> or <a target="_blank" href="https://wiki.seeedstudio.com/contributors/">Contributor Program</a>!</div></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/Getting_Started/"><div class="navbar__logo"><img src="https://files.seeedstudio.com/wiki/wiki-platform/SeeedStudio.png" alt="Seeed Studio" class="themedImage_ToTc themedImage--light_HNdA navbar_logo_items"><img src="https://files.seeedstudio.com/wiki/wiki-platform/seeed_white_logo.png" alt="Seeed Studio" class="themedImage_ToTc themedImage--dark_i4oU navbar_logo_items"></div></a><div class="navbar__item dropdown dropdown--hoverable"><a class="navbar__link navbar_dorp_items" aria-haspopup="true" aria-expanded="false" role="button" href="/Getting_Started/">Getting Started</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/Sensor_Network/">Sensor and Sensing</a></li><li><a class="dropdown__link" href="/Network/">Networking</a></li><li><a class="dropdown__link" href="/Edge_Computing/">Edge Computing</a></li><li><a class="dropdown__link" href="/Cloud/">Cloud</a></li></ul></div><div class="navbar__item dropdown dropdown--hoverable"><a class="navbar__link navbar_dorp_items" aria-haspopup="true" aria-expanded="false" role="button" href="/topicintroduction/">Technology</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/tinyml_topic/">TinyML</a></li><li><a class="dropdown__link" href="/ModelAssistant_Introduce_Overview/">SenseCraft Model Assistant</a></li><li><a class="dropdown__link" href="/home_assistant_topic/">Home Assistant</a></li><li><a class="dropdown__link" href="/open_source_topic/">Open Source</a></li><li><a class="dropdown__link" href="/edge_ai_topic/">Edge AI</a></li><li><a class="dropdown__link" href="/cn/Getting_Started/">ÁüΩÈÄíÁßëÊäÄ Wiki ÊñáÊ°£Âπ≥Âè∞ÔºàÊµãËØïÔºâ</a></li></ul></div><div class="navbar__item dropdown dropdown--hoverable"><a class="navbar__link navbar_dorp_items" aria-haspopup="true" aria-expanded="false" role="button" href="/knowledgebase/">FAQs</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/Jetson_FAQ/">NVIDIA Jetson Series</a></li><li><a class="dropdown__link" href="/XIAO_FAQ/">Seeed Studio XIAO Series</a></li><li><a class="dropdown__link" href="/reComputer_R1000_FAQ/">reComputer R1000 Series</a></li><li><a class="dropdown__link" href="/reTerminal-new_FAQ/">reTerminal</a></li><li><a class="dropdown__link" href="/FAQs_For_openWrt/">reRouter</a></li><li><a class="dropdown__link" href="/ODYSSEY_FAQ/">Odyssey</a></li><li><a class="dropdown__link" href="/wio_terminal_faq/">Wio Terminal</a></li><li><hr style="margin: 8px 0;"></li><li><a href="https://discord.com/invite/eWkprNDMU7" target="_blank" rel="noopener noreferrer" class="dropdown__link">Discord<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li><a href="https://www.seeedstudio.com/contacts" target="_blank" rel="noopener noreferrer" class="dropdown__link">Email<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li><a href="https://forum.seeedstudio.com/" target="_blank" rel="noopener noreferrer" class="dropdown__link">Forum<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li><a href="https://github.com/Seeed-Studio/wiki-documents/discussions/69" target="_blank" rel="noopener noreferrer" class="dropdown__link">Have Suggestions?<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="navbar__item dropdown dropdown--hoverable"><a class="navbar__link navbar_dorp_items" aria-haspopup="true" aria-expanded="false" role="button" href="/ranger/">Rangers</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/ranger/">Rangers</a></li><li><a class="dropdown__link" href="/contributors/">Contributors</a></li><li><a href="https://docs.google.com/forms/d/e/1FAIpQLSdiAWHmRJqgVNTJyJDkzhufc1dygFyhWFyEtUTm-mrgSKaEgg/viewform" target="_blank" rel="noopener noreferrer" class="dropdown__link">Apply for Rangers<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li><a href="https://github.com/orgs/Seeed-Studio/projects/6" target="_blank" rel="noopener noreferrer" class="dropdown__link">Direct to Assignments<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li><a href="https://www.seeedstudio.com/blog/2023/09/15/join-the-seeed-ranger-program-empowering-developers-and-building-communities/" target="_blank" rel="noopener noreferrer" class="dropdown__link">More about Rangers<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li><a href="https://wiki.seeedstudio.com/Contributor" target="_blank" rel="noopener noreferrer" class="dropdown__link">More about Contributors<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="navbar__items navbar__items--right"><a href="https://www.seeedstudio.com/" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link navbar_doc_right_items">Bazaar üõçÔ∏è</a><a href="https://wiki-gpt.seeedstudio.com/chat" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link navbar_doc_right_items">AI Bot ü§ñÔ∏è</a><a href="https://sensecraft.seeed.cc/ai/#/home" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link navbar_doc_right_items">SenseCraft AI</a><a href="https://sensecraft.seeed.cc/ai/#/home" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-SSCMA"></a><a href="https://github.com/Seeed-Studio/wiki-documents" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-github-link" aria-label="GitHub repository"></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently dark mode)" aria-label="Switch between dark and light mode (currently dark mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0 docsWrapper_BCFX"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docPage__5DB"><aside class="theme-doc-sidebar-container docSidebarContainer_b6E3"><div class="sidebarViewport_Xe31"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG menuWithAnnouncementBar_GW3s"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item sideboard_calss"><a class="menu__link" href="/Getting_Started/">Getting Started</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item sideboard_calss"><a class="menu__link" href="/weekly_wiki/">Weekly Wiki</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item sideboard_calss"><a class="menu__link" href="/Sensor_Network/">Sensing</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/Grove_System/">Grove</a><button aria-label="Toggle the collapsible sidebar category &#x27;Grove&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" aria-expanded="true" href="/SenseCAP_introduction/">SenseCAP</a><button aria-label="Toggle the collapsible sidebar category &#x27;SenseCAP&#x27;" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/sensecap_t1000_tracker/">SenseCAP T1000 Tracker</a><button aria-label="Toggle the collapsible sidebar category &#x27;SenseCAP T1000 Tracker&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" aria-expanded="true" tabindex="0" href="/SenseCAP_Sensor_Intro/">SenseCAP Sensor</a><button aria-label="Toggle the collapsible sidebar category &#x27;SenseCAP Sensor&#x27;" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" tabindex="0" href="/Sensor/SenseCAP/SenseCAP_LoRaWAN_Sensor/SenseCAP_S210X_Series/SenseCAP_LoRaWAN_S210X_Series_Sensor/">SenseCAP LoRaWAN Sensor</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-4 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/Sensor/SenseCAP/SenseCAP_LoRaWAN_Sensor/SenseCAP_S210X_Series/SenseCAP_LoRaWAN_S210X_Series_Sensor/">SenseCAP S210X Series</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-4 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/Sensor/SenseCAP/SenseCAP_LoRaWAN_Sensor/SenseCAP_S2120_8-in-1_LoRaWAN_Weather_Sensor/SenseCAP_S2120_8-in-1_LoRaWAN_Weather_Sensor_Introduction/">SenseCAP S2120 8-in-1 LoRaWAN Weather Sensor</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-4 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" tabindex="0" href="/SenseCAP-Vision-AI-Get-Started/">SenseCAP A1101</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/SenseCAP-Vision-AI-Get-Started/">Getting Started with SenseCAP Vision AI</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/Train-Deploy-AI-Model-A1101/">Train and Deploy Your Own AI Model Into SenseCAP A1101</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/One-Stop-Model-Training-with-Edge-Impulse/">One Stop Model Training with Edge Impulse</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-5 menu__list-item"><a class="menu__link" tabindex="0" href="/Train-Water-Meter-Digits-Recognition-Model-with-SenseCAP-A1101/">Train Water Meter Digits Recognition Model with SenseCAP A1101</a></li></ul></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/SenseCAP_ONE_weather_sensor/"> SenseCAP ONE Weather Sensor</a><button aria-label="Toggle the collapsible sidebar category &#x27; SenseCAP ONE Weather Sensor&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/SenseCAP_probes_intro/">SenseCAP Sensor Probe</a><button aria-label="Toggle the collapsible sidebar category &#x27;SenseCAP Sensor Probe&#x27;" type="button" class="clean-btn menu__caret"></button></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/Build-LoRaWAN-Sensors-SenseCAP-XIAO-Controller-Data-Logger/"> SenseCAP Sensor Builder</a><button aria-label="Toggle the collapsible sidebar category &#x27; SenseCAP Sensor Builder&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/SenseCAP_Data_Logger_Intro/"> SenseCAP Data Logger</a><button aria-label="Toggle the collapsible sidebar category &#x27; SenseCAP Data Logger&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/SenseCAP_Decoder/">SenseCAP Decoder</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/home_assistant_with_sensecap_lorawan_sensors/">Applications</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/select_lorawan_network/">Learn</a></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/Sensor/SenseCAP/SenseCAP_Indicator/Get_started_with_SenseCAP_Indicator/">SenseCAP Indicator</a><button aria-label="Toggle the collapsible sidebar category &#x27;SenseCAP Indicator&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/watcher/">SenseCAP Watcher</a><button aria-label="Toggle the collapsible sidebar category &#x27;SenseCAP Watcher&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/mmwave_radar_Intro/">mmWave Radar Sensor</a><button aria-label="Toggle the collapsible sidebar category &#x27;mmWave Radar Sensor&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/SeeedStudio_XIAO_Series_Introduction/">XIAO</a><button aria-label="Toggle the collapsible sidebar category &#x27;XIAO&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/Wio_Terminal_Intro/">Wio Terminal</a><button aria-label="Toggle the collapsible sidebar category &#x27;Wio Terminal&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/reSpeaker_usb_v3/">ReSpeaker Lite</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/Ultra_Sonic_range_measurement_module/">Other Sensing Modules</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/Wio/">Other Microcontrollers</a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item sideboard_calss"><a class="menu__link" href="/Network/">Network</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/meshtastic_introduction/">Meshtastic Network</a><button aria-label="Toggle the collapsible sidebar category &#x27;Meshtastic Network&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/Network/SenseCAP_Network/SenseCAP_Gateway_Intro/">SenseCAP Gateway</a><button aria-label="Toggle the collapsible sidebar category &#x27;SenseCAP Gateway&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/SenseCAP_K1100_Intro/">SenseCAP K1100</a><button aria-label="Toggle the collapsible sidebar category &#x27;SenseCAP K1100&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/M2_Kit_Getting_Started/">SenseCAP LoRaWAN Starter Kit</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/reRouter_Intro/">Raspberry Pi Solutions</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/Rockchip_network_solutions/">Rockchip Solutions</a><button aria-label="Toggle the collapsible sidebar category &#x27;Rockchip Solutions&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/The-Things-Indoor-Gateway/">Other Network Devices</a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item sideboard_calss"><a class="menu__link" href="/Edge_Computing/">Edge Computing</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/raspberry-pi-devices/">Raspberry Pi Devices</a><button aria-label="Toggle the collapsible sidebar category &#x27;Raspberry Pi Devices&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/NVIDIA_Jetson/">NVIDIA Jetson¬Æ</a><button aria-label="Toggle the collapsible sidebar category &#x27;NVIDIA Jetson¬Æ&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/Edgebox-ESP-100-Arduino/">ESP Devices</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/BeagleBone/">BeagleBone¬Æ</a><button aria-label="Toggle the collapsible sidebar category &#x27;BeagleBone¬Æ&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/ODYSSEY_Intro/">ODYSSEY</a><button aria-label="Toggle the collapsible sidebar category &#x27;ODYSSEY&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/reServer-Getting-Started/">Other Edge Devices</a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item sideboard_calss"><a class="menu__link" href="/Cloud/">Cloud</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/Cloud_Chain/SenseCAP_Dashboard/Dashboard_Basics/">SenseCAP Dashboard</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/Cloud_Chain/SenseCAP_Portal/QuickStart/">SenseCAP Portal</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/SenseCAP_Hotspot_APP/">SenseCAP Hotspot APP</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/sensecraft_app/">SenseCraft APP</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/How_to_Use_SenseCAP_AI_on_SenseCAP_Portal_and_SenseCAP_Mate_APP/">SenseCAP AI</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/Cloud_Chain/SenseCAP_API/SenseCAP_API_Introduction/">SenseCAP API</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/sensecraft_ai/">SenseCraft AI</a><button aria-label="Toggle the collapsible sidebar category &#x27;SenseCraft AI&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item sideboard_calss"><a class="menu__link" href="/topicintroduction/">Technology Topics</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/home_assistant_topic/">Home Assistant</a><button aria-label="Toggle the collapsible sidebar category &#x27;Home Assistant&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/tinyml_topic/">TinyML</a><button aria-label="Toggle the collapsible sidebar category &#x27;TinyML&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/open_source_topic/">Open Source</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/edge_ai_topic/">Edge AI</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item sideboard_calss"><a class="menu__link" href="/Contributor/">Contributions</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/Contribution-Guide/">Github Contributions Guide</a><button aria-label="Toggle the collapsible sidebar category &#x27;Github Contributions Guide&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/Scale-up-Your-Creation-with-Fusion/">Scale up Your Creation with Seeed Studio Fusion</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item sideboard_calss"><a class="menu__link" href="/popularplatforms/">Popular Platforms</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/Arduino/">Arduino</a><button aria-label="Toggle the collapsible sidebar category &#x27;Arduino&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/Raspberry_Pi/">Raspberry Pi</a><button aria-label="Toggle the collapsible sidebar category &#x27;Raspberry Pi&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/microbit_wiki_page/">Micro:bit</a><button aria-label="Toggle the collapsible sidebar category &#x27;Micro:bit&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item sideboard_calss"><a class="menu__link" href="/discontinuedproducts/">Discontinued Products</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/ReSpeaker/">Product List</a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/About/">About</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/License/">License</a></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_gTbr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_z5aJ"><div class="docItemContainer_c0TR"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/SenseCAP_introduction/"><span itemprop="name">SenseCAP</span></a><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/SenseCAP_Sensor_Intro/"><span itemprop="name">SenseCAP Sensor</span></a><meta itemprop="position" content="2"></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">SenseCAP LoRaWAN Sensor</span><meta itemprop="position" content="3"></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">SenseCAP A1101</span><meta itemprop="position" content="4"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Train and Deploy Your Own AI Model Into SenseCAP A1101</span><meta itemprop="position" content="5"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>Train and Deploy Your Own AI Model Into SenseCAP A1101</h1><h2 class="anchor anchorWithStickyNavbar_LWe7" id="overview">Overview<a href="#overview" class="hash-link" aria-label="Direct link to Overview" title="Direct link to Overview">‚Äã</a></h2><p>In this wiki, we will teach you how to train your own AI model for your specific application and then deploy it easily to the SenseCAP A1101 - LoRaWAN Vision AI Sensor. Let&#x27;s get started!</p><div class="theme-admonition theme-admonition-caution alert alert--warning admonition_LlT9"><div class="admonitionHeading_tbUL"><span class="admonitionIcon_kALy"><svg viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span><mdxadmonitiontitle><strong>Note:</strong></mdxadmonitiontitle></div><div class="admonitionContent_S0QG"><p>Our current device firmware is compatible with <a href="https://wiki.seeedstudio.com/One-Stop-Model-Training-with-Edge-Impulse/" target="_blank" rel="noopener noreferrer">EI</a>. If you purchased the device after <strong>March 30, 2023</strong>, you need to flash the device back to the <a href="https://wiki.seeedstudio.com/Train-Deploy-AI-Model-A1101/#change-device-firmware-after-image-collection" target="_blank" rel="noopener noreferrer">default firmware</a> to follow this wiki.</p></div></div><h2 class="anchor anchorWithStickyNavbar_LWe7" id="hardware-introduction">Hardware introduction<a href="#hardware-introduction" class="hash-link" aria-label="Direct link to Hardware introduction" title="Direct link to Hardware introduction">‚Äã</a></h2><p>We will mainly use SenseCAP A1101 - LoRaWAN Vision AI Sensor throughout this wiki. So first, let&#x27;s become familiar with this hardware.</p><p><a href="https://www.seeedstudio.com/SenseCAP-A1101-LoRaWAN-Vision-AI-Sensor-p-5367.html" target="_blank" rel="noopener noreferrer">SenseCAP A1101 - LoRaWAN Vision AI Sensor</a> combines TinyML AI technology and LoRaWAN long-range transmission to enable a low-power, high-performance AI device solution for outdoor use. This sensor features Himax&#x27;s high-performance, low-power AI vision solution which supports the Google TensorFlow Lite framework and multiple TinyML AI platforms. Different models can implement different AI functions, for example, pest detection, people counting, object recognition. Users can adopt models provided by Seeed, generate their own models through AI training tools, or procure deployable, commercial models from Seeed&#x27;s partner model providers.</p><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/SenseCAP-A1101/60.jpg" class="img_ev3q"></div><h2 class="anchor anchorWithStickyNavbar_LWe7" id="software-introduction">Software introduction<a href="#software-introduction" class="hash-link" aria-label="Direct link to Software introduction" title="Direct link to Software introduction">‚Äã</a></h2><p>We will be using the following software technologies in this wiki</p><ul><li>Roboflow - for annotating</li><li>YOLOv5 - for training</li><li>TensorFlow Lite - for inferencing</li></ul><div align="center"><img loading="lazy" width="{600}" src="https://files.seeedstudio.com/wiki/SenseCAP-A1101/57.png" class="img_ev3q"></div><h3 class="anchor anchorWithStickyNavbar_LWe7" id="what-is-roboflow">What is Roboflow?<a href="#what-is-roboflow" class="hash-link" aria-label="Direct link to What is Roboflow?" title="Direct link to What is Roboflow?">‚Äã</a></h3><p><a href="https://roboflow.com" target="_blank" rel="noopener noreferrer">Roboflow</a> is an annotation tool based online. This tool allows you to easily annotate all your images, add further processing to these images and export the labeled dataset into different formats such as YOLOV5 PyTorch, Pascal VOC, and more! Roboflow also has public datasets readily available to users.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="what-is-yolov5">What is YOLOv5?<a href="#what-is-yolov5" class="hash-link" aria-label="Direct link to What is YOLOv5?" title="Direct link to What is YOLOv5?">‚Äã</a></h3><p>YOLO is an abbreviation for the term ‚ÄòYou Only Look Once‚Äô. It is an algorithm that detects and recognizes various objects in an image in real-time. Ultralytics <a href="https://ultralytics.com/yolov5" target="_blank" rel="noopener noreferrer">YOLOv5</a> is the version of YOLO based on the PyTorch framework.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="what-is-tensorflow-lite">What is TensorFlow Lite?<a href="#what-is-tensorflow-lite" class="hash-link" aria-label="Direct link to What is TensorFlow Lite?" title="Direct link to What is TensorFlow Lite?">‚Äã</a></h3><p><a href="https://www.tensorflow.org/lite" target="_blank" rel="noopener noreferrer">TensorFlow Lite</a> is an open-source, product ready, cross-platform deep learning framework that converts a pre-trained model in TensorFlow to a special format that can be optimized for speed or storage. The special format model can be deployed on edge devices like mobiles using Android or iOS or Linux based embedded devices like Raspberry Pi or Microcontrollers to make the inference at the Edge.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="wiki-structure">Wiki structure<a href="#wiki-structure" class="hash-link" aria-label="Direct link to Wiki structure" title="Direct link to Wiki structure">‚Äã</a></h2><p>This wiki will be divided into three main sections</p><ol><li><a href="https://wiki.seeedstudio.com/Train-Deploy-AI-Model-A1101#1-train-your-own-ai-model-with-a-public-dataset" target="_blank" rel="noopener noreferrer">Train your own AI model with a public dataset</a></li><li><a href="https://wiki.seeedstudio.com/Train-Deploy-AI-Model-A1101#2-train-your-own-ai-model-with-your-own-dataset" target="_blank" rel="noopener noreferrer">Train your own AI model with your own dataset</a></li><li><a href="https://wiki.seeedstudio.com/Train-Deploy-AI-Model-A1101#3-deploy-the-trained-model-and-perform-inference" target="_blank" rel="noopener noreferrer">Deploy the trained AI model into SenseCAP A1101</a></li></ol><p>The first section will be the fastest way to build your own AI model with the least number of steps. The second section will take some time and effort to build your own AI model, but it will be definitely worth the knowledge. The third section about deploying the AI model can be done either after first or second section.</p><p>So there are two ways to follow this wiki:</p><ol><li><p>Follow <a href="https://wiki.seeedstudio.com/Train-Deploy-AI-Model-A1101#1-train-your-own-ai-model-with-a-public-dataset" target="_blank" rel="noopener noreferrer">section 1</a> and then <a href="https://wiki.seeedstudio.com/Train-Deploy-AI-Model-A1101#3-deploy-the-trained-model-and-perform-inference" target="_blank" rel="noopener noreferrer">section 3</a> - fast to follow</p></li><li><p>Follow <a href="https://wiki.seeedstudio.com/Train-Deploy-AI-Model-A1101#2-train-your-own-ai-model-with-your-own-dataset" target="_blank" rel="noopener noreferrer">section 2</a> and then <a href="https://wiki.seeedstudio.com/Train-Deploy-AI-Model-A1101#3-deploy-the-trained-model-and-perform-inference" target="_blank" rel="noopener noreferrer">section 3</a> - slow to follow</p></li></ol><p>However, we encourage to follow the first way at first and then move onto the second way.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="1-train-your-own-ai-model-with-a-public-dataset">1. Train your own AI model with a public dataset<a href="#1-train-your-own-ai-model-with-a-public-dataset" class="hash-link" aria-label="Direct link to 1. Train your own AI model with a public dataset" title="Direct link to 1. Train your own AI model with a public dataset">‚Äã</a></h2><p>The very first step of an object detection project is to obtain data for training. You can either download datasets available publicly or create your own dataset!</p><p>But what is the fastest and easiest way to get started with object detection? Well...Using public datasets can save you a lot of time that you would otherwise spend on collecting data by yourself and annotating them. These public datasets are already annotated out-of-the-box, giving you more time to focus on your AI vision applications.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="hardware-preparation">Hardware preparation<a href="#hardware-preparation" class="hash-link" aria-label="Direct link to Hardware preparation" title="Direct link to Hardware preparation">‚Äã</a></h3><ul><li>SenseCAP A1101 - LoRaWAN Vision AI Sensor</li><li>USB Type-C cable</li><li>Windows/ Linux/ Mac with internet access</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="software-preparation">Software preparation<a href="#software-preparation" class="hash-link" aria-label="Direct link to Software preparation" title="Direct link to Software preparation">‚Äã</a></h3><ul><li>No need to prepare additional software</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="use-publicly-available-annotated-dataset">Use publicly available annotated dataset<a href="#use-publicly-available-annotated-dataset" class="hash-link" aria-label="Direct link to Use publicly available annotated dataset" title="Direct link to Use publicly available annotated dataset">‚Äã</a></h3><p>You can download a number of publically available datasets such as the  <a href="https://cocodataset.org" target="_blank" rel="noopener noreferrer">COCO dataset</a>, <a href="http://host.robots.ox.ac.uk/pascal/VOC" target="_blank" rel="noopener noreferrer">Pascal VOC dataset</a> and much more. <a href="https://universe.roboflow.com" target="_blank" rel="noopener noreferrer">Roboflow Universe</a> is a recommended platform which provides a wide-range of datasets and it has <a href="https://blog.roboflow.com/computer-vision-datasets-and-apis" target="_blank" rel="noopener noreferrer">90,000+ datasets with 66+ million images</a> available for building computer vision models. Also, you can simply search <strong>open-source datasets</strong> on Google and choose from a variety of datasets available.</p><ul><li><p><strong>Step 1.</strong> Visit <a href="https://universe.roboflow.com/lakshantha-dissanayake/apple-detection-5z37o/dataset/1" target="_blank" rel="noopener noreferrer">this URL</a> to access an Apple Detection dataset available publicly on Roboflow Universe</p></li><li><p><strong>Step 2.</strong> Click <strong>Create Account</strong> to create a Roboflow account</p></li></ul><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/SenseCAP-A1101/53.png" class="img_ev3q"></div><ul><li><strong>Step 3.</strong> Click <strong>Download</strong>, select <strong>YOLO v5 PyTorch</strong> as the <strong>Format</strong>, click <strong>show download code</strong> and click <strong>Continue</strong></li></ul><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/SenseCAP-A1101/51.png" class="img_ev3q"></div><p>This will generate a code snippet that we will use later inside Google Colab training. So please keep this window open in the background.</p><div align="center"><img loading="lazy" width="{700}" src="https://files.seeedstudio.com/wiki/SenseCAP-A1101/52.png" class="img_ev3q"></div><h3 class="anchor anchorWithStickyNavbar_LWe7" id="train-using-yolov5-on-google-colab">Train using YOLOv5 on Google Colab<a href="#train-using-yolov5-on-google-colab" class="hash-link" aria-label="Direct link to Train using YOLOv5 on Google Colab" title="Direct link to Train using YOLOv5 on Google Colab">‚Äã</a></h3><p>After we have chosen a public dataset, we need to train the dataset. Here we use a Google Colaboratory environment to perform training on the cloud. Furthermore, we use Roboflow api within Colab to easily download our dataset.</p><p>Click <a href="https://colab.research.google.com/github/Seeed-Studio/yolov5-swift/blob/master/tutorial.ipynb" target="_blank" rel="noopener noreferrer">here</a> to open an already prepared Google Colab workspace, go through the steps mentioned in the workspace and run the code cells one by one.</p><p><strong>Note:</strong> On Google Colab, in the code cell under <strong>Step 4</strong>, you can directly copy the code snippet from Roboflow as mentioned above</p><p>It will walkthrough the following:</p><ul><li>Setup an environment for training</li><li>Download a dataset</li><li>Perform the training</li><li>Download the trained model</li></ul><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/SenseCAP-A1101/18.png" class="img_ev3q"></div><p>For an apple detection dataset with 699 images, it took around 7 minutes to finish the training process on Google Colab running on NVIDIA Tesla T4 GPU with 16GB GPU memory.</p><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/SenseCAP-A1101/43.png" class="img_ev3q"></div><p>If you followed the above Colab project, you know that you can load 4 models to the device all at once. However, please note that only one model can be loaded at a time. This can be specified by the user and will be explained later in this wiki.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="deploy-and-inference">Deploy and inference<a href="#deploy-and-inference" class="hash-link" aria-label="Direct link to Deploy and inference" title="Direct link to Deploy and inference">‚Äã</a></h3><p>If you directly want to jump to <strong>section 3</strong> which explains how to deploy the trained AI model into SenseCAP A1101 and perform inference, <a href="https://wiki.seeedstudio.com/Train-Deploy-AI-Model-A1101/#3-deploy-the-trained-model-and-perform-inference" target="_blank" rel="noopener noreferrer">click here</a>.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="2-train-your-own-ai-model-with-your-own-dataset">2. Train your own AI model with your own dataset<a href="#2-train-your-own-ai-model-with-your-own-dataset" class="hash-link" aria-label="Direct link to 2. Train your own AI model with your own dataset" title="Direct link to 2. Train your own AI model with your own dataset">‚Äã</a></h2><p>If you want to build specific object detection projects where the public datasets do not have the objects that you want to detect, you might want to build your own dataset.  When you record data for your own dataset, you have to make sure that you cover all angles (360 degrees) of the object, place the object in different environments, different lighting and different weather conditions. After recording your own dataset, you also have to annotate the images in the datset. All these steps will be convered in this section.</p><p>Eventhough there are different methods of collecting data such as using a mobile phone camera, the best way to collect data is to use the in-built camera on the SenseCAP A1101. This is because the colors, image quality and other details will be similar when we perform inference on SenseCAP A1101 which makes the overall detection more accurate.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="hardware-preparation-1">Hardware preparation<a href="#hardware-preparation-1" class="hash-link" aria-label="Direct link to Hardware preparation" title="Direct link to Hardware preparation">‚Äã</a></h3><ul><li>SenseCAP A1101 - LoRaWAN Vision AI Sensor</li><li>USB Type-C cable</li><li>Windows/ Linux/ Mac with internet access</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="software-preparation-1">Software preparation<a href="#software-preparation-1" class="hash-link" aria-label="Direct link to Software preparation" title="Direct link to Software preparation">‚Äã</a></h3><p>Now let&#x27;s setup the software. The software setup for Windows, Linux and Intel Mac will be same whereas for M1/M2 Mac will be different.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="windows-linux-intel-mac">Windows, Linux, Intel Mac<a href="#windows-linux-intel-mac" class="hash-link" aria-label="Direct link to Windows, Linux, Intel Mac" title="Direct link to Windows, Linux, Intel Mac">‚Äã</a></h4><ul><li><p><strong>Step 1.</strong> Make sure Python is already installed on the computer. If not, visit <a href="https://www.python.org/downloads/" target="_blank" rel="noopener noreferrer">this page</a> to download and install latest version of Python</p></li><li><p><strong>Step 2.</strong> Install the following dependency</p></li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">pip3 install libusb1</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><h4 class="anchor anchorWithStickyNavbar_LWe7" id="m1-m2-mac">M1/ M2 Mac<a href="#m1-m2-mac" class="hash-link" aria-label="Direct link to M1/ M2 Mac" title="Direct link to M1/ M2 Mac">‚Äã</a></h4><ul><li><strong>Step 1.</strong> Install Homebrew</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">/bin/bash -c &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)&quot;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>Step 2.</strong> Install conda</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">brew install conda</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>Step 3.</strong> Download libusb</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">wget https://conda.anaconda.org/conda-forge/osx-arm64/libusb-1.0.26-h1c322ee_100.tar.bz2</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>Step 4.</strong> Install libusb</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">conda install libusb-1.0.26-h1c322ee_100.tar.bz2</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><div class="theme-admonition theme-admonition-caution alert alert--warning admonition_LlT9"><div class="admonitionHeading_tbUL"><span class="admonitionIcon_kALy"><svg viewBox="0 0 16 16"><path fill-rule="evenodd" d="M8.893 1.5c-.183-.31-.52-.5-.887-.5s-.703.19-.886.5L.138 13.499a.98.98 0 0 0 0 1.001c.193.31.53.501.886.501h13.964c.367 0 .704-.19.877-.5a1.03 1.03 0 0 0 .01-1.002L8.893 1.5zm.133 11.497H6.987v-2.003h2.039v2.003zm0-3.004H6.987V5.987h2.039v4.006z"></path></svg></span>warning</div><div class="admonitionContent_S0QG"><p>You need to make sure your BootLoader version is greater than 2.0.0 before you can change the firmware to do the following. If you are not sure, please check the BootLoader version by following the steps mentioned in <a href="#check-bootloader-version">this section</a>, and if the version is less than 2.0.0, please update the BootLoader by following the steps mentioned in <a href="#update-bootloader">this section</a></p></div></div><h3 class="anchor anchorWithStickyNavbar_LWe7" id="collect-dataset">Collect dataset<a href="#collect-dataset" class="hash-link" aria-label="Direct link to Collect dataset" title="Direct link to Collect dataset">‚Äã</a></h3><ul><li><strong>Step 1.</strong> Connect SenseCAP A1101 to PC by using USB Type-C cable</li></ul><div align="center"><img loading="lazy" width="{500}" src="https://files.seeedstudio.com/wiki/SenseCAP-A1101/38.png" class="img_ev3q"></div><ul><li><strong>Step 2.</strong> Double click the boot button to enter <strong>boot mode</strong></li></ul><div align="center"><img loading="lazy" width="{500}" src="https://files.seeedstudio.com/wiki/SenseCAP-A1101/39.png" class="img_ev3q"></div><p>After this you will see a new storage drive shown on your file explorer as <strong>SENSECAP</strong></p><div align="center"><img loading="lazy" width="{280}" src="https://files.seeedstudio.com/wiki/SenseCAP-A1101/edge-impulse-A1101/p8.png" class="img_ev3q"></div><ul><li><strong>Step 3.</strong> Drag and drop <a href="https://github.com/Seeed-Studio/Seeed_Arduino_GroveAI/releases/download/v1.1.0/sensecap_ai_capture_firmware_v01-00.uf2" target="_blank" rel="noopener noreferrer">this .uf2 file</a> to <strong>SENSECAP</strong> drive</li></ul><p>As soon as the uf2 finishes copying into the drive, the drive will disappear. This means the uf2 has been successfully uploaded to the module.</p><ul><li><p><strong>Step 4.</strong> Copy and paste <a href="https://github.com/Seeed-Studio/Seeed_Arduino_GroveAI/blob/master/tools/capture_images_script.py" target="_blank" rel="noopener noreferrer">this Python script</a> inside a newly-created file named <strong>capture_images_script.py</strong> on your PC</p></li><li><p><strong>Step 5.</strong> Execute the Python script to start capturing images</p></li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">python3 capture_images_script.py</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>By default, it will capture an image every 300ms. If you want to change this, you can run the script in this format</p><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">python3 capture_images_script.py --interval &lt;time_in_ms&gt;</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>For example, to capture an image every second</p><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">python3 capture_images_script.py --interval 1000</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>After the above script is executed, SenseCAP A1101 will start to capture images from the in-built cameras continuosly and save all of them inside a folder named <strong>save_img</strong></p><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/SenseCAP-A1101/41.png" class="img_ev3q"></div><p>Also, it will open a preview window while it is recording</p><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/SenseCAP-A1101/40.jpg" class="img_ev3q"></div><p>After you have enough images captured, click on the terminal window and press the following key combinations to stop the capturing process</p><ul><li>Windows: Ctrl + Break</li><li>Linux: Ctrl + Shift + \</li><li>Mac: CMD + Shift + \</li></ul><h3 class="anchor anchorWithStickyNavbar_LWe7" id="change-device-firmware-after-image-collection">Change device firmware after image collection<a href="#change-device-firmware-after-image-collection" class="hash-link" aria-label="Direct link to Change device firmware after image collection" title="Direct link to Change device firmware after image collection">‚Äã</a></h3><p>After you have finished recording images for the dataset, you need to make sure to change the firmware inside the SenseCAP A1101 back to original, so that you can again load object detection models for detection. Let&#x27;s go through the steps now.</p><ul><li><p><strong>Step 1.</strong> Enter <strong>Boot mode</strong> on SenseCAP A1101 as explained before</p></li><li><p><strong>Step 2.</strong> Drag and drop <a href="https://github.com/Seeed-Studio/Seeed_Arduino_GroveAI/releases/download/v1.1.0/sensecap_ai_v01-30.uf2" target="_blank" rel="noopener noreferrer">this .uf2 file</a> to <strong>SENSECAP</strong> drive according to your device</p></li></ul><p>As soon as the uf2 finishes copying into the drive, the drive will disappear. This means the uf2 has been successfully uploaded to the module.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="annotate-dataset-using-roboflow">Annotate dataset using Roboflow<a href="#annotate-dataset-using-roboflow" class="hash-link" aria-label="Direct link to Annotate dataset using Roboflow" title="Direct link to Annotate dataset using Roboflow">‚Äã</a></h3><p>If you use your own dataset, you will need to annotate all the images in your dataset. Annotating means simply drawing rectangular boxes around each object that we want to detect and assign them labels. We will explain how to do this using Roboflow.</p><p><a href="https://roboflow.com" target="_blank" rel="noopener noreferrer">Roboflow</a> is an annotation tool based online. Here we can directly import the video footage that we have recorded into Roboflow and it will be exported into a series of images. This tool is very convenient because it will let us help distribute the dataset into &quot;training, validation and testing&quot;. Also this tool will allow us to add further processing to these images after labelling them. Furthermore, it can easily export the labelled dataset into <strong>YOLOV5 PyTorch format</strong> which is what we exactly need!</p><p>For this wiki, we will use a dataset with images containing apples so that we can detect apples later on and do counting as well.</p><ul><li><p><strong>Step 1.</strong> Click <a href="https://app.roboflow.com/login" target="_blank" rel="noopener noreferrer">here</a> to sign up for a Roboflow account</p></li><li><p><strong>Step 2.</strong> Click <strong>Create New Project</strong> to start our project</p></li></ul><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOV5/2.jpg" class="img_ev3q"></div><ul><li><strong>Step 3.</strong> Fill in <strong>Project Name</strong>, keep the <strong>License (CC BY 4.0)</strong> and <strong>Project type (Object Detection (Bounding Box))</strong>  as default. Under <strong>What will your model predict?</strong> column, fill in an annotation group name. For example, in our case we choose <strong>apples</strong>. This name should highlight all of the classes of your dataset. Finally, click <strong>Create Public Project</strong>.</li></ul><div align="center"><img loading="lazy" width="{350}" src="https://files.seeedstudio.com/wiki/SenseCAP-A1101/6.jpg" class="img_ev3q"></div><ul><li><strong>Step 4.</strong> Drag and drop the images that you have captured using SenseCAP A1101</li></ul><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/SenseCAP-A1101/7.png" class="img_ev3q"></div><ul><li><strong>Step 5.</strong> After the images are processed, click <strong>Finish Uploading</strong>. Wait patiently until the images are uploaded.</li></ul><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/SenseCAP-A1101/4.jpg" class="img_ev3q"></div><ul><li><strong>Step 6.</strong> After the images are uploaded, click <strong>Assign Images</strong></li></ul><div align="center"><img loading="lazy" width="300" src="https://files.seeedstudio.com/wiki/SenseCAP-A1101/5.jpg" class="img_ev3q"></div><ul><li><strong>Step 7.</strong> Select an image, draw a rectangular box around an apple, choose the label as <strong>apple</strong> and press <strong>ENTER</strong></li></ul><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/SenseCAP-A1101/9.png" class="img_ev3q"></div><ul><li><strong>Step 8.</strong> Repeat the same for the remaining apples</li></ul><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/SenseCAP-A1101/10.png" class="img_ev3q"></div><p><strong>Note:</strong> Try to label all the apples that you see inside the image. If only a part of an apple is visible, try to label that too.</p><ul><li><strong>Step 9.</strong> Continue to annotate all the images in the dataset</li></ul><p>Roboflow has a feature called <strong>Label Assist</strong> where it can predict the labels beforehand so that your labelling will be much faster. However, it will not work with all object types, but rather a selected type of objects. To turn this feature on, you simply need to press the <strong>Label Assist</strong> button, <strong>select a model</strong>, <strong>select the classes</strong> and navigate through the images to see the predicted labels with bounding boxes</p><div align="center"><img loading="lazy" width="{200}" src="https://files.seeedstudio.com/wiki/YOLOV5/41.png" class="img_ev3q"></div><div align="center"><img loading="lazy" width="{400}" src="https://files.seeedstudio.com/wiki/YOLOV5/39.png" class="img_ev3q"></div><div align="center"><img loading="lazy" width="{400}" src="https://files.seeedstudio.com/wiki/YOLOV5/40.png" class="img_ev3q"></div><p>As you can see above, it can only help to predict annotations for the 80 classes mentioned. If your images do not contain the object classes from above, you cannot use the label assist feature.</p><ul><li><strong>Step 10.</strong> Once labelling is done, click <strong>Add images to Dataset</strong></li></ul><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOV5/25.jpg" class="img_ev3q"></div><ul><li><strong>Step 11.</strong> Next we will split the images between &quot;Train, Valid and Test&quot;. Keep the default percentages for the distribution and click <strong>Add Images</strong></li></ul><div align="center"><img loading="lazy" width="{330}" src="https://files.seeedstudio.com/wiki/YOLOV5/26.png" class="img_ev3q"></div><ul><li><strong>Step 12.</strong> Click <strong>Generate New Version</strong></li></ul><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOV5/27.jpg" class="img_ev3q"></div><ul><li><strong>Step 13.</strong> Now you can add <strong>Preprocessing</strong> and <strong>Augmentation</strong> if you prefer. Here we will <strong>change</strong> the <strong>Resize</strong> option to <strong>192x192</strong></li></ul><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/SenseCAP-A1101/11.png" class="img_ev3q"></div><div align="center"><img loading="lazy" width="{450}" src="https://files.seeedstudio.com/wiki/SenseCAP-A1101/13.png" class="img_ev3q"></div><p>Here we change the image size to 192x192 because we will use that size for training and the training will be faster. Otherwise, it will have to convert all images to 192x192 during the training process which consumes more CPU resources and makes the training process slower.</p><ul><li><strong>Step 14.</strong> Next, proceed with the remaining defaults and click <strong>Generate</strong></li></ul><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/SenseCAP-A1101/14.png" class="img_ev3q"></div><ul><li><strong>Step 15.</strong> Click <strong>Export</strong>, select <strong>Format</strong> as <strong>YOLO v5 PyTorch</strong>, select <strong>show download code</strong> and click <strong>Continue</strong></li></ul><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/SenseCAP-A1101/54.png" class="img_ev3q"></div><p>This will generate a code snippet that we will use later inside Google Colab training. So please keep this window open in the background.</p><div align="center"><img loading="lazy" width="{600}" src="https://files.seeedstudio.com/wiki/SenseCAP-A1101/55.png" class="img_ev3q"></div><h3 class="anchor anchorWithStickyNavbar_LWe7" id="train-using-yolov5-on-google-colab-1">Train using YOLOv5 on Google Colab<a href="#train-using-yolov5-on-google-colab-1" class="hash-link" aria-label="Direct link to Train using YOLOv5 on Google Colab" title="Direct link to Train using YOLOv5 on Google Colab">‚Äã</a></h3><p>After we are done with annotating the dataset, we need to train the dataset. Jump to <a href="https://wiki.seeedstudio.com/Train-Deploy-AI-Model-A1101/#train-using-yolov5-on-google-colab" target="_blank" rel="noopener noreferrer">this part</a> which explains how to train an AI model using YOLOv5 running on Google Colab.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="3-deploy-the-trained-model-and-perform-inference">3. Deploy the trained model and perform inference<a href="#3-deploy-the-trained-model-and-perform-inference" class="hash-link" aria-label="Direct link to 3. Deploy the trained model and perform inference" title="Direct link to 3. Deploy the trained model and perform inference">‚Äã</a></h2><p>Now we will move the <strong>model-1.uf2</strong> that we obtained at the end of the training into SenseCAP A1101.</p><ul><li><p><strong>Step 1.</strong> Install the latest version of <a href="https://www.google.com/chrome" target="_blank" rel="noopener noreferrer">Google Chrome</a> or <a href="https://www.microsoft.com/en-us/edge?r=1" target="_blank" rel="noopener noreferrer">Microsoft Edge browser</a> and open it</p></li><li><p><strong>Step 2.</strong> Connect SenseCAP A1101 into your PC via a USB Type-C cable</p></li></ul><div align="center"><img loading="lazy" width="{500}" src="https://files.seeedstudio.com/wiki/SenseCAP-A1101/38.png" class="img_ev3q"></div><ul><li><strong>Step 3.</strong> Double-click the boot button on SenseCAP A1101 to enter mass storage mode</li></ul><div align="center"><img loading="lazy" width="{500}" src="https://files.seeedstudio.com/wiki/SenseCAP-A1101/39.png" class="img_ev3q"></div><p>After this, you will see a new storage drive shown on your file explorer as <strong>SENSECAP</strong></p><div align="center"><img loading="lazy" width="{280}" src="https://files.seeedstudio.com/wiki/SenseCAP-A1101/edge-impulse-A1101/p8.png" class="img_ev3q"></div><ul><li><strong>Step 4.</strong> Drag and drop the <strong>model-1.uf2</strong> file to <strong>SENSECAP</strong> drive</li></ul><p>As soon as the uf2 finishes copying into the drive, the drive will disappear. This means the uf2 has been successfully uploaded to the module.</p><p><strong>Note:</strong> If you have 4 model files ready, you can drag and drop each model one-by-one. Drop first model, wait until it finishes copying, enter boot mode again, drop second model and so on. If you have only loaded one model (with index 1) into SenseCAP A1101, it will load that model.</p><ul><li><p><strong>Step 5.</strong> Open <strong>SenseCAP Mate App</strong>. If you do not have it, download and install it on your mobile phone according to your OS</p><ul><li><a href="https://play.google.com/store/apps/details?id=cc.seeed.sensecapmate&amp;hl=en&amp;gl=US" target="_blank" rel="noopener noreferrer">Android</a></li><li><a href="https://apps.apple.com/gb/app/sensecap-mate/id1619944834" target="_blank" rel="noopener noreferrer">iOS</a></li></ul></li><li><p><strong>Step 6.</strong> Open the app, under <strong>Config</strong> screen, select <strong>Vision AI Sensor</strong></p></li></ul><div align="center"><img loading="lazy" width="{100}" src="https://files.seeedstudio.com/wiki/SenseCAP-A1101/21.jpg" class="img_ev3q"></div><ul><li><strong>Step 7.</strong> Press and hold the configuration button on the SenseCap A1101 for 3 seconds to enter bluetooth pairing mode</li></ul><div align="center"><img loading="lazy" width="{100}" src="https://files.seeedstudio.com/wiki/SenseCAP-A1101/37.png" class="img_ev3q"></div><ul><li><strong>Step 8.</strong> Click <strong>Setup</strong> and it will start scanning for nearby SenseCAP A1101 devices</li></ul><div align="center"><img loading="lazy" width="{100}" src="https://files.seeedstudio.com/wiki/SenseCAP-A1101/23.jpg" class="img_ev3q"></div><ul><li><strong>Step 9.</strong> Click on the device found</li></ul><div align="center"><img loading="lazy" width="{100}" src="https://files.seeedstudio.com/wiki/SenseCAP-A1101/24.jpg" class="img_ev3q"></div><ul><li><strong>Step 10.</strong> Go to <strong>Settings</strong> and make sure <strong>Object Detection</strong> is selected. If not, select it and click <strong>Send</strong></li></ul><div align="center"><img loading="lazy" width="{100}" src="https://files.seeedstudio.com/wiki/SenseCAP-A1101/25.jpg" class="img_ev3q"></div><ul><li><strong>Step 11.</strong> Go to <strong>General</strong> and click <strong>Detect</strong></li></ul><div align="center"><img loading="lazy" width="{100}" src="https://files.seeedstudio.com/wiki/SenseCAP-A1101/26.jpg" class="img_ev3q"></div><ul><li><strong>Step 12.</strong> <a href="https://files.seeedstudio.com/grove_ai_vision/index.html" target="_blank" rel="noopener noreferrer">Click here</a> to open a preview window of the camera stream</li></ul><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/SenseCAP-A1101/31.png" class="img_ev3q"></div><ul><li><strong>Step 13.</strong> Click <strong>Connect</strong> button. Then you will see a pop up on the browser. Select <strong>SenseCAP Vision AI - Paired</strong> and click <strong>Connect</strong></li></ul><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/SenseCAP-A1101/32.png" class="img_ev3q"></div><ul><li><strong>Step 14.</strong> View real-time inference results using the preview window!</li></ul><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/SenseCAP-A1101/33.jpg" class="img_ev3q"></div><p>As you can see above, the apples are being detected with bounding boxes around them. Here &quot;0&quot; corresponds to each detection of the same class. If you have multiple classes, they will be named as 0,1,2,3,4 and so on. Also the confidence score for each detected apple (0.8 and 0.84 in above demo) is being displayed!</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="bonus-content">Bonus content<a href="#bonus-content" class="hash-link" aria-label="Direct link to Bonus content" title="Direct link to Bonus content">‚Äã</a></h2><p>If you feel more adventurous, you can continue to follow the rest of the wiki!</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="can-i-train-an-ai-model-on-my-pc">Can I train an AI model on my PC?<a href="#can-i-train-an-ai-model-on-my-pc" class="hash-link" aria-label="Direct link to Can I train an AI model on my PC?" title="Direct link to Can I train an AI model on my PC?">‚Äã</a></h3><p>You can also use your own PC to train an object detection model. However, the training preformance will depend on the hardware you have. You also need to have a PC with a Linux OS for training. We have used an Ubuntu 20.04 PC for this wiki.</p><ul><li><strong>Step 1.</strong> Clone the <strong>yolov5-swift repo</strong> and install <strong>requirements.txt</strong> in a <strong>Python&gt;=3.7.0</strong> environment</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">git clone https://github.com/Seeed-Studio/yolov5-swift</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">cd yolov5-swift</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">pip install -r requirements.txt</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>Step 2.</strong> If you followed the steps in this wiki before, you might remember that we exported the dataset after annotating in Robolflow. Also in Roboflow Universe, we downloaded the dataset. In both methods, there was a window like below where it asks what kind of format to download the dataset. So now, please select <strong>download zip to computer</strong>, under <strong>Format</strong> choose <strong>YOLO v5 PyTorch</strong> and click <strong>Continue</strong></li></ul><div align="center"><img loading="lazy" width="{400}" src="https://files.seeedstudio.com/wiki/SenseCAP-A1101/16.png" class="img_ev3q"></div><div align="center"><img loading="lazy" width="{400}" src="https://files.seeedstudio.com/wiki/SenseCAP-A1101/17.png" class="img_ev3q"></div><p>After that, a <strong>.zip file</strong> will be downloaded to your computer</p><ul><li><strong>Step 3.</strong> Copy and paste the .zip file that we downloaded into <strong>yolov5-swift</strong> directory and extract it</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain"># example</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">cp ~/Downloads/Apples.v1i.yolov5pytorch.zip ~/yolov5-swift</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">unzip Apples.v1i.yolov5pytorch.zip</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>Step 4.</strong> Open <strong>data.yaml</strong> file and edit <strong>train</strong> and <strong>val</strong> directories as follows</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">train: train/images</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">val: valid/images</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>Step 5.</strong> Download a pre-trained model suitable for our training</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">sudo apt install wget</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">wget https://github.com/Seeed-Studio/yolov5-swift/releases/download/v0.1.0-alpha/yolov5n6-xiao.pt</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>Step 6.</strong> Execute the following to start training</li></ul><p>Here, we are able to pass a number of arguments:</p><ul><li><strong>img:</strong> define input image size</li><li><strong>batch:</strong> determine batch size</li><li><strong>epochs:</strong> define the number of training epochs</li><li><strong>data:</strong> set the path to our yaml file</li><li><strong>cfg:</strong> specify our model configuration</li><li><strong>weights:</strong> specify a custom path to weights</li><li><strong>name:</strong> result names</li><li><strong>nosave:</strong> only save the final checkpoint</li><li><strong>cache:</strong> cache images for faster training</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">python3 train.py --img 192 --batch 64 --epochs 100 --data data.yaml --cfg yolov5n6-xiao.yaml --weights yolov5n6-xiao.pt --name yolov5n6_results --cache</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>For an apple detection dataset with 987 images, it took around 30 minutes to finish the training process on a Local PC running on NVIDIA GeForce GTX 1660 Super GPU with 6GB GPU memory.</p><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/SenseCAP-A1101/44.png" class="img_ev3q"></div><p>If you followed the above Colab project, you know that you can load 4 models to the device all at once. However, please not that only one model can be loaded at a time. This can be specified by the user and will be explained later in this wiki.</p><ul><li><strong>Step 7.</strong> If you navigate to <code>runs/train/exp/weights</code>, you will see a file called <strong>best.pt</strong>. This is the generated model from training.</li></ul><div align="center"><img loading="lazy" width="{600}" src="https://files.seeedstudio.com/wiki/YOLOV5/33.jpg" class="img_ev3q"></div><ul><li><strong>Step 8.</strong> Export the trained model to TensorFlow Lite</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">python3 export.py --data {dataset.location}/data.yaml --weights runs/train/yolov5n6_results/weights/best.pt --imgsz 192 --int8 --include tflite</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>Step 9.</strong> Convert TensorFlow Lite to a UF2 file</li></ul><p>UF2 is a file format, developed by Microsoft. Seeed uses this format to convert .tflite to .uf2, allowing tflite files to be stored on the AIoT devices launched by Seeed. Currently Seeed&#x27;s devices support up to 4 models, each model (.tflite) is less than 1M .</p><p>You can specify the model to be placed in the corresponding index with -t.</p><p>For example:</p><ul><li><code>-t 1</code>: index 1</li><li><code>-t 2</code>: index 2</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain"># Place the model to index 1</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">python3 uf2conv.py -f GROVEAI -t 1 -c runs//train/yolov5n6_results//weights/best-int8.tflite -o model-1.uf2</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Eventhough you can load 4 models to the device all at once, please not that only one model can be loaded at a time. This can be specified by the user and will be explained later in this wiki.</p><ul><li><strong>Step 10.</strong> Now a file named <strong>model-1.uf2</strong> will be generated. This is the file that we will load into the SenseCAP A1101 Module to perform the inference!</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="check-bootloader-version">Check BootLoader Version<a href="#check-bootloader-version" class="hash-link" aria-label="Direct link to Check BootLoader Version" title="Direct link to Check BootLoader Version">‚Äã</a></h2><ul><li>Double click the BOOT button and wait for the removable drive to mount</li><li>Open INFO_UF2.TXT in the removable drive<div align="center"><img loading="lazy" width="{600}" src="https://github.com/Seeed-Studio/Seeed_Arduino_GroveAI/raw/master/assert/q2.png" class="img_ev3q"></div></li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="update-bootloader">Update BootLoader<a href="#update-bootloader" class="hash-link" aria-label="Direct link to Update BootLoader" title="Direct link to Update BootLoader">‚Äã</a></h2><p>If your SenseCAP A1101 is not recognized by your computer and behaves as no port number, then you may need to update the BootLoader.</p><ul><li><strong>Step 1</strong>. Download the BootLoader <code>.bin</code> file on the windows PC.</li></ul><p>Please download the latest version of the BootLoader file in the link below. The name of the BootLoader is usually <code>tinyuf2-sensecap_vision_ai_vx.x.x.bin</code>.</p><div class="github_container" style="text-align:center"><a href="https://github.com/Seeed-Studio/Seeed_Arduino_GroveAI/releases" target="_blank" rel="noopener noreferrer" class="github_item"><strong><span><font color="FFFFFF" size="4"> Download the Firware</font></span></strong> <svg aria-hidden="true" focusable="false" role="img" class="mr-2" viewBox="-3 10 9 1" width="16" height="16" fill="currentColor" style="text-align:center;display:inline-block;user-select:none;vertical-align:text-bottom;overflow:visible"><path d="M8 0c4.42 0 8 3.58 8 8a8.013 8.013 0 0 1-5.45 7.59c-.4.08-.55-.17-.55-.38 0-.27.01-1.13.01-2.2 0-.75-.25-1.23-.54-1.48 1.78-.2 3.65-.88 3.65-3.95 0-.88-.31-1.59-.82-2.15.08-.2.36-1.02-.08-2.12 0 0-.67-.22-2.2.82-.64-.18-1.32-.27-2-.27-.68 0-1.36.09-2 .27-1.53-1.03-2.2-.82-2.2-.82-.44 1.1-.16 1.92-.08 2.12-.51.56-.82 1.28-.82 2.15 0 3.06 1.86 3.75 3.64 3.95-.23.2-.44.55-.51 1.07-.46.21-1.61.55-2.33-.66-.15-.24-.6-.83-1.23-.82-.67.01-.27.38.01.53.34.19.73.9.82 1.13.16.45.68 1.31 2.69.94 0 .67.01 1.3.01 1.49 0 .21-.15.45-.55.38A7.995 7.995 0 0 1 0 8c0-4.42 3.58-8 8-8Z"></path></svg></a></div><p>This is the firmware that controls the BL702 chip that builds the connection between the computer and the Himax chip. The latest version of the BootLoader has now fixed the problem of Vision AI not being able to be recognised by Mac and Linux.</p><ul><li><strong>Step 2</strong>. Download and open <a href="https://files.seeedstudio.com/wiki/Grove_AI_Module/BouffaloLabDevCube-1.6.6-win32.rar" target="_blank" rel="noopener noreferrer"><strong>BLDevCube.exe</strong></a> software, select <strong>BL702/704/706</strong>, and then click <strong>Finish</strong>.</li></ul><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/Grove_AI_Module/GroveAI01a.png" style="width:300px;height:auto" class="img_ev3q"></div><ul><li><strong>Step 3</strong>. Click <strong>View</strong>, choose <strong>MCU</strong> first. Move to <strong>Image file</strong>, click <strong>Browse</strong> and select the firmware you just downloaded.</li></ul><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/Grove_AI_Module/1.png" style="width:800px;height:auto" class="img_ev3q"></div><ul><li><p><strong>Step 4</strong>. Make sure there are no other devices connect to the PC. Then hold the Boot button on the module, connect it to the PC.</p></li><li><p><strong>Step 5</strong>. Back to the BLDevCube software on the PC, click <strong>Refresh</strong> and choose a proper port. Then click <strong>Open UART</strong> and set <strong>Chip Erase</strong> to <strong>True</strong>, then click <strong>Creat&amp;Program</strong>, wait for the process done.</p></li></ul><div style="text-align:center"><img loading="lazy" src="https://files.seeedstudio.com/wiki/Grove_AI_Module/GroveAI07.png" style="width:800px;height:auto" class="img_ev3q"></div><h2 class="anchor anchorWithStickyNavbar_LWe7" id="resources">Resources<a href="#resources" class="hash-link" aria-label="Direct link to Resources" title="Direct link to Resources">‚Äã</a></h2><ul><li><p><strong>[Web Page]</strong> <a href="https://docs.ultralytics.com" target="_blank" rel="noopener noreferrer">YOLOv5 Documentation</a></p></li><li><p><strong>[Web Page]</strong> <a href="https://ultralytics.com/hub" target="_blank" rel="noopener noreferrer">Ultralytics HUB</a></p></li><li><p><strong>[Web Page]</strong> <a href="https://docs.roboflow.com" target="_blank" rel="noopener noreferrer">Roboflow Documentation</a></p></li><li><p><strong>[Web Page]</strong> <a href="https://www.tensorflow.org/lite/guide" target="_blank" rel="noopener noreferrer">TensorFlow Lite Documentation</a></p></li><li><p><strong>[PDF]</strong> <a href="https://files.seeedstudio.com/wiki/SenseCAP-A1101/SenseCAP_A1101_spec.pdf" target="_blank" rel="noopener noreferrer">SenseCAP A1101 LoRaWAN Vision AI Sensor Specification</a></p></li><li><p><strong>[PDF]</strong> <a href="https://files.seeedstudio.com/wiki/SenseCAP-A1101/SenseCAP_A1101_LoRaWAN_Vision_AI_Sensor_User_Guide_V1.0.2.pdf" target="_blank" rel="noopener noreferrer">SenseCAP A1101 LoRaWAN Vision AI Sensor User Guide</a></p></li><li><p><strong>[PDF]</strong> <a href="https://files.seeedstudio.com/products/114992867/SenseCAP%20S210X%20LoRaWAN%20Sensor%20Catalogue.pdf" target="_blank" rel="noopener noreferrer">SenseCAP S210X LoRaWAN Sensor Catalogue</a></p></li><li><p><strong>[PDF]</strong> <a href="https://files.seeedstudio.com/wiki/SenseCAP-A1101/FAQ_for_SenseCAP_A1101_LoRaWAN_AI_Vision_Sensor_v1.0.0.pdf" target="_blank" rel="noopener noreferrer">FAQ for SenseCAP A1101 LoRaWAN Vision AI Sensor</a></p></li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="tech-support--product-discussion">Tech Support &amp; Product Discussion<a href="#tech-support--product-discussion" class="hash-link" aria-label="Direct link to Tech Support &amp; Product Discussion" title="Direct link to Tech Support &amp; Product Discussion">‚Äã</a></h2><br><p>Thank you for choosing our products! We are here to provide you with different support to ensure that your experience with our products is as smooth as possible. We offer several communication channels to cater to different preferences and needs.</p><div class="button_tech_support_container"><a href="https://forum.seeedstudio.com/" target="_blank" rel="noopener noreferrer" class="button_forum"></a><a href="https://www.seeedstudio.com/contacts" target="_blank" rel="noopener noreferrer" class="button_email"></a></div><div class="button_tech_support_container"><a href="https://discord.gg/eWkprNDMU7" target="_blank" rel="noopener noreferrer" class="button_discord"></a><a href="https://github.com/Seeed-Studio/wiki-documents/discussions/69" target="_blank" rel="noopener noreferrer" class="button_discussion"></a></div></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/Seeed-Studio/wiki-documents/blob/docusaurus-version/docs/Sensor/SenseCAP/SenseCAP_LoRaWAN_Sensor/SenseCAP_A1101/Train-Deploy-AI-Model-A1101.md" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_vwxv"><span class="theme-last-updated">Last updated<!-- --> on <b><time datetime="2023-05-10T00:00:00.000Z">May 10, 2023</time></b> by <b>Yvonne</b></span></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/SenseCAP-Vision-AI-Get-Started/"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Getting Started with SenseCAP Vision AI</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/One-Stop-Model-Training-with-Edge-Impulse/"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">One Stop Model Training with Edge Impulse</div></a></nav></div><div>Loading Comments...</div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#overview" class="table-of-contents__link toc-highlight">Overview</a></li><li><a href="#hardware-introduction" class="table-of-contents__link toc-highlight">Hardware introduction</a></li><li><a href="#software-introduction" class="table-of-contents__link toc-highlight">Software introduction</a><ul><li><a href="#what-is-roboflow" class="table-of-contents__link toc-highlight">What is Roboflow?</a></li><li><a href="#what-is-yolov5" class="table-of-contents__link toc-highlight">What is YOLOv5?</a></li><li><a href="#what-is-tensorflow-lite" class="table-of-contents__link toc-highlight">What is TensorFlow Lite?</a></li></ul></li><li><a href="#wiki-structure" class="table-of-contents__link toc-highlight">Wiki structure</a></li><li><a href="#1-train-your-own-ai-model-with-a-public-dataset" class="table-of-contents__link toc-highlight">1. Train your own AI model with a public dataset</a><ul><li><a href="#hardware-preparation" class="table-of-contents__link toc-highlight">Hardware preparation</a></li><li><a href="#software-preparation" class="table-of-contents__link toc-highlight">Software preparation</a></li><li><a href="#use-publicly-available-annotated-dataset" class="table-of-contents__link toc-highlight">Use publicly available annotated dataset</a></li><li><a href="#train-using-yolov5-on-google-colab" class="table-of-contents__link toc-highlight">Train using YOLOv5 on Google Colab</a></li><li><a href="#deploy-and-inference" class="table-of-contents__link toc-highlight">Deploy and inference</a></li></ul></li><li><a href="#2-train-your-own-ai-model-with-your-own-dataset" class="table-of-contents__link toc-highlight">2. Train your own AI model with your own dataset</a><ul><li><a href="#hardware-preparation-1" class="table-of-contents__link toc-highlight">Hardware preparation</a></li><li><a href="#software-preparation-1" class="table-of-contents__link toc-highlight">Software preparation</a><ul><li><a href="#windows-linux-intel-mac" class="table-of-contents__link toc-highlight">Windows, Linux, Intel Mac</a></li><li><a href="#m1-m2-mac" class="table-of-contents__link toc-highlight">M1/ M2 Mac</a></li></ul></li><li><a href="#collect-dataset" class="table-of-contents__link toc-highlight">Collect dataset</a></li><li><a href="#change-device-firmware-after-image-collection" class="table-of-contents__link toc-highlight">Change device firmware after image collection</a></li><li><a href="#annotate-dataset-using-roboflow" class="table-of-contents__link toc-highlight">Annotate dataset using Roboflow</a></li><li><a href="#train-using-yolov5-on-google-colab-1" class="table-of-contents__link toc-highlight">Train using YOLOv5 on Google Colab</a></li></ul></li><li><a href="#3-deploy-the-trained-model-and-perform-inference" class="table-of-contents__link toc-highlight">3. Deploy the trained model and perform inference</a></li><li><a href="#bonus-content" class="table-of-contents__link toc-highlight">Bonus content</a><ul><li><a href="#can-i-train-an-ai-model-on-my-pc" class="table-of-contents__link toc-highlight">Can I train an AI model on my PC?</a></li></ul></li><li><a href="#check-bootloader-version" class="table-of-contents__link toc-highlight">Check BootLoader Version</a></li><li><a href="#update-bootloader" class="table-of-contents__link toc-highlight">Update BootLoader</a></li><li><a href="#resources" class="table-of-contents__link toc-highlight">Resources</a></li><li><a href="#tech-support--product-discussion" class="table-of-contents__link toc-highlight">Tech Support &amp; Product Discussion</a></li></ul></div></div></div></div></main></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Navigation</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/Getting_Started/">Getting Started</a></li><li class="footer__item"><a class="footer__link-item" href="/Sensor_Network/">Sensor and Sensing</a></li><li class="footer__item"><a class="footer__link-item" href="/Network/">Network</a></li><li class="footer__item"><a class="footer__link-item" href="/Edge_Computing/">Edge Computing</a></li><li class="footer__item"><a class="footer__link-item" href="/Cloud/">Cloud</a></li><li class="footer__item"><a class="footer__link-item" href="/Solutions/">Solutions</a></li></ul></div><div class="col footer__col"><div class="footer__title">Ecosystem</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://discord.com/invite/QqMgVwHT3X" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord</a></li><li class="footer__item"><a href="https://project.seeedstudio.com/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Project Hub</a></li><li class="footer__item"><a href="https://www.seeedstudio.com/ecosystem/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Partners</a></li><li class="footer__item"><a href="https://www.seeedstudio.com/distributors.html" target="_blank" rel="noopener noreferrer" class="footer__link-item">Distributors</a></li></ul></div><div class="col footer__col"><div class="footer__title">Quick Guide</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://www.seeedstudio.com/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Bazzar</a></li><li class="footer__item"><a href="https://www.seeedstudio.com/get_help/HowToGetHelp" target="_blank" rel="noopener noreferrer" class="footer__link-item">How to get help</a></li><li class="footer__item"><a href="https://support.seeedstudio.com/knowledgebase" target="_blank" rel="noopener noreferrer" class="footer__link-item">FAQs</a></li><li class="footer__item"><a href="https://forum.seeedstudio.com/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Forum</a></li><li class="footer__item"><a href="https://www.seeedstudio.com/get_help/TechnicalSupport" target="_blank" rel="noopener noreferrer" class="footer__link-item">Technical Support</a></li></ul></div><div class="col footer__col"><div class="footer__title">Company</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://www.seeedstudio.com/about-us/" target="_blank" rel="noopener noreferrer" class="footer__link-item">About Seeed</a></li><li class="footer__item"><a href="https://www.seeedstudio.com/join-us/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Join us</a></li><li class="footer__item"><a href="https://www.seeedstudio.com/contacts" target="_blank" rel="noopener noreferrer" class="footer__link-item">Contact Us</a></li><li class="footer__item"><a href="https://www.seeedstudio.com/blog/2020/04/22/seeed-in-the-news/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Press</a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright ¬© 2024 Seeed Studio, Inc. Built with Docusaurus.</div></div></div></footer></div>
<script src="/assets/js/runtime~main.7b0f7417.js"></script>
<script src="/assets/js/main.4c47889c.js"></script>
</body>
</html>