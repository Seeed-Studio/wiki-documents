<!doctype html>
<html lang="en-US" dir="ltr" class="docs-wrapper docs-doc-page docs-version-current plugin-docs plugin-id-default docs-doc-id-Edge/NVIDIA_Jetson/Application/Computer_Vision/YOLOv5-Object-Detection-Jetson" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.4.3">
<title data-rh="true">Getting started with Yolov5 and roboflow | Seeed Studio Wiki</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://wiki.seeedstudio.com/YOLOv5-Object-Detection-Jetson/"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Getting started with Yolov5 and roboflow | Seeed Studio Wiki"><meta data-rh="true" name="description" content="Few-shot Object Detection - Data Label, AI Model Train, AI Model Deploy with Yolov5 and roboflow on NVIDIA Jetson"><meta data-rh="true" property="og:description" content="Few-shot Object Detection - Data Label, AI Model Train, AI Model Deploy with Yolov5 and roboflow on NVIDIA Jetson"><meta data-rh="true" property="og:image" content="https://files.seeedstudio.com/wiki/wiki-platform/S-tempor.png"><meta data-rh="true" name="twitter:image" content="https://files.seeedstudio.com/wiki/wiki-platform/S-tempor.png"><link data-rh="true" rel="icon" href="/img/S.png"><link data-rh="true" rel="canonical" href="https://wiki.seeedstudio.com/YOLOv5-Object-Detection-Jetson/"><link data-rh="true" rel="alternate" href="https://wiki.seeedstudio.com/YOLOv5-Object-Detection-Jetson/" hreflang="en-US"><link data-rh="true" rel="alternate" href="https://wiki.seeedstudio.com/YOLOv5-Object-Detection-Jetson/" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Seeed Studio Wiki RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Seeed Studio Wiki Atom Feed">

<link rel="preconnect" href="https://www.googletagmanager.com">
<script>window.dataLayer=window.dataLayer||[]</script>
<script>!function(e,t,a,n){e[n]=e[n]||[],e[n].push({"gtm.start":(new Date).getTime(),event:"gtm.js"});var g=t.getElementsByTagName(a)[0],m=t.createElement(a);m.async=!0,m.src="https://www.googletagmanager.com/gtm.js?id=GTM-M4JG2HVB",g.parentNode.insertBefore(m,g)}(window,document,"script","dataLayer")</script>


<link rel="icon" href="/img/S.png">
<link rel="manifest" href="/manifest.json">
<meta name="theme-color" content="rgb(37, 194, 160)">


<link rel="search" type="application/opensearchdescription+xml" title="Seeed Studio Wiki" href="/opensearch.xml">
<script src="https://viewer.altium.com/client/static/js/embed.js" async></script>
<script src="/js/custom.js" async></script><link rel="stylesheet" href="/assets/css/styles.43565612.css">
<link rel="preload" href="/assets/js/runtime~main.2b86bf0f.js" as="script">
<link rel="preload" href="/assets/js/main.c695d726.js" as="script">
</head>
<body class="navigation-with-keyboard">
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-M4JG2HVB" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>

<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}return t}()||function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"dark")}(),document.documentElement.setAttribute("data-announcement-bar-initially-dismissed",function(){try{return"true"===localStorage.getItem("docusaurus.announcement.dismiss")}catch(t){}return!1}())</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><div class="announcementBar_mb4j" style="background-color:#013949;color:#FFFFFF" role="banner"><div class="content_knG7 announcementBarContent_xLdY">Collaborating with us! Join the Seeed Studio <a target="_blank" href="https://wiki.seeedstudio.com/ranger/">Ranger Program</a> or <a target="_blank" href="https://wiki.seeedstudio.com/contributors/">Contributor Program</a>!</div></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/Getting_Started/"><div class="navbar__logo"><img src="https://files.seeedstudio.com/wiki/wiki-platform/SeeedStudio.png" alt="Seeed Studio" class="themedImage_ToTc themedImage--light_HNdA navbar_logo_items"><img src="https://files.seeedstudio.com/wiki/wiki-platform/seeed_white_logo.png" alt="Seeed Studio" class="themedImage_ToTc themedImage--dark_i4oU navbar_logo_items"></div></a><div class="navbar__item dropdown dropdown--hoverable"><a class="navbar__link navbar_dorp_items" aria-haspopup="true" aria-expanded="false" role="button" href="/Getting_Started/">Getting Started</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/Sensor_Network/">Sensor and Sensing</a></li><li><a class="dropdown__link" href="/Network/">Networking</a></li><li><a class="dropdown__link" href="/Edge_Computing/">Edge Computing</a></li><li><a class="dropdown__link" href="/Cloud/">Cloud</a></li></ul></div><div class="navbar__item dropdown dropdown--hoverable"><a class="navbar__link navbar_dorp_items" aria-haspopup="true" aria-expanded="false" role="button" href="/topicintroduction/">Technology</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/tinyml_topic/">TinyML</a></li><li><a class="dropdown__link" href="/ModelAssistant_Introduce_Overview/">SenseCraft Model Assistant</a></li><li><a class="dropdown__link" href="/home_assistant_topic/">Home Assistant</a></li><li><a class="dropdown__link" href="/open_source_topic/">Open Source</a></li><li><a class="dropdown__link" href="/edge_ai_topic/">Edge AI</a></li><li><a class="dropdown__link" href="/cn/Getting_Started/">ÁüΩÈÄíÁßëÊäÄ Wiki ÊñáÊ°£Âπ≥Âè∞ÔºàÊµãËØïÔºâ</a></li></ul></div><div class="navbar__item dropdown dropdown--hoverable"><a class="navbar__link navbar_dorp_items" aria-haspopup="true" aria-expanded="false" role="button" href="/knowledgebase/">FAQs</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/Jetson_FAQ/">NVIDIA Jetson Series</a></li><li><a class="dropdown__link" href="/XIAO_FAQ/">Seeed Studio XIAO Series</a></li><li><a class="dropdown__link" href="/reComputer_R1000_FAQ/">reComputer R1000 Series</a></li><li><a class="dropdown__link" href="/reTerminal-new_FAQ/">reTerminal</a></li><li><a class="dropdown__link" href="/FAQs_For_openWrt/">reRouter</a></li><li><a class="dropdown__link" href="/ODYSSEY_FAQ/">Odyssey</a></li><li><a class="dropdown__link" href="/wio_terminal_faq/">Wio Terminal</a></li><li><hr style="margin: 8px 0;"></li><li><a href="https://discord.com/invite/eWkprNDMU7" target="_blank" rel="noopener noreferrer" class="dropdown__link">Discord<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li><a href="https://www.seeedstudio.com/contacts" target="_blank" rel="noopener noreferrer" class="dropdown__link">Email<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li><a href="https://forum.seeedstudio.com/" target="_blank" rel="noopener noreferrer" class="dropdown__link">Forum<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li><a href="https://github.com/Seeed-Studio/wiki-documents/discussions/69" target="_blank" rel="noopener noreferrer" class="dropdown__link">Have Suggestions?<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="navbar__item dropdown dropdown--hoverable"><a class="navbar__link navbar_dorp_items" aria-haspopup="true" aria-expanded="false" role="button" href="/ranger/">Rangers</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/ranger/">Rangers</a></li><li><a class="dropdown__link" href="/contributors/">Contributors</a></li><li><a href="https://docs.google.com/forms/d/e/1FAIpQLSdiAWHmRJqgVNTJyJDkzhufc1dygFyhWFyEtUTm-mrgSKaEgg/viewform" target="_blank" rel="noopener noreferrer" class="dropdown__link">Apply for Rangers<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li><a href="https://github.com/orgs/Seeed-Studio/projects/6" target="_blank" rel="noopener noreferrer" class="dropdown__link">Direct to Assignments<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li><a href="https://www.seeedstudio.com/blog/2023/09/15/join-the-seeed-ranger-program-empowering-developers-and-building-communities/" target="_blank" rel="noopener noreferrer" class="dropdown__link">More about Rangers<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li><a href="https://wiki.seeedstudio.com/Contributor" target="_blank" rel="noopener noreferrer" class="dropdown__link">More about Contributors<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="navbar__items navbar__items--right"><a href="https://www.seeedstudio.com/" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link navbar_doc_right_items">Bazaar üõçÔ∏è</a><a href="https://wiki-gpt.seeedstudio.com/chat" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link navbar_doc_right_items">AI Bot ü§ñÔ∏è</a><a href="https://sensecraft.seeed.cc/ai/#/home" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link navbar_doc_right_items">SenseCraft AI</a><a href="https://sensecraft.seeed.cc/ai/#/home" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-SSCMA"></a><a href="https://github.com/Seeed-Studio/wiki-documents" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-github-link" aria-label="GitHub repository"></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently dark mode)" aria-label="Switch between dark and light mode (currently dark mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0 docsWrapper_BCFX"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docPage__5DB"><aside class="theme-doc-sidebar-container docSidebarContainer_b6E3"><div class="sidebarViewport_Xe31"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG menuWithAnnouncementBar_GW3s"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item sideboard_calss"><a class="menu__link" href="/Getting_Started/">Getting Started</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item sideboard_calss"><a class="menu__link" href="/weekly_wiki/">Weekly Wiki</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item sideboard_calss"><a class="menu__link" href="/Sensor_Network/">Sensing</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/Grove_System/">Grove</a><button aria-label="Toggle the collapsible sidebar category &#x27;Grove&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/SenseCAP_introduction/">SenseCAP</a><button aria-label="Toggle the collapsible sidebar category &#x27;SenseCAP&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/Sensor/SenseCAP/SenseCAP_Indicator/Get_started_with_SenseCAP_Indicator/">SenseCAP Indicator</a><button aria-label="Toggle the collapsible sidebar category &#x27;SenseCAP Indicator&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/watcher/">SenseCAP Watcher</a><button aria-label="Toggle the collapsible sidebar category &#x27;SenseCAP Watcher&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/mmwave_radar_Intro/">mmWave Radar Sensor</a><button aria-label="Toggle the collapsible sidebar category &#x27;mmWave Radar Sensor&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/SeeedStudio_XIAO_Series_Introduction/">XIAO</a><button aria-label="Toggle the collapsible sidebar category &#x27;XIAO&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/Wio_Terminal_Intro/">Wio Terminal</a><button aria-label="Toggle the collapsible sidebar category &#x27;Wio Terminal&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/reSpeaker_usb_v3/">ReSpeaker Lite</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/Ultra_Sonic_range_measurement_module/">Other Sensing Modules</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/Wio/">Other Microcontrollers</a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item sideboard_calss"><a class="menu__link" href="/Network/">Network</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/meshtastic_introduction/">Meshtastic Network</a><button aria-label="Toggle the collapsible sidebar category &#x27;Meshtastic Network&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/Network/SenseCAP_Network/SenseCAP_Gateway_Intro/">SenseCAP Gateway</a><button aria-label="Toggle the collapsible sidebar category &#x27;SenseCAP Gateway&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/SenseCAP_K1100_Intro/">SenseCAP K1100</a><button aria-label="Toggle the collapsible sidebar category &#x27;SenseCAP K1100&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/M2_Kit_Getting_Started/">SenseCAP LoRaWAN Starter Kit</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/reRouter_Intro/">Raspberry Pi Solutions</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/Rockchip_network_solutions/">Rockchip Solutions</a><button aria-label="Toggle the collapsible sidebar category &#x27;Rockchip Solutions&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/The-Things-Indoor-Gateway/">Other Network Devices</a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item sideboard_calss"><a class="menu__link" href="/Edge_Computing/">Edge Computing</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/raspberry-pi-devices/">Raspberry Pi Devices</a><button aria-label="Toggle the collapsible sidebar category &#x27;Raspberry Pi Devices&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active" aria-expanded="true" href="/NVIDIA_Jetson/">NVIDIA¬Æ Jetson‚Ñ¢</a><button aria-label="Toggle the collapsible sidebar category &#x27;NVIDIA¬Æ Jetson‚Ñ¢&#x27;" type="button" class="clean-btn menu__caret"></button></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/reComputer_J1010_J101_Flash_Jetpack/">Carrier Boards</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/reComputer_Intro/">reComputer Jetson</a><button aria-label="Toggle the collapsible sidebar category &#x27;reComputer Jetson&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/reServer_Industrial_Getting_Started/">reServer Jetson</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/Jetson_AGX_Orin_32GB_H01_Flash_Jetpack/">Other Devices</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" tabindex="0" href="/DashCamNet-with-Jetson-Xavier-NX-Multicamera/">Applications</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" tabindex="0" href="/DashCamNet-with-Jetson-Xavier-NX-Multicamera/">Computer Vision</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/DashCamNet-with-Jetson-Xavier-NX-Multicamera/">DashCamNet with Jetson Xavier NX Multicamera</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/How_to_Train_and_Deploy_YOLOv8_on_reComputer/">How to train and deploy YOLOv8 on reComputer</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/Jetson-Nano-MaskCam/">MaskCam</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/Security_Scan/">Security Xray Scan Knife Detection</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/reComputer_Jetson_Series_Projects/">Jetson Community Projects</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/Traffic-Management-DeepStream-SDK/">Traffic Management DeepStream SDK</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/YOLOv5-Object-Detection-Jetson/">Getting started with Yolov5 and roboflow</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/YOLOv8-DeepStream-TRT-Jetson/">Deploy YOLOv8 with TensorRT and DeepStream SDK</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/YOLOv8-TRT-Jetson/">Deploy YOLOv8 with TensorRT</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/train_and_deploy_a_custom_classification_model_with_yolov8/">Train and deploy a custom classification model with YOLOv8</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/deploy_frigate_on_jetson/">Deploy Frigate On Jetson</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-4 menu__list-item"><a class="menu__link" tabindex="0" href="/ai_nvr_with_jetson/">AI NVR with Jetson Orin</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" tabindex="0" href="/Generative_AI_Intro/">Generative AI</a><button aria-label="Toggle the collapsible sidebar category &#x27;Generative AI&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/speech_vlm/">Multimodal AI</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/installing_ros1/">Robotics</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/Allxon-Jetson-Getting-Started/">Managed Services</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-3 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/gapi_getting_started-with_jetson/">Developer Tools</a></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-2 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" tabindex="0" href="/Jetson_FAQ/">FAQs</a></div></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/Edgebox-ESP-100-Arduino/">ESP Devices</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/BeagleBone/">BeagleBone¬Æ</a><button aria-label="Toggle the collapsible sidebar category &#x27;BeagleBone¬Æ&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/ODYSSEY_Intro/">ODYSSEY</a><button aria-label="Toggle the collapsible sidebar category &#x27;ODYSSEY&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/recamera_getting_started/">reCamera</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/reServer-Getting-Started/">Other Edge Devices</a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item sideboard_calss"><a class="menu__link" href="/Cloud/">Cloud</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/Cloud_Chain/SenseCAP_Dashboard/Dashboard_Basics/">SenseCAP Dashboard</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/Cloud_Chain/SenseCAP_Portal/QuickStart/">SenseCAP Portal</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/SenseCAP_Hotspot_APP/">SenseCAP Hotspot APP</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/sensecraft_app/">SenseCraft APP</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/How_to_Use_SenseCAP_AI_on_SenseCAP_Portal_and_SenseCAP_Mate_APP/">SenseCAP AI</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/Cloud_Chain/SenseCAP_API/SenseCAP_API_Introduction/">SenseCAP API</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/sensecraft_ai/">SenseCraft AI</a><button aria-label="Toggle the collapsible sidebar category &#x27;SenseCraft AI&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item sideboard_calss"><a class="menu__link" href="/topicintroduction/">Technology Topics</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/home_assistant_topic/">Home Assistant</a><button aria-label="Toggle the collapsible sidebar category &#x27;Home Assistant&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/tinyml_topic/">TinyML</a><button aria-label="Toggle the collapsible sidebar category &#x27;TinyML&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/open_source_topic/">Open Source</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/edge_ai_topic/">Edge AI</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item sideboard_calss"><a class="menu__link" href="/Contributor/">Contributions</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/Contribution-Guide/">Github Contributions Guide</a><button aria-label="Toggle the collapsible sidebar category &#x27;Github Contributions Guide&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/Scale-up-Your-Creation-with-Fusion/">Scale up Your Creation with Seeed Studio Fusion</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item sideboard_calss"><a class="menu__link" href="/popularplatforms/">Popular Platforms</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/Arduino/">Arduino</a><button aria-label="Toggle the collapsible sidebar category &#x27;Arduino&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/Raspberry_Pi/">Raspberry Pi</a><button aria-label="Toggle the collapsible sidebar category &#x27;Raspberry Pi&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/microbit_wiki_page/">Micro:bit</a><button aria-label="Toggle the collapsible sidebar category &#x27;Micro:bit&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item sideboard_calss"><a class="menu__link" href="/discontinuedproducts/">Discontinued Products</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/ReSpeaker/">Product List</a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/About/">About</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/License/">License</a></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_gTbr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_z5aJ"><div class="docItemContainer_c0TR"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item"><a class="breadcrumbs__link" itemprop="item" href="/NVIDIA_Jetson/"><span itemprop="name">NVIDIA¬Æ Jetson‚Ñ¢</span></a><meta itemprop="position" content="1"></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Applications</span><meta itemprop="position" content="2"></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Computer Vision</span><meta itemprop="position" content="3"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">Getting started with Yolov5 and roboflow</span><meta itemprop="position" content="4"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>Few-Shot Object Detection with YOLOv5 and Roboflow</h1><h2 class="anchor anchorWithStickyNavbar_LWe7" id="introduction">Introduction<a href="#introduction" class="hash-link" aria-label="Direct link to Introduction" title="Direct link to Introduction">‚Äã</a></h2><p><a href="https://docs.ultralytics.com" target="_blank" rel="noopener noreferrer">YOLO</a> is one of the most famous object detection algorithms available. It only needs <strong>few samples for training</strong>, while providing <strong>faster training times</strong> and <strong>high accuracy</strong>. We will demonstrate these features one-by-one in this wiki, while explaining the complete machine learning pipeline step-by-step where you <strong>collect data, label them, train them and finally detect objects using the trained data</strong> by running the trained model on an edge device such as the <strong>NVIDIA Jetson platform</strong>. Also, we will compare the difference between using custom datasets and public datasets.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="what-is-yolov5">What is YOLOv5?<a href="#what-is-yolov5" class="hash-link" aria-label="Direct link to What is YOLOv5?" title="Direct link to What is YOLOv5?">‚Äã</a></h2><p>YOLO is an abbreviation for the term ‚ÄòYou Only Look Once‚Äô. It is an algorithm that detects and recognizes various objects in an image in real-time. Ultralytics <a href="https://ultralytics.com/yolov5" target="_blank" rel="noopener noreferrer">YOLOv5</a> is the latest version of YOLO and it is now based on the PyTorch framework.</p><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOV5/YOLOv5_banner.jpg" class="img_ev3q"></div><h2 class="anchor anchorWithStickyNavbar_LWe7" id="what-is-few-shot-object-detection">What is few-shot object detection?<a href="#what-is-few-shot-object-detection" class="hash-link" aria-label="Direct link to What is few-shot object detection?" title="Direct link to What is few-shot object detection?">‚Äã</a></h2><p>Traditionally if you want to train a machine learning model, you would use a public dataset such as the Pascal VOC 2012 dataset which consists of around 17112 images. However, we will use transfer learning to realize few-shot object detection with YOLOv5 which needs only a very few training samples. We will demonstate this in this wiki.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="hardware-supported">Hardware supported<a href="#hardware-supported" class="hash-link" aria-label="Direct link to Hardware supported" title="Direct link to Hardware supported">‚Äã</a></h2><p>YOLOv5 is supported by the following hardware:</p><ul><li><p>Official Development Kits by NVIDIA:</p><ul><li>NVIDIA¬Æ Jetson Nano Developer Kit</li><li>NVIDIA¬Æ Jetson Xavier NX Developer Kit</li><li>NVIDIA¬Æ Jetson AGX Xavier Developer Kit</li><li>NVIDIA¬Æ Jetson TX2 Developer Kit</li></ul></li><li><p>Official SoMs by NVIDIA:</p><ul><li>NVIDIA¬Æ Jetson Nano module</li><li>NVIDIA¬Æ Jetson Xavier NX module</li><li>NVIDIA¬Æ Jetson TX2 NX module</li><li>NVIDIA¬Æ Jetson TX2 module</li><li>NVIDIA¬Æ Jetson AGX Xavier module</li></ul></li><li><p>Carrier Boards by Seeed:</p><ul><li>Jetson Mate</li><li>Jetson SUB Mini PC</li><li>Jetson Xavier AGX H01 Kit</li><li>A203 Carrier Board</li><li>A203 (Version 2) Carrier Board</li><li>A205 Carrier Board</li><li>A206 Carrier Board</li></ul></li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="prerequisites">Prerequisites<a href="#prerequisites" class="hash-link" aria-label="Direct link to Prerequisites" title="Direct link to Prerequisites">‚Äã</a></h2><ul><li><p>Any of the above Jetson devices running latest JetPack v4.6.1 with all SDK components installed (check <a href="https://wiki.seeedstudio.com/reComputer_J1020_A206_Flash_JetPack/" target="_blank" rel="noopener noreferrer">this wiki</a> for a reference on installation)</p></li><li><p>Host PC</p><ul><li>Local training needs a Linux PC (preferably Ubuntu)</li><li>Cloud training can be performed from a PC with any OS</li></ul></li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="getting-started">Getting started<a href="#getting-started" class="hash-link" aria-label="Direct link to Getting started" title="Direct link to Getting started">‚Äã</a></h2><p>Running your first object detection project on an edge device such as the Jetson platform simply involves 4 main steps!</p><ol><li><p>Collect dataset or use publically available dataset</p><ul><li>Collect dataset manually</li><li>Use publicly available dataset</li></ul></li><li><p>Annotate dataset using Roboflow</p></li><li><p>Train on local PC or cloud</p><ul><li>Train on local PC (Linux)</li><li>Train on Google Colab</li></ul></li><li><p>Inference on Jetson device</p></li></ol><h2 class="anchor anchorWithStickyNavbar_LWe7" id="collect-dataset-or-use-publically-available-dataset">Collect dataset or use publically available dataset<a href="#collect-dataset-or-use-publically-available-dataset" class="hash-link" aria-label="Direct link to Collect dataset or use publically available dataset" title="Direct link to Collect dataset or use publically available dataset">‚Äã</a></h2><p>The very first step of an object detection project is to obtain data for training. You can either download datasets available publicly or create your own dataset! Usually public datasets are used for education and research purposes. However, if you want to build specific object detection projects where the public datasets do not have the objects that you want to detect, you might want to build your own dataset.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="collect-dataset-manually">Collect dataset manually<a href="#collect-dataset-manually" class="hash-link" aria-label="Direct link to Collect dataset manually" title="Direct link to Collect dataset manually">‚Äã</a></h3><p>It is recommended that you first record a video footage of the object that you want to recognize. You have to make sure that you cover all angles (360 degrees) of the object, place the object in different environments, different lighting and different weather conditions.
The total video we recorded is 9 minutes long where 4.5 minutes is for flowers and the remaining 4.5 minutes is for leaves.  The recording can be broken down as follows:</p><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOV5/pink-flowers-2.gif" class="img_ev3q"></div><ol><li>morning normal weather</li><li>morning windy weather</li><li>Morning rainy weather</li><li>Noon normal weather</li><li>Noon windy weather</li><li>Noon rainy weather</li><li>Evening normal weather</li><li>Evening windy weather</li><li>Evening rainy weather</li></ol><p><strong>Note:</strong> Later on, we will convert this video footage into a series of images to make up the dataset for training.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="use-publicly-available-dataset">Use publicly available dataset<a href="#use-publicly-available-dataset" class="hash-link" aria-label="Direct link to Use publicly available dataset" title="Direct link to Use publicly available dataset">‚Äã</a></h3><p>You can download a number of publically available datasets such as the  <a href="https://cocodataset.org" target="_blank" rel="noopener noreferrer">COCO dataset</a>, <a href="http://host.robots.ox.ac.uk/pascal/VOC" target="_blank" rel="noopener noreferrer">Pascal VOC dataset</a> and much more. <a href="https://universe.roboflow.com" target="_blank" rel="noopener noreferrer">Roboflow Universe</a> is a recommended platform which provides a wide-range of datasets and it has <a href="https://blog.roboflow.com/computer-vision-datasets-and-apis" target="_blank" rel="noopener noreferrer">90,000+ datasets with 66+ million images</a> available for building computer vision models. Also, you can simply search <strong>open-source datasets</strong> on Google and choose from a variety of datasets available.</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="annotate-dataset-using-roboflow">Annotate dataset using Roboflow<a href="#annotate-dataset-using-roboflow" class="hash-link" aria-label="Direct link to Annotate dataset using Roboflow" title="Direct link to Annotate dataset using Roboflow">‚Äã</a></h2><p>Next we will move on to annotating the dataset that we have. Annotating means simply drawing rectangular boxes around each object that we want to detect and assign them labels. We will explain how to do this using Roboflow.</p><p><a href="https://roboflow.com" target="_blank" rel="noopener noreferrer">Roboflow</a> is an annotation tool based online. Here we can directly import the video footage that we recorded before into Roboflow and it will be exported into a series of images. This tool is very convenient because it will let us help distribute the dataset into &quot;training, validation and testing&quot;. Also this tool will allow us to add further processing to these images after labelling them. Furthermore, it can easily export the labelled dataset into <strong>YOLOV5 PyTorch format</strong> which is what we exactly need!</p><ul><li><p><strong>Step 1.</strong> Click <a href="https://app.roboflow.com/login" target="_blank" rel="noopener noreferrer">here</a> to sign up for a Roboflow account</p></li><li><p><strong>Step 2.</strong> Click <strong>Create New Project</strong> to start our project</p></li></ul><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOV5/2.jpg" class="img_ev3q"></div><ul><li><strong>Step 3.</strong> Fill in <strong>Project Name</strong>, keep the <strong>License (CC BY 4.0)</strong> and <strong>Project type (Object Detection (Bounding Box))</strong>  as default. Under <strong>What will your model predict?</strong> column, fill in an annotation group name. For example, in our case we choose <strong>plants</strong>. This name should highlight all of the classes of your dataset. Finally, click <strong>Create Public Project</strong>.</li></ul><div align="center"><img loading="lazy" width="360" src="https://files.seeedstudio.com/wiki/YOLOV5/20.jpg" class="img_ev3q"></div><ul><li><strong>Step 4.</strong> Drag and drop the video footage that you recorded before</li></ul><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOV5/4.jpg" class="img_ev3q"></div><ul><li><strong>Step 5.</strong> Choose a framerate so that the video will be divided into a series of images. Here we will use the default frame rate which is <strong>1 frame/second</strong> and this will generate 542 images in total. Once you select a frame rate by scrubbing through the slider, click <strong>Choose Frame Rate</strong>. It will take a few seconds to a few minutes (depending on the video length) to finish this process.</li></ul><div align="center"><img loading="lazy" width="400" src="https://files.seeedstudio.com/wiki/YOLOV5/5.png" class="img_ev3q"></div><ul><li><strong>Step 6.</strong> After the images are processed, click <strong>Finish Uploading</strong>. Wait patiently until the images are uploaded.</li></ul><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOV5/6.jpg" class="img_ev3q"></div><ul><li><strong>Step 7.</strong> After the images are uploaded, click <strong>Assign Images</strong></li></ul><div align="center"><img loading="lazy" width="500" src="https://files.seeedstudio.com/wiki/YOLOV5/7.jpg" class="img_ev3q"></div><ul><li><strong>Step 8.</strong> Select an image, draw a rectangular box around a flower, choose the label as <strong>pink flower</strong> and press <strong>ENTER</strong></li></ul><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOV5/21.jpg" class="img_ev3q"></div><ul><li><strong>Step 9.</strong> Repeat the same for the remaining flowers</li></ul><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOV5/22.jpg" class="img_ev3q"></div><ul><li><strong>Step 10.</strong> Draw a rectangular box around a leaf, choose the label as <strong>leaf</strong> and press <strong>ENTER</strong></li></ul><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOV5/23.jpg" class="img_ev3q"></div><ul><li><strong>Step 11.</strong> Repeat the same for the remaining leaves</li></ul><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOV5/24.jpg" class="img_ev3q"></div><p><strong>Note:</strong> Try to label all the objects that you see inside the image. If only a part of the object is visible, try to label that too.</p><ul><li><strong>Step 12.</strong> Continue to annotate all the images in the dataset</li></ul><p>Roboflow has a feature called <strong>Label Assist</strong> where it can predict the labels beforehand so that your labelling will be much faster. However, it will not work with all object types, but rather a selected type of objects. To turn this feature on, you simply need to press the <strong>Label Assist</strong> button, <strong>select a model</strong>, <strong>select the classes</strong> and navigate through the images to see the predicted labels with bounding boxes</p><div align="center"><img loading="lazy" width="300" src="https://files.seeedstudio.com/wiki/YOLOV5/41.png" class="img_ev3q"></div><div align="center"><img loading="lazy" width="400" src="https://files.seeedstudio.com/wiki/YOLOV5/39.png" class="img_ev3q"></div><div align="center"><img loading="lazy" width="400" src="https://files.seeedstudio.com/wiki/YOLOV5/40.png" class="img_ev3q"></div><p>As you can see above, it can only help to predict annotations for the 80 classes mentioned. If your images do not contain the object classes from above, you cannot use the label assist feature.</p><ul><li><strong>Step 13.</strong> Once labelling is done, click <strong>Add images to Dataset</strong></li></ul><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOV5/25.jpg" class="img_ev3q"></div><ul><li><strong>Step 14.</strong> Next we will split the images between &quot;Train, Valid and Test&quot;. Keep the default percentages for the distribution and click <strong>Add Images</strong></li></ul><div align="center"><img loading="lazy" width="330" src="https://files.seeedstudio.com/wiki/YOLOV5/26.png" class="img_ev3q"></div><ul><li><strong>Step 15.</strong> Click <strong>Generate New Version</strong></li></ul><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOV5/27.jpg" class="img_ev3q"></div><ul><li><strong>Step 16.</strong> Now you can add <strong>Preprocessing</strong> and <strong>Augmentation</strong> if you prefer. Here we will <strong>delete</strong> the <strong>Resize</strong> option and keep the original image sizes</li></ul><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOV5/28.jpg" class="img_ev3q"></div><ul><li><strong>Step 17.</strong> Next, proceed with the remaining defaults and click <strong>Generate</strong></li></ul><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOV5/29.jpg" class="img_ev3q"></div><ul><li><strong>Step 18.</strong> Click <strong>Export</strong></li></ul><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOV5/17.jpg" class="img_ev3q"></div><ul><li><strong>Step 19.</strong> Select <strong>download zip to computer</strong>, under &quot;Select a Format&quot; choose <strong>YOLO v5 PyTorch</strong> and click <strong>Continue</strong></li></ul><div align="center"><img loading="lazy" width="400" src="https://files.seeedstudio.com/wiki/YOLOV5/18.jpg" class="img_ev3q"></div><ul><li><strong>Step 20.</strong> After that, a <strong>.zip file</strong> will be downloaded to your computer. We will need this .zip file later for our training.</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="train-on-local-pc-or-cloud">Train on local PC or cloud<a href="#train-on-local-pc-or-cloud" class="hash-link" aria-label="Direct link to Train on local PC or cloud" title="Direct link to Train on local PC or cloud">‚Äã</a></h2><p>After we are done with annotating the dataset, we need to train the dataset. For training we will introduce two methods. One method will be based online (Google Colab) and the other method will be based on local PC (Linux).</p><p>For the Google Colab training, we will use two methods. In the first method, we will use Ultralytics HUB to upload the dataset, setup training on Colab, monitor the training and grab the trained model. In the second method, we will grab the dataset from Roboflow via Roboflow api, train and download the model from Colab.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="use-google-colab-with-ultralytics-hub">Use Google Colab with Ultralytics HUB<a href="#use-google-colab-with-ultralytics-hub" class="hash-link" aria-label="Direct link to Use Google Colab with Ultralytics HUB" title="Direct link to Use Google Colab with Ultralytics HUB">‚Äã</a></h3><p><a href="https://hub.ultralytics.com" target="_blank" rel="noopener noreferrer">Ultralytics HUB</a> is a platform where you can train your models without having to know a single line of code. Simply upload your data to Ultralytics HUB, train your model and deploy it into the real world! It is fast, simple and easy to use. Anyone can get started!</p><ul><li><p><strong>Step 1.</strong> Visit <a href="https://hub.ultralytics.com" target="_blank" rel="noopener noreferrer">this link</a> to sign up for a free Ultralytics HUB account</p></li><li><p><strong>Step 2.</strong> Enter your credentials and <strong>sign up with email</strong> or sign up directly with a <strong>Google, GitHub or Apple account</strong></p></li></ul><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOv5-2/1.png" class="img_ev3q"></div><p>After you login to Ultralytics HUB, you will see the dashboard as follows</p><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOv5-2/2.png" class="img_ev3q"></div><ul><li><p><strong>Step 3.</strong> Extract the zip file that we downloaded before from Roboflow and put all the included files inside a new folder</p></li><li><p><strong>Step 4.</strong> Make sure your <strong>dataset yaml</strong> and <strong>root folder</strong> (the folder we created before) share the same name. For example, if you name your yaml file as <strong>pinkflowers.yaml</strong>,  the root folder should be named as <strong>pinkflowers</strong>.</p></li><li><p><strong>Step 5.</strong> Open <strong>pinkflowers.yaml</strong> file and edit <strong>train</strong> and <strong>val</strong> directories as follows</p></li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">train: train/images</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">val: valid/images</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>Step 6.</strong> Compress the root folder as a <strong>.zip</strong> and name it the same as the root folder (<strong>pinkflowers.zip</strong> in this example)</li></ul><p>Now we have prepared the dataset which is ready to be uploaded to Ultalytics HUB.</p><ul><li><strong>Step 7.</strong> Click on the <strong>Datasets</strong> tab and click <strong>Upload Dataset</strong></li></ul><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOv5-2/6.jpg" class="img_ev3q"></div><ul><li><strong>Step 8.</strong> Enter a <strong>Name</strong> for the dataset, enter a <strong>Description</strong> if needed, drag and drop the .zip file that we created before under <strong>Dataset</strong> field and click <strong>Upload Dataset</strong></li></ul><div align="center"><img loading="lazy" width="400" src="https://files.seeedstudio.com/wiki/YOLOv5-2/24.png" class="img_ev3q"></div><ul><li><strong>Step 9.</strong> After the datset is uploaded, click on the dataset to view more insights into the dataset</li></ul><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOv5-2/25.png" class="img_ev3q"></div><ul><li><strong>Step 10.</strong> Click on the <strong>Projects</strong> tab and click <strong>Create Project</strong></li></ul><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOv5-2/5.jpg" class="img_ev3q"></div><ul><li><strong>Step 11.</strong> Enter a <strong>Name</strong> for the project, enter a <strong>Description</strong> if needed, add a <strong>cover image</strong> if needed, and click <strong>Create Project</strong></li></ul><div align="center"><img loading="lazy" width="350" src="https://files.seeedstudio.com/wiki/YOLOv5-2/26.png" class="img_ev3q"></div><ul><li><strong>Step 12.</strong> Enter the newly created project and click <strong>Create Model</strong></li></ul><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOv5-2/27.png" class="img_ev3q"></div><ul><li><strong>Step 13.</strong> Enter a <strong>Model name</strong>, choose <strong>YOLOv5n</strong> as the pretrained model, and click <strong>Next</strong></li></ul><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOv5-2/28.png" class="img_ev3q"></div><p><strong>Note:</strong> Usually <strong>YOLOv5n6</strong> is preferred as the pretrained model because it is suitable to be used for edge devices such as the Jetson platform. However, Ultralytics HUB still does not have the support for it. So we use <strong>YOLOv5n</strong> which is a slightly similar model.</p><ul><li><strong>Step 14.</strong> Choose the dataset that we uploaded before and click <strong>Next</strong></li></ul><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOv5-2/29.png" class="img_ev3q"></div><ul><li><strong>Step 15.</strong> Choose <strong>Google Colab</strong> as the training platform and click the <strong>Advanced Options</strong> drop-down menu. Here we can change some settings for training. For example, we will change the number of epochs from 300 to 100 and keep the other settings as they are. Click <strong>Save</strong></li></ul><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOv5-2/30.png" class="img_ev3q"></div><p><strong>Note:</strong> You can also choose <strong>Bring your own agent</strong> if you are planning to perform local training</p><ul><li><strong>Step 16.</strong> Copy the <strong>API key</strong> and click <strong>Open Colab</strong></li></ul><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOv5-2/31.png" class="img_ev3q"></div><ul><li><strong>Step 17.</strong> Replace <strong>MODEL_KEY</strong> with the <strong>API key</strong> that we copied before</li></ul><div align="center"><img loading="lazy" width="700" src="https://files.seeedstudio.com/wiki/YOLOv5-2/16.jpg" class="img_ev3q"></div><ul><li><strong>Step 18.</strong> Click <code>Runtime &gt; Rull All</code> to run all the code cells and start the training process</li></ul><div align="center"><img loading="lazy" width="600" src="https://files.seeedstudio.com/wiki/YOLOv5-2/17.jpg" class="img_ev3q"></div><ul><li><strong>Step 19.</strong> Come back to Ultralytics HUB and click <strong>Done</strong> when it turns blue. You will also see that Colab shows as <strong>Connected</strong>.</li></ul><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOv5-2/32.png" class="img_ev3q"></div><p>Now you will see the training progress on the HUB</p><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOv5-2/33.png" class="img_ev3q"></div><ul><li><strong>Step 20.</strong> After the training is finished, click PyTorch to download the trained model in PyTorch format. PyTorch is the format that we need in order to perform inference on the Jetson device</li></ul><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOv5-2/37.png" class="img_ev3q"></div><p><strong>Note:</strong> You can also export into other formats as well which are displayed under <strong>Formats</strong></p><p>If you go back to Google Colab, you can see more details as follows:</p><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOv5-2/36.png" class="img_ev3q"></div><p>Here the accuracy <code>mAP@.5</code> is about 90% and 99.4% for leaf and flower respectively, while the total accuracy <code>mAP@.5</code> is about 94.7%.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="use-google-colab-with-roboflow-api">Use Google Colab with Roboflow api<a href="#use-google-colab-with-roboflow-api" class="hash-link" aria-label="Direct link to Use Google Colab with Roboflow api" title="Direct link to Use Google Colab with Roboflow api">‚Äã</a></h3><p>Here we use a Google Colaboratory environment to perform training on the cloud. Furthermore, we use Roboflow api within Colab to easily download our dataset.</p><ul><li><strong>Step 1.</strong> Click <a href="https://colab.research.google.com/gist/lakshanthad/645de50b7cc5870f4070b720be770f8b/yolov5-training-for-jetson.ipynb" target="_blank" rel="noopener noreferrer">here</a> to open an already prepared Google Colab workspace and go through the steps mentioned in the workspace</li></ul><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOV5/82.png" class="img_ev3q"></div><p>After the training is done, you will see an output as follows:</p><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOV5/37.png" class="img_ev3q"></div><p>Here the accuracy <code>mAP@.5</code> is about 91.6% and 99.4% for leaf and flower respectively, while the total accuracy <code>mAP@.5</code> is about 95.5%.</p><ul><li><strong>Step 2.</strong> Under <strong>Files</strong> tab, if you navigate to <code>runs/train/exp/weights</code>, you will see a file called <strong>best.pt</strong>. This is the generated model from training. Download this file and copy to your Jetson device because this is the model we are going to use later for inferencing on the Jetson device.</li></ul><div align="center"><img loading="lazy" width="400" src="https://files.seeedstudio.com/wiki/YOLOV5/52.png" class="img_ev3q"></div><h3 class="anchor anchorWithStickyNavbar_LWe7" id="use-local-pc">Use local PC<a href="#use-local-pc" class="hash-link" aria-label="Direct link to Use local PC" title="Direct link to Use local PC">‚Äã</a></h3><p>Here you can use a PC with a Linux OS for training. We have used an Ubuntu 20.04 PC for this wiki.</p><ul><li><strong>Step 1.</strong> Clone the <strong>YOLOv5 repo</strong> and install <strong>requirements.txt</strong> in a <strong>Python&gt;=3.7.0</strong> environment</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">git clone https://github.com/ultralytics/yolov5 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">cd yolov5</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">pip install -r requirements.txt</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>Step 2.</strong> Copy and paste the .zip file that we downloaded before from Roboflow into <strong>yolov5</strong> directory and extract it</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain"># example</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">cp ~/Downloads/pink-flowers.v1i.yolov5pytorch.zip ~/yolov5</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">unzip pink-flowers.v1i.yolov5pytorch.zip</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>Step 3.</strong> Open <strong>data.yaml</strong> file and edit <strong>train</strong> and <strong>val</strong> directories as follows</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">train: train/images</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">val: valid/images</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>Step 4.</strong> Execute the following to start training</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">python3 train.py --data data.yaml --img-size 640 --batch-size -1 --epoch 100 --weights yolov5n6.pt</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Since our dataset is relatively small (~500 images), <strong>transfer learning</strong> is expected to produce better results than training from scratch. Our model was initialized with weights from a pre-trained COCO model, by passing the name of the model (yolov5n6) to the ‚Äòweights‚Äô argument. Here we used <strong>yolov5n6</strong> because it is ideal for edge devices. Here the <strong>image size</strong> is set to <strong>640x640</strong>. We use <strong>batch-size</strong> as <strong>-1</strong> because that will automatically determine the best batch size. However, if there is an error which says &quot;GPU memory not enough&quot;, choose batch size as <strong>32</strong>, or even <strong>16</strong>. You can also change <strong>epoch</strong> according to your preference.  </p><p>After the training is done, you will see an output as follows:</p><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOV5/65.png" class="img_ev3q"></div><p>Here the accuracy <code>mAP@.5</code> is about 90.6% and 99.4% for leaf and flower respectively, while the total accuracy <code>mAP@.5</code> is about 95%.</p><ul><li><strong>Step 5.</strong> If you navigate to <code>runs/train/exp/weights</code>, you will see a file called <strong>best.pt</strong>. This is the generated model from training. Copy and paste this file to your Jetson device because this is the model we are going to use later for inferencing on the Jetson device.</li></ul><div align="center"><img loading="lazy" width="600" src="https://files.seeedstudio.com/wiki/YOLOV5/33.jpg" class="img_ev3q"></div><h2 class="anchor anchorWithStickyNavbar_LWe7" id="inference-on-jetson-device">Inference on Jetson device<a href="#inference-on-jetson-device" class="hash-link" aria-label="Direct link to Inference on Jetson device" title="Direct link to Inference on Jetson device">‚Äã</a></h2><h3 class="anchor anchorWithStickyNavbar_LWe7" id="using-tensorrt">Using TensorRT<a href="#using-tensorrt" class="hash-link" aria-label="Direct link to Using TensorRT" title="Direct link to Using TensorRT">‚Äã</a></h3><p>Now we will use a Jetson device to perform inference (detect objects) on images with the help of the model generated from our training before. Here we will use <a href="https://developer.nvidia.com/tensorrt" target="_blank" rel="noopener noreferrer">NVIDIA TensorRT</a> to increase the inference performance on the Jetson platform</p><ul><li><strong>Step 1.</strong> Access the terminal of Jetson device, install pip and upgrade it</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">sudo apt update</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">sudo apt install -y python3-pip</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">pip3 install --upgrade pip</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>Step 2.</strong> Clone the following repo</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">git clone https://github.com/ultralytics/yolov5</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>Step 3.</strong> Open <strong>requirements.txt</strong></li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">cd yolov5</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">vi requirements.txt</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>Step 4.</strong> Edit the following lines. Here you need to press <strong>i</strong> first to enter editing mode. Press <strong>ESC</strong>, then type <strong>:wq</strong> to save and quit</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">matplotlib==3.2.2</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">numpy==1.19.4</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># torch&gt;=1.7.0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># torchvision&gt;=0.8.1</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p><strong>Note:</strong> We include fixed versions for <strong>matplotlib</strong> and <strong>numpy</strong> to make sure there are no errors when running YOLOv5 later. Also, torch and torchvision are excluded for now because they will be installed later.</p><ul><li><strong>Step 5.</strong> install the below dependency</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">sudo apt install -y libfreetype6-dev</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>Step 6.</strong> Install the necessary packages</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">pip3 install -r requirements.txt</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>Step 7.</strong> Install torch</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">cd ~</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">sudo apt-get install -y libopenblas-base libopenmpi-dev</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">wget https://nvidia.box.com/shared/static/fjtbno0vpo676a25cgvuqc1wty0fkkg6.whl -O torch-1.10.0-cp36-cp36m-linux_aarch64.whl</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">pip3 install torch-1.10.0-cp36-cp36m-linux_aarch64.whl</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>Step 8.</strong> Install torchvision</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">sudo apt install -y libjpeg-dev zlib1g-dev</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">git clone --branch v0.9.0 https://github.com/pytorch/vision torchvision</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">cd torchvision</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">sudo python3 setup.py install </span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>Step 9.</strong> Clone the following repo</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">cd ~</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">git clone https://github.com/wang-xinyu/tensorrtx</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><p><strong>Step 10.</strong> Copy <strong>best.pt</strong> file from previous training into <strong>yolov5</strong> directory</p></li><li><p><strong>Step 11.</strong> Copy <strong>gen_wts.py</strong> from <strong>tensorrtx/yolov5</strong> into <strong>yolov5</strong> directory</p></li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">cp tensorrtx/yolov5/gen_wts.py yolov5</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>Step 12.</strong> Generate <strong>.wts</strong> file from PyTorch with <strong>.pt</strong></li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">cd yolov5</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">python3 gen_wts.py -w best.pt -o best.wts</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>Step 13.</strong> Navigate to <strong>tensorrtx/yolov5</strong></li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">cd ~</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">cd tensorrtx/yolov5</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>Step 14.</strong> Open <strong>yololayer.h</strong> with <strong>vi text editor</strong></li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">vi yololayer.h</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>Step 15.</strong> Change <strong>CLASS_NUM</strong> to the number of classes your model is trained. In our example, it is 2</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">CLASS_NUM = 2</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>Step 16.</strong> Create a new <strong>build</strong> directory and navigate inside</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">mkdir build </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">cd build</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>Step 17.</strong> Copy the previously generated <strong>best.wts</strong> file into this <strong>build</strong> directory</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">cp ~/yolov5/best.wts .</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>Step 18.</strong> Compile it</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">cmake ..</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">make</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>Step 19.</strong> Serialize the model</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">sudo ./yolov5 -s [.wts] [.engine] [n/s/m/l/x/n6/s6/m6/l6/x6 or c/c6 gd gw]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">#example</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">sudo ./yolov5 -s best.wts best.engine n6</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Here we use <strong>n6</strong> because that is recommended for edge devices such as the NVIDIA Jetson platform. However, if you use Ultralytics HUB to set up training, you can only use <strong>n</strong> because <strong>n6</strong> not yet supported by the HUB.</p><ul><li><p><strong>Step 20.</strong> Copy the images that you want the model to detect into a new folder such as <strong>tensorrtx/yolov5/images</strong></p></li><li><p><strong>Step 21.</strong> Deserialize and run inference on the images as follows</p></li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">sudo ./yolov5 -d best.engine images</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>Below is a comparison of inference time running on Jetson Nano vs Jetson Xavier NX.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="jetson-nano">Jetson Nano<a href="#jetson-nano" class="hash-link" aria-label="Direct link to Jetson Nano" title="Direct link to Jetson Nano">‚Äã</a></h4><p>Here quantization is set to FP16</p><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOV5/58.png" class="img_ev3q"></div><p>From the above results, we can take the average as about <strong>47ms</strong>. Converting this value to frames per second: 1000/47 = 21.2766 = <strong>21fps</strong>.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="jetson-xavier-nx">Jetson Xavier NX<a href="#jetson-xavier-nx" class="hash-link" aria-label="Direct link to Jetson Xavier NX" title="Direct link to Jetson Xavier NX">‚Äã</a></h4><p>Here quantization is set to FP16</p><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOV5/59.jpg" class="img_ev3q"></div><p>From the above results, we can take the average as about <strong>20ms</strong>. Converting this value to frames per second: 1000/20 = <strong>50fps</strong>.</p><p>Also, the output images will be as follows with the objects detected:</p><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOV5/55.jpg" class="img_ev3q"></div><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOV5/56.jpg" class="img_ev3q"></div><h3 class="anchor anchorWithStickyNavbar_LWe7" id="using-tensorrt-and-deepstream-sdk">Using TensorRT and DeepStream SDK<a href="#using-tensorrt-and-deepstream-sdk" class="hash-link" aria-label="Direct link to Using TensorRT and DeepStream SDK" title="Direct link to Using TensorRT and DeepStream SDK">‚Äã</a></h3><p>Here we will use <a href="https://developer.nvidia.com/tensorrt" target="_blank" rel="noopener noreferrer">NVIDIA TensorRT</a> along with <a href="https://developer.nvidia.com/deepstream-sdk" target="_blank" rel="noopener noreferrer">NVIDIA DeepStream SDK</a> to perform inference on a video footage</p><ul><li><strong>Step 1.</strong> Make sure you have properly installed all the <strong>SDK Components</strong> and <strong>DeepStream SDK</strong> on the Jetson device. (check <a href="https://wiki.seeedstudio.com/Tutorial-of-A20X-Carrier-Boards" target="_blank" rel="noopener noreferrer">this wiki</a> for a reference on installation)</li></ul><p><strong>Note:</strong> It is recommended to use NVIDIA SDK Manager to install all the SDK components and DeepStream SDK</p><ul><li><strong>Step 2.</strong> Access the terminal of Jetson device, install pip and upgrade it</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">sudo apt update</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">sudo apt install -y python3-pip</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">pip3 install --upgrade pip</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>Step 3.</strong> Clone the following repo</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">git clone https://github.com/ultralytics/yolov5</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>Step 4.</strong> Open <strong>requirements.txt</strong></li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">cd yolov5</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">vi requirements.txt</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>Step 5.</strong> Edit the following lines. Here you need to press <strong>i</strong> first to enter editing mode. Press <strong>ESC</strong>, then type <strong>:wq</strong> to save and quit</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">matplotlib==3.2.2</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">numpy==1.19.4</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># torch&gt;=1.7.0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># torchvision&gt;=0.8.1</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p><strong>Note:</strong> We include fixed versions for <strong>matplotlib</strong> and <strong>numpy</strong> to make sure there are no errors when running YOLOv5 later. Also, torch and torchvision are excluded for now because they will be installed later.</p><ul><li><strong>Step 6.</strong> install the below dependency</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">sudo apt install -y libfreetype6-dev</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>Step 7.</strong> Install the necessary packages</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">pip3 install -r requirements.txt</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>Step 8.</strong> Install torch</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">cd ~</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">sudo apt-get install -y libopenblas-base libopenmpi-dev</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">wget https://nvidia.box.com/shared/static/fjtbno0vpo676a25cgvuqc1wty0fkkg6.whl -O torch-1.10.0-cp36-cp36m-linux_aarch64.whl</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">pip3 install torch-1.10.0-cp36-cp36m-linux_aarch64.whl</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>Step 9.</strong> Install torchvision</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">sudo apt install -y libjpeg-dev zlib1g-dev</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">git clone --branch v0.9.0 https://github.com/pytorch/vision torchvision</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">cd torchvision</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">sudo python3 setup.py install </span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>Step 10.</strong> Clone the following repo</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">cd ~</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">git clone https://github.com/marcoslucianops/DeepStream-Yolo</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>Step 11.</strong> Copy <strong>gen_wts_yoloV5.py</strong> from <strong>DeepStream-Yolo/utils</strong> into <strong>yolov5</strong> directory</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">cp DeepStream-Yolo/utils/gen_wts_yoloV5.py yolov5</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>Step 12.</strong> Inside the yolov5 repo, download <strong>pt file</strong> from YOLOv5 releases (example for YOLOv5s 6.1)</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">cd yolov5</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">wget https://github.com/ultralytics/yolov5/releases/download/v6.1/yolov5s.pt</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>Step 13.</strong> Generate the <strong>cfg</strong> and <strong>wts</strong> files</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">python3 gen_wts_yoloV5.py -w yolov5s.pt</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p><strong>Note</strong>: To change the inference size (defaut: 640)</p><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">-s SIZE</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">--size SIZE</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">-s HEIGHT WIDTH</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">--size HEIGHT WIDTH</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Example for 1280:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">-s 1280</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">or</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">-s 1280 1280</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>Step 14.</strong> Copy the generated <strong>cfg</strong> and <strong>wts</strong> files into the <strong>DeepStream-Yolo</strong> folder</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">cp yolov5s.cfg ~/DeepStream-Yolo</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">cp yolov5s.wts ~/DeepStream-Yolo</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>Step 15.</strong> Open the <strong>DeepStream-Yolo</strong> folder and compile the library</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">cd ~/DeepStream-Yolo</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># For DeepStream 6.1</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">CUDA_VER=11.4 make -C nvdsinfer_custom_impl_Yolo</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># For DeepStream 6.0.1 / 6.0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">CUDA_VER=10.2 make -C nvdsinfer_custom_impl_Yolo</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>Step 16.</strong> Edit the <strong>config_infer_primary_yoloV5.txt</strong> file according to your model</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">[property]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">...</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">custom-network-config=yolov5s.cfg</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">model-file=yolov5s.wts</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">...</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>Step 17.</strong> Edit the <strong>deepstream_app_config</strong> file</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">...</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[primary-gie]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">...</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">config-file=config_infer_primary_yoloV5.txt</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>Step 18.</strong> Run the inference</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">deepstream-app -c deepstream_app_config.txt</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOV5/FP32-yolov5s.gif" class="img_ev3q"></div><p>The above result is running on <strong>Jetson Xavier NX</strong> with <strong>FP32</strong> and <strong>YOLOv5s 640x640</strong>. We can see that the <strong>FPS</strong> is around <strong>30</strong>.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="int8-calibration">INT8 Calibration<a href="#int8-calibration" class="hash-link" aria-label="Direct link to INT8 Calibration" title="Direct link to INT8 Calibration">‚Äã</a></h4><p>If you want to use INT8 precision for inference, you need to follow the steps below</p><ul><li><strong>Step 1.</strong> Install OpenCV</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">sudo apt-get install libopencv-dev</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>Step 2.</strong> Compile/recompile the <strong>nvdsinfer_custom_impl_Yolo</strong> library with OpenCV support</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">cd ~/DeepStream-Yolo</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># For DeepStream 6.1</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">CUDA_VER=11.4 OPENCV=1 make -C nvdsinfer_custom_impl_Yolo</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># For DeepStream 6.0.1 / 6.0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">CUDA_VER=10.2 OPENCV=1 make -C nvdsinfer_custom_impl_Yolo</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><p><strong>Step 3.</strong> For COCO dataset, download the <a href="https://drive.google.com/file/d/1gbvfn7mcsGDRZ_luJwtITL-ru2kK99aK/view?usp=sharing" target="_blank" rel="noopener noreferrer">val2017</a>, extract, and move to <strong>DeepStream-Yolo</strong> folder</p></li><li><p><strong>Step 4.</strong> Make a new directory for calibration images</p></li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">mkdir calibration</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>Step 5.</strong> Run the following to select 1000 random images from COCO dataset to run calibration</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">for jpg in $(ls -1 val2017/*.jpg | sort -R | head -1000); do \</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    cp ${jpg} calibration/; \</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">done</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p><strong>Note:</strong> NVIDIA recommends at least 500 images to get a good accuracy. On this example, 1000 images are chosen to get better accuracy (more images = more accuracy). Higher INT8_CALIB_BATCH_SIZE values will result in more accuracy and faster calibration speed. Set it according to you GPU memory. You can set it from <strong>head -1000</strong>. For example, for 2000 images, <strong>head -2000</strong>. This process can take a long time.</p><ul><li><strong>Step 6.</strong> Create the <strong>calibration.txt</strong> file with all selected images</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">realpath calibration/*jpg &gt; calibration.txt</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>Step 7.</strong> Set environment variables</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">export INT8_CALIB_IMG_PATH=calibration.txt</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">export INT8_CALIB_BATCH_SIZE=1</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>Step 8.</strong> Update the <strong>config_infer_primary_yoloV5.txt</strong> file</li></ul><p>From</p><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">...</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">model-engine-file=model_b1_gpu0_fp32.engine</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">#int8-calib-file=calib.table</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">...</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">network-mode=0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">...</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>To</p><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">...</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">model-engine-file=model_b1_gpu0_int8.engine</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">int8-calib-file=calib.table</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">...</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">network-mode=1</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">...</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>Step 9.</strong> Run the inference</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">deepstream-app -c deepstream_app_config.txt</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOV5/INT8-yolov5s.gif" class="img_ev3q"></div><p>The above result is running on <strong>Jetson Xavier NX</strong> with <strong>INT8</strong> and <strong>YOLOv5s 640x640</strong>. We can see that the <strong>FPS</strong> is around <strong>60</strong>.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="benchmark-results">Benchmark results<a href="#benchmark-results" class="hash-link" aria-label="Direct link to Benchmark results" title="Direct link to Benchmark results">‚Äã</a></h4><p>The following table summarizes how different models perform on <strong>Jetson Xavier NX</strong>.</p><table><thead><tr><th>Model Name</th><th>Precision</th><th>Inference Size</th><th>Inference Time (ms)</th><th>FPS</th></tr></thead><tbody><tr><td rowspan="3">YOLOv5s</td><td>FP32</td><td>320x320</td><td>16.66</td><td>60</td></tr><tr><td>FP32</td><td>640x640</td><td>33.33</td><td>30</td></tr><tr><td>INT8</td><td>640x640</td><td>16.66</td><td>60</td></tr><tr><td>YOLOv5n</td><td>FP32</td><td>640x640</td><td>16.66</td><td>60</td></tr></tbody></table><h2 class="anchor anchorWithStickyNavbar_LWe7" id="comparison-between-using-public-datasets-and-custom-datasets">Comparison between using public datasets and custom datasets<a href="#comparison-between-using-public-datasets-and-custom-datasets" class="hash-link" aria-label="Direct link to Comparison between using public datasets and custom datasets" title="Direct link to Comparison between using public datasets and custom datasets">‚Äã</a></h2><p>Now we will compare the difference between the number of training samples and training time when using public datasets and your own custom datasets</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="number-of-training-samples">Number of training samples<a href="#number-of-training-samples" class="hash-link" aria-label="Direct link to Number of training samples" title="Direct link to Number of training samples">‚Äã</a></h3><h4 class="anchor anchorWithStickyNavbar_LWe7" id="custom-dataset">Custom dataset<a href="#custom-dataset" class="hash-link" aria-label="Direct link to Custom dataset" title="Direct link to Custom dataset">‚Äã</a></h4><p>In this wiki, we collected our plant dataset as a video first and then converted the video into a series of images using Roboflow. Here we obtained 542 images which is a very small dataset when compared with public datasets.</p><div align="center"><img loading="lazy" width="400" src="https://files.seeedstudio.com/wiki/YOLOV5/62.jpg" class="img_ev3q"></div><h4 class="anchor anchorWithStickyNavbar_LWe7" id="public-dataset">Public dataset<a href="#public-dataset" class="hash-link" aria-label="Direct link to Public dataset" title="Direct link to Public dataset">‚Äã</a></h4><p>Public datasets such as <strong>Pascal VOC 2012</strong> and <strong>Microsoft COCO 2017</strong> dataset have around <strong>17112</strong> and <strong>121408</strong> Images repectively.</p><h5 class="anchor anchorWithStickyNavbar_LWe7" id="pascal-voc-2012-dataset">Pascal VOC 2012 dataset<a href="#pascal-voc-2012-dataset" class="hash-link" aria-label="Direct link to Pascal VOC 2012 dataset" title="Direct link to Pascal VOC 2012 dataset">‚Äã</a></h5><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOV5/63.png" class="img_ev3q"></div><h5 class="anchor anchorWithStickyNavbar_LWe7" id="microsoft-coco-2017-dataset">Microsoft COCO 2017 dataset<a href="#microsoft-coco-2017-dataset" class="hash-link" aria-label="Direct link to Microsoft COCO 2017 dataset" title="Direct link to Microsoft COCO 2017 dataset">‚Äã</a></h5><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOV5/64.png" class="img_ev3q"></div><h3 class="anchor anchorWithStickyNavbar_LWe7" id="training-time">Training time<a href="#training-time" class="hash-link" aria-label="Direct link to Training time" title="Direct link to Training time">‚Äã</a></h3><h4 class="anchor anchorWithStickyNavbar_LWe7" id="local-training">Local training<a href="#local-training" class="hash-link" aria-label="Direct link to Local training" title="Direct link to Local training">‚Äã</a></h4><p>The training was done on an NVIDIA GeForce GTX 1660 Super Graphics Card with 6GB memory</p><h5 class="anchor anchorWithStickyNavbar_LWe7" id="custom-dataset-with-local-training">Custom dataset with local training<a href="#custom-dataset-with-local-training" class="hash-link" aria-label="Direct link to Custom dataset with local training" title="Direct link to Custom dataset with local training">‚Äã</a></h5><h6 class="anchor anchorWithStickyNavbar_LWe7" id="540-images-dataset">540 images dataset<a href="#540-images-dataset" class="hash-link" aria-label="Direct link to 540 images dataset" title="Direct link to 540 images dataset">‚Äã</a></h6><p>According to the local training we performed before for the plants, we obtained the following results</p><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOV5/65.png" class="img_ev3q"></div><p>Here it took only <strong>2.2 hours</strong> run 100 epochs. This is comparatively faster than training using public datasets.</p><h6 class="anchor anchorWithStickyNavbar_LWe7" id="240-images-dataset">240 images dataset<a href="#240-images-dataset" class="hash-link" aria-label="Direct link to 240 images dataset" title="Direct link to 240 images dataset">‚Äã</a></h6><p>We reduced the dataset to 240 images and performed training again and obtained the following results</p><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOV5/83.png" class="img_ev3q"></div><p>Here it took only about <strong>1 hour</strong> run 100 epochs. This is comparatively faster than training using public datasets.</p><h5 class="anchor anchorWithStickyNavbar_LWe7" id="pascal-voc-2012-dataset-with-local-training">Pascal VOC 2012 dataset with local training<a href="#pascal-voc-2012-dataset-with-local-training" class="hash-link" aria-label="Direct link to Pascal VOC 2012 dataset with local training" title="Direct link to Pascal VOC 2012 dataset with local training">‚Äã</a></h5><p>We used a Pascal VOC 2012 dataset for the training in this scenario while keeping the same training parameters. We found that it was taking about <strong>50 minutes (0.846 hours * 60)</strong> to run 1 epoch, and therefore we stopped the training on 1 epoch.</p><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOV5/66.png" class="img_ev3q"></div><p>If we calculate the training time for 100 epochs, it would take about <strong>50 * 100 minutes = 5000 minutes = 83 hours</strong> which is much longer than the training time for the custom dataset.</p><h5 class="anchor anchorWithStickyNavbar_LWe7" id="microsoft-coco-2017-dataset-with-local-training">Microsoft COCO 2017 Dataset with local training<a href="#microsoft-coco-2017-dataset-with-local-training" class="hash-link" aria-label="Direct link to Microsoft COCO 2017 Dataset with local training" title="Direct link to Microsoft COCO 2017 Dataset with local training">‚Äã</a></h5><p>We used a Microsoft COCO 2017 dataset for the training in this scenario while keeping the same training parameters. We found that it was estimated to take about <strong>7.5 hours</strong> to run 1 epoch, and therefore we stopped the training before 1 epoch was finished.</p><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOV5/68.png" class="img_ev3q"></div><p>If we calculate the training time for 100 epochs, it would take about <strong>7.5 hours * 100 = 750 hours</strong> which is much longer than the training time for the custom dataset.</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="google-colab-training">Google Colab training<a href="#google-colab-training" class="hash-link" aria-label="Direct link to Google Colab training" title="Direct link to Google Colab training">‚Äã</a></h4><p>The training was done on an NVIDIA Tesla K80 Graphics Card with 12GB memory</p><h5 class="anchor anchorWithStickyNavbar_LWe7" id="custom-dataset-1">Custom dataset<a href="#custom-dataset-1" class="hash-link" aria-label="Direct link to Custom dataset" title="Direct link to Custom dataset">‚Äã</a></h5><h6 class="anchor anchorWithStickyNavbar_LWe7" id="540-images-dataset-1">540 images dataset<a href="#540-images-dataset-1" class="hash-link" aria-label="Direct link to 540 images dataset" title="Direct link to 540 images dataset">‚Äã</a></h6><p>According to the Google Colab training we performed before for the plants with 540 images, we obtained the following results</p><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOV5/37.png" class="img_ev3q"></div><p>Here it took only about <strong>1.3 hours</strong> run 100 epochs. This is also comparatively faster than training using public datasets.</p><h6 class="anchor anchorWithStickyNavbar_LWe7" id="240-images-dataset-1">240 images dataset<a href="#240-images-dataset-1" class="hash-link" aria-label="Direct link to 240 images dataset" title="Direct link to 240 images dataset">‚Äã</a></h6><p>We reduced the dataset to 240 images and performed training again and obtained the following results</p><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOV5/79.png" class="img_ev3q"></div><p>Here it took only about <strong>42 minutes (0.697 hours * 60)</strong> run 100 epochs. This is comparatively faster than training using public datasets.</p><h5 class="anchor anchorWithStickyNavbar_LWe7" id="pascal-voc-2012-dataset-with-google-colab-training">Pascal VOC 2012 dataset with Google Colab training<a href="#pascal-voc-2012-dataset-with-google-colab-training" class="hash-link" aria-label="Direct link to Pascal VOC 2012 dataset with Google Colab training" title="Direct link to Pascal VOC 2012 dataset with Google Colab training">‚Äã</a></h5><p>We used a Pascal VOC 2012 dataset for the training in this scenario while keeping the same training parameters. We found that it was taking about <strong>9 minutes (0.148 hours * 60)</strong> to run 1 epoch, and therefore we stopped the training on 1 epoch.</p><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOV5/67.png" class="img_ev3q"></div><p>If we calculate the training time for 100 epochs, it would take about <strong>9 * 100 minutes = 900 minutes = 15 hours</strong> which is much longer than the training time for the custom dataset.</p><h5 class="anchor anchorWithStickyNavbar_LWe7" id="microsoft-coco-2017-dataset-with-google-colab-training">Microsoft COCO 2017 Dataset with Google Colab training<a href="#microsoft-coco-2017-dataset-with-google-colab-training" class="hash-link" aria-label="Direct link to Microsoft COCO 2017 Dataset with Google Colab training" title="Direct link to Microsoft COCO 2017 Dataset with Google Colab training">‚Äã</a></h5><p>We used a Microsoft COCO 2017 dataset for the training in this scenario while keeping the same training parameters. We found that it was estimated to take about <strong>1.25 hours</strong> to run 1 epoch, and therefore we stopped the training before 1 epoch was finished.</p><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOV5/69.png" class="img_ev3q"></div><p>If we calculate the training time for 100 epochs, it would take about <strong>1.25 hours * 100 = 125 hours</strong> which is much longer than the training time for the custom dataset.</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="number-of-training-samples-and-training-time-summary">Number of training samples and training time summary<a href="#number-of-training-samples-and-training-time-summary" class="hash-link" aria-label="Direct link to Number of training samples and training time summary" title="Direct link to Number of training samples and training time summary">‚Äã</a></h3><table><thead><tr><th>Dataset</th><th>Number of training samples</th><th>Training time on Local PC (GTX 1660 Super)</th><th>Training time on Google Colab (NVIDIA Tesla K80)</th></tr></thead><tbody><tr><td>Custom</td><td>542</td><td>2.2 hours</td><td>1.3 hours</td></tr><tr><td></td><td>240</td><td>1 hour</td><td>42 minutes</td></tr><tr><td>Pascal VOC 2012</td><td>17112</td><td>83 hours</td><td>15 hours</td></tr><tr><td>Microsoft COCO 2017</td><td>121408</td><td>750 hours</td><td>125 hours</td></tr></tbody></table><h2 class="anchor anchorWithStickyNavbar_LWe7" id="pretrained-checkpoints-comparison">Pretrained checkpoints comparison<a href="#pretrained-checkpoints-comparison" class="hash-link" aria-label="Direct link to Pretrained checkpoints comparison" title="Direct link to Pretrained checkpoints comparison">‚Äã</a></h2><p>You can learn more about pretrained checkpoints from the table below. Here we have highlighted our scenario when trained with <strong>Google Colab</strong> and inference done on <strong>Jetson Nano</strong> and <strong>Jetson Xavier NX</strong> with <strong>YOLOv5n6</strong> as the pretrained checkpoint.</p><table><thead><tr><th>Model</th><th>size (pixels)</th><th>mAPval 0.5:0.95</th><th>mAPval 0.5</th><th>Speed CPU b1 (ms)</th><th>Speed V100 b1 (ms)</th><th>Speed V100 b32 (ms)</th><th>Speed Jetson  Nano FP16 (ms)</th><th>Speed Jetson Xavier NX FP16 (ms)</th><th>params (M)</th><th>FLOPs @640 (B)</th></tr></thead><tbody><tr><td>YOLOv5n</td><td>640</td><td>28.0</td><td>45.7</td><td>45</td><td>6.3</td><td>0.6</td><td></td><td></td><td>1.9</td><td>4.5</td></tr><tr><td>YOLOv5s</td><td>640</td><td>37.4</td><td>56.8</td><td>98</td><td>6.4</td><td>0.9</td><td></td><td></td><td>7.2</td><td>16.5</td></tr><tr><td>YOLOv5m</td><td>640</td><td>45.4</td><td>64.1</td><td>224</td><td>8.2</td><td>1.7</td><td></td><td></td><td>21.2</td><td>49.0</td></tr><tr><td>YOLOv5l</td><td>640</td><td>49.0</td><td>67.3</td><td>430</td><td>10.1</td><td>2.7</td><td></td><td></td><td>46.5</td><td>109.1</td></tr><tr><td>YOLOv5x</td><td>640</td><td>50.7</td><td>68.9</td><td>766</td><td>12.1</td><td>4.8</td><td></td><td></td><td>86.7</td><td>205.7</td></tr><tr><td><strong>YOLOv5n6</strong></td><td><strong>640</strong></td><td><strong>71.7</strong></td><td><strong>95.5</strong></td><td><strong>153</strong></td><td><strong>8.1</strong></td><td><strong>2.1</strong></td><td><strong>47</strong></td><td><strong>20</strong></td><td><strong>3.1</strong></td><td><strong>4.6</strong></td></tr><tr><td>YOLOv5s6</td><td>1280</td><td>44.8</td><td>63.7</td><td>385</td><td>8.2</td><td>3.6</td><td></td><td></td><td>12.6</td><td>16.8</td></tr><tr><td>YOLOv5m6</td><td>1280</td><td>51.3</td><td>69.3</td><td>887</td><td>11.1</td><td>6.8</td><td></td><td></td><td>35.7</td><td>50.0</td></tr><tr><td>YOLOv5l6</td><td>1280</td><td>53.7</td><td>71.3</td><td>1784</td><td>15.8</td><td>10.5</td><td></td><td></td><td>76.8</td><td>111.4</td></tr><tr><td>YOLOv5x6 + <!-- -->[TTA]</td><td>1280 1536</td><td>55.0 55.8</td><td>72.7 72.7</td><td>3136 -</td><td>26.2 -</td><td>19.4 -</td><td></td><td></td><td>140.7 -</td><td>209.8 -</td></tr></tbody></table><blockquote><p>Reference: <a href="https://github.com/ultralytics/yolov5" target="_blank" rel="noopener noreferrer">YOLOv5 GitHub</a></p></blockquote><h2 class="anchor anchorWithStickyNavbar_LWe7" id="bonus-applications">Bonus Applications<a href="#bonus-applications" class="hash-link" aria-label="Direct link to Bonus Applications" title="Direct link to Bonus Applications">‚Äã</a></h2><p>Since all the steps that we explained above are common for any type of object detection application, you only need to change the dataset for your own object detection application!</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="road-signs-detection">Road signs detection<a href="#road-signs-detection" class="hash-link" aria-label="Direct link to Road signs detection" title="Direct link to Road signs detection">‚Äã</a></h3><p>Here we used the <a href="https://universe.roboflow.com/usmanchaudhry622-gmail-com/traffic-and-road-signs/1" target="_blank" rel="noopener noreferrer">road signs dataset</a> from Roboflow and performed inference on NVIDIA Jetson!</p><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOv5-2/thumb-2.png" class="img_ev3q"></div><h3 class="anchor anchorWithStickyNavbar_LWe7" id="wildfire-smoke-detection">Wildfire smoke detection<a href="#wildfire-smoke-detection" class="hash-link" aria-label="Direct link to Wildfire smoke detection" title="Direct link to Wildfire smoke detection">‚Äã</a></h3><p>Here we used <a href="https://public.roboflow.com/object-detection/wildfire-smoke" target="_blank" rel="noopener noreferrer">wildfire smoke dataset</a> from Roboflow and performed inference on NVIDIA Jetson!</p><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/Roboflow/20.jpg" class="img_ev3q"></div><h2 class="anchor anchorWithStickyNavbar_LWe7" id="resources">Resources<a href="#resources" class="hash-link" aria-label="Direct link to Resources" title="Direct link to Resources">‚Äã</a></h2><ul><li><p><strong>[Web Page]</strong> <a href="https://docs.ultralytics.com" target="_blank" rel="noopener noreferrer">YOLOv5 Documentation</a></p></li><li><p><strong>[Web Page]</strong> <a href="https://ultralytics.com/hub" target="_blank" rel="noopener noreferrer">Ultralytics HUB</a></p></li><li><p><strong>[Web Page]</strong> <a href="https://docs.roboflow.com" target="_blank" rel="noopener noreferrer">Roboflow Documentation</a></p></li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="tech-support--product-discussion">Tech Support &amp; Product Discussion<a href="#tech-support--product-discussion" class="hash-link" aria-label="Direct link to Tech Support &amp; Product Discussion" title="Direct link to Tech Support &amp; Product Discussion">‚Äã</a></h2><p>Thank you for choosing our products! We are here to provide you with different support to ensure that your experience with our products is as smooth as possible. We offer several communication channels to cater to different preferences and needs.</p><div class="button_tech_support_container"><a href="https://forum.seeedstudio.com/" target="_blank" rel="noopener noreferrer" class="button_forum"></a><a href="https://www.seeedstudio.com/contacts" target="_blank" rel="noopener noreferrer" class="button_email"></a></div><div class="button_tech_support_container"><a href="https://discord.gg/eWkprNDMU7" target="_blank" rel="noopener noreferrer" class="button_discord"></a><a href="https://github.com/Seeed-Studio/wiki-documents/discussions/69" target="_blank" rel="noopener noreferrer" class="button_discussion"></a></div></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-tags-row row margin-bottom--sm"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/tags/data-label/">Data Label</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/tags/ai-model-train/">AI model train</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/tags/ai-model-deploy/">AI model deploy</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/tags/roboflow/">Roboflow</a></li></ul></div></div><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/Seeed-Studio/wiki-documents/blob/docusaurus-version/docs/Edge/NVIDIA_Jetson/Application/Computer_Vision/YOLOv5-Object-Detection-Jetson.md" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_vwxv"><span class="theme-last-updated">Last updated<!-- --> on <b><time datetime="2023-01-04T00:00:00.000Z">Jan 4, 2023</time></b> by <b>w0x7ce</b></span></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/Traffic-Management-DeepStream-SDK/"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Traffic Management DeepStream SDK</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/YOLOv8-DeepStream-TRT-Jetson/"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Deploy YOLOv8 with TensorRT and DeepStream SDK</div></a></nav></div><div>Loading Comments...</div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#introduction" class="table-of-contents__link toc-highlight">Introduction</a></li><li><a href="#what-is-yolov5" class="table-of-contents__link toc-highlight">What is YOLOv5?</a></li><li><a href="#what-is-few-shot-object-detection" class="table-of-contents__link toc-highlight">What is few-shot object detection?</a></li><li><a href="#hardware-supported" class="table-of-contents__link toc-highlight">Hardware supported</a></li><li><a href="#prerequisites" class="table-of-contents__link toc-highlight">Prerequisites</a></li><li><a href="#getting-started" class="table-of-contents__link toc-highlight">Getting started</a></li><li><a href="#collect-dataset-or-use-publically-available-dataset" class="table-of-contents__link toc-highlight">Collect dataset or use publically available dataset</a><ul><li><a href="#collect-dataset-manually" class="table-of-contents__link toc-highlight">Collect dataset manually</a></li><li><a href="#use-publicly-available-dataset" class="table-of-contents__link toc-highlight">Use publicly available dataset</a></li></ul></li><li><a href="#annotate-dataset-using-roboflow" class="table-of-contents__link toc-highlight">Annotate dataset using Roboflow</a></li><li><a href="#train-on-local-pc-or-cloud" class="table-of-contents__link toc-highlight">Train on local PC or cloud</a><ul><li><a href="#use-google-colab-with-ultralytics-hub" class="table-of-contents__link toc-highlight">Use Google Colab with Ultralytics HUB</a></li><li><a href="#use-google-colab-with-roboflow-api" class="table-of-contents__link toc-highlight">Use Google Colab with Roboflow api</a></li><li><a href="#use-local-pc" class="table-of-contents__link toc-highlight">Use local PC</a></li></ul></li><li><a href="#inference-on-jetson-device" class="table-of-contents__link toc-highlight">Inference on Jetson device</a><ul><li><a href="#using-tensorrt" class="table-of-contents__link toc-highlight">Using TensorRT</a><ul><li><a href="#jetson-nano" class="table-of-contents__link toc-highlight">Jetson Nano</a></li><li><a href="#jetson-xavier-nx" class="table-of-contents__link toc-highlight">Jetson Xavier NX</a></li></ul></li><li><a href="#using-tensorrt-and-deepstream-sdk" class="table-of-contents__link toc-highlight">Using TensorRT and DeepStream SDK</a><ul><li><a href="#int8-calibration" class="table-of-contents__link toc-highlight">INT8 Calibration</a></li><li><a href="#benchmark-results" class="table-of-contents__link toc-highlight">Benchmark results</a></li></ul></li></ul></li><li><a href="#comparison-between-using-public-datasets-and-custom-datasets" class="table-of-contents__link toc-highlight">Comparison between using public datasets and custom datasets</a><ul><li><a href="#number-of-training-samples" class="table-of-contents__link toc-highlight">Number of training samples</a><ul><li><a href="#custom-dataset" class="table-of-contents__link toc-highlight">Custom dataset</a></li><li><a href="#public-dataset" class="table-of-contents__link toc-highlight">Public dataset</a><ul><li><a href="#pascal-voc-2012-dataset" class="table-of-contents__link toc-highlight">Pascal VOC 2012 dataset</a></li><li><a href="#microsoft-coco-2017-dataset" class="table-of-contents__link toc-highlight">Microsoft COCO 2017 dataset</a></li></ul></li></ul></li><li><a href="#training-time" class="table-of-contents__link toc-highlight">Training time</a><ul><li><a href="#local-training" class="table-of-contents__link toc-highlight">Local training</a><ul><li><a href="#custom-dataset-with-local-training" class="table-of-contents__link toc-highlight">Custom dataset with local training</a></li><li><a href="#pascal-voc-2012-dataset-with-local-training" class="table-of-contents__link toc-highlight">Pascal VOC 2012 dataset with local training</a></li><li><a href="#microsoft-coco-2017-dataset-with-local-training" class="table-of-contents__link toc-highlight">Microsoft COCO 2017 Dataset with local training</a></li></ul></li><li><a href="#google-colab-training" class="table-of-contents__link toc-highlight">Google Colab training</a><ul><li><a href="#custom-dataset-1" class="table-of-contents__link toc-highlight">Custom dataset</a></li><li><a href="#pascal-voc-2012-dataset-with-google-colab-training" class="table-of-contents__link toc-highlight">Pascal VOC 2012 dataset with Google Colab training</a></li><li><a href="#microsoft-coco-2017-dataset-with-google-colab-training" class="table-of-contents__link toc-highlight">Microsoft COCO 2017 Dataset with Google Colab training</a></li></ul></li></ul></li><li><a href="#number-of-training-samples-and-training-time-summary" class="table-of-contents__link toc-highlight">Number of training samples and training time summary</a></li></ul></li><li><a href="#pretrained-checkpoints-comparison" class="table-of-contents__link toc-highlight">Pretrained checkpoints comparison</a></li><li><a href="#bonus-applications" class="table-of-contents__link toc-highlight">Bonus Applications</a><ul><li><a href="#road-signs-detection" class="table-of-contents__link toc-highlight">Road signs detection</a></li><li><a href="#wildfire-smoke-detection" class="table-of-contents__link toc-highlight">Wildfire smoke detection</a></li></ul></li><li><a href="#resources" class="table-of-contents__link toc-highlight">Resources</a></li><li><a href="#tech-support--product-discussion" class="table-of-contents__link toc-highlight">Tech Support &amp; Product Discussion</a></li></ul></div></div></div></div></main></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Navigation</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/Getting_Started/">Getting Started</a></li><li class="footer__item"><a class="footer__link-item" href="/Sensor_Network/">Sensor and Sensing</a></li><li class="footer__item"><a class="footer__link-item" href="/Network/">Network</a></li><li class="footer__item"><a class="footer__link-item" href="/Edge_Computing/">Edge Computing</a></li><li class="footer__item"><a class="footer__link-item" href="/Cloud/">Cloud</a></li><li class="footer__item"><a class="footer__link-item" href="/Solutions/">Solutions</a></li></ul></div><div class="col footer__col"><div class="footer__title">Ecosystem</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://discord.com/invite/QqMgVwHT3X" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord</a></li><li class="footer__item"><a href="https://project.seeedstudio.com/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Project Hub</a></li><li class="footer__item"><a href="https://www.seeedstudio.com/ecosystem/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Partners</a></li><li class="footer__item"><a href="https://www.seeedstudio.com/distributors.html" target="_blank" rel="noopener noreferrer" class="footer__link-item">Distributors</a></li></ul></div><div class="col footer__col"><div class="footer__title">Quick Guide</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://www.seeedstudio.com/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Bazzar</a></li><li class="footer__item"><a href="https://www.seeedstudio.com/get_help/HowToGetHelp" target="_blank" rel="noopener noreferrer" class="footer__link-item">How to get help</a></li><li class="footer__item"><a href="https://support.seeedstudio.com/knowledgebase" target="_blank" rel="noopener noreferrer" class="footer__link-item">FAQs</a></li><li class="footer__item"><a href="https://forum.seeedstudio.com/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Forum</a></li><li class="footer__item"><a href="https://www.seeedstudio.com/get_help/TechnicalSupport" target="_blank" rel="noopener noreferrer" class="footer__link-item">Technical Support</a></li></ul></div><div class="col footer__col"><div class="footer__title">Company</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://www.seeedstudio.com/about-us/" target="_blank" rel="noopener noreferrer" class="footer__link-item">About Seeed</a></li><li class="footer__item"><a href="https://www.seeedstudio.com/join-us/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Join us</a></li><li class="footer__item"><a href="https://www.seeedstudio.com/contacts" target="_blank" rel="noopener noreferrer" class="footer__link-item">Contact Us</a></li><li class="footer__item"><a href="https://www.seeedstudio.com/blog/2020/04/22/seeed-in-the-news/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Press</a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright ¬© 2024 Seeed Studio, Inc. Built with Docusaurus.</div></div></div></footer></div>
<script src="/assets/js/runtime~main.2b86bf0f.js"></script>
<script src="/assets/js/main.c695d726.js"></script>
</body>
</html>