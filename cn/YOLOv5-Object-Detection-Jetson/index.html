<!doctype html>
<html lang="en-US" dir="ltr" class="docs-wrapper docs-doc-page docs-version-current plugin-docs plugin-id-default docs-doc-id-zh-CN/Edge/NVIDIA_Jetson/Application/Computer_Vision/YOLOv5-Object-Detection-Jetson" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v2.4.3">
<title data-rh="true">使用YOLOv5和Roboflow进行少样本目标检测 | Seeed Studio Wiki</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://wiki.seeedstudio.com/cn/YOLOv5-Object-Detection-Jetson/"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="使用YOLOv5和Roboflow进行少样本目标检测 | Seeed Studio Wiki"><meta data-rh="true" name="description" content="使用YOLOv5和Roboflow进行少样本目标检测"><meta data-rh="true" property="og:description" content="使用YOLOv5和Roboflow进行少样本目标检测"><meta data-rh="true" property="og:image" content="https://files.seeedstudio.com/wiki/wiki-platform/S-tempor.png"><meta data-rh="true" name="twitter:image" content="https://files.seeedstudio.com/wiki/wiki-platform/S-tempor.png"><link data-rh="true" rel="icon" href="/img/S.png"><link data-rh="true" rel="canonical" href="https://wiki.seeedstudio.com/cn/YOLOv5-Object-Detection-Jetson/"><link data-rh="true" rel="alternate" href="https://wiki.seeedstudio.com/cn/YOLOv5-Object-Detection-Jetson/" hreflang="en-US"><link data-rh="true" rel="alternate" href="https://wiki.seeedstudio.com/cn/YOLOv5-Object-Detection-Jetson/" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Seeed Studio Wiki RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Seeed Studio Wiki Atom Feed">

<link rel="preconnect" href="https://www.googletagmanager.com">
<script>window.dataLayer=window.dataLayer||[]</script>
<script>!function(e,t,a,n,g){e[n]=e[n]||[],e[n].push({"gtm.start":(new Date).getTime(),event:"gtm.js"});var m=t.getElementsByTagName(a)[0],r=t.createElement(a);r.async=!0,r.src="https://www.googletagmanager.com/gtm.js?id=GTM-M4JG2HVB",m.parentNode.insertBefore(r,m)}(window,document,"script","dataLayer")</script>


<link rel="icon" href="/img/S.png">
<link rel="manifest" href="/manifest.json">
<meta name="theme-color" content="rgb(37, 194, 160)">


<link rel="search" type="application/opensearchdescription+xml" title="Seeed Studio Wiki" href="/opensearch.xml">
<script src="https://viewer.altium.com/client/static/js/embed.js" async></script>
<script src="/js/custom.js" async></script><link rel="stylesheet" href="/assets/css/styles.f264e8be.css">
<link rel="preload" href="/assets/js/runtime~main.b0a22fb9.js" as="script">
<link rel="preload" href="/assets/js/main.df7d386f.js" as="script">
</head>
<body class="navigation-with-keyboard">
<noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-M4JG2HVB" height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>

<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}return t}()||function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"dark")}(),document.documentElement.setAttribute("data-announcement-bar-initially-dismissed",function(){try{return"true"===localStorage.getItem("docusaurus.announcement.dismiss")}catch(t){}return!1}())</script><div id="__docusaurus">
<div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><div class="announcementBar_mb4j" style="background-color:#013949;color:#FFFFFF" role="banner"><div class="content_knG7 announcementBarContent_xLdY">Building Sustainable Growth, Strengthening Local Partnerships. Join   the <a target="_blank" href="https://wiki.seeedstudio.com/ranger/">Seeed Studio Ranger Program</a> now! </div></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/Getting_Started/"><div class="navbar__logo"><img src="https://files.seeedstudio.com/wiki/wiki-platform/SeeedStudio.png" alt="Seeed Studio" class="themedImage_ToTc themedImage--light_HNdA navbar_logo_items"><img src="https://files.seeedstudio.com/wiki/wiki-platform/seeed_white_logo.png" alt="Seeed Studio" class="themedImage_ToTc themedImage--dark_i4oU navbar_logo_items"></div></a><div class="navbar__item dropdown dropdown--hoverable"><a class="navbar__link navbar_dorp_items" aria-haspopup="true" aria-expanded="false" role="button" href="/Getting_Started/">Getting Started</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/Sensor_Network/">Sensor and Sensing</a></li><li><a class="dropdown__link" href="/Network/">Networking</a></li><li><a class="dropdown__link" href="/Edge_Computing/">Edge Computing</a></li><li><a class="dropdown__link" href="/Cloud/">Cloud</a></li></ul></div><div class="navbar__item dropdown dropdown--hoverable"><a class="navbar__link navbar_dorp_items" aria-haspopup="true" aria-expanded="false" role="button" href="/topicintroduction/">Technology</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/tinyml_topic/">TinyML</a></li><li><a class="dropdown__link" href="/ModelAssistant_Introduce_Overview/">SenseCraft Model Assistant</a></li><li><a class="dropdown__link" href="/home_assistant_topic/">Home Assistant</a></li><li><a class="dropdown__link" href="/open_source_topic/">Open Source</a></li><li><a class="dropdown__link" href="/edge_ai_topic/">Edge AI</a></li><li><a class="dropdown__link" href="/cn/Getting_Started/">矽递科技 Wiki 文档平台（测试）</a></li></ul></div><div class="navbar__item dropdown dropdown--hoverable"><a class="navbar__link navbar_dorp_items" aria-haspopup="true" aria-expanded="false" role="button" href="/knowledgebase/">FAQs</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/Jetson_FAQ/">NVIDIA Jetson Series</a></li><li><a class="dropdown__link" href="/XIAO_FAQ/">Seeed Studio XIAO Series</a></li><li><a class="dropdown__link" href="/reComputer_R1000_FAQ/">reComputer R1000 Series</a></li><li><a class="dropdown__link" href="/reTerminal-new_FAQ/">reTerminal</a></li><li><a class="dropdown__link" href="/FAQs_For_openWrt/">reRouter</a></li><li><a class="dropdown__link" href="/ODYSSEY_FAQ/">Odyssey</a></li><li><a class="dropdown__link" href="/wio_terminal_faq/">Wio Terminal</a></li><li><hr style="margin: 8px 0;"></li><li><a href="https://discord.com/invite/eWkprNDMU7" target="_blank" rel="noopener noreferrer" class="dropdown__link">Discord<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li><a href="https://www.seeedstudio.com/contacts" target="_blank" rel="noopener noreferrer" class="dropdown__link">Email<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li><a href="https://forum.seeedstudio.com/" target="_blank" rel="noopener noreferrer" class="dropdown__link">Forum<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li><a href="https://github.com/Seeed-Studio/wiki-documents/discussions/69" target="_blank" rel="noopener noreferrer" class="dropdown__link">Have Suggestions?<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="navbar__item dropdown dropdown--hoverable"><a class="navbar__link navbar_dorp_items" aria-haspopup="true" aria-expanded="false" role="button" href="/ranger/">Rangers</a><ul class="dropdown__menu"><li><a class="dropdown__link" href="/ranger/">Rangers</a></li><li><a href="https://github.com/orgs/Seeed-Studio/projects/6?pane=issue&amp;itemId=30957479" target="_blank" rel="noopener noreferrer" class="dropdown__link">Contributors(GitHub)<svg width="12" height="12" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="navbar__items navbar__items--right"><a href="https://www.seeedstudio.com/" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link navbar_doc_right_items">Bazaar 🛍️</a><a href="https://wiki-gpt.seeedstudio.com/chat" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link navbar_doc_right_items">AI Bot 🤖️</a><a href="https://sensecraft.seeed.cc/ai/#/home" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link navbar_doc_right_items">SenseCraft AI</a><a href="https://sensecraft.seeed.cc/ai/#/home" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-SSCMA"></a><a href="https://github.com/Seeed-Studio/wiki-documents" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link header-github-link" aria-label="GitHub repository"></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently dark mode)" aria-label="Switch between dark and light mode (currently dark mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="searchBox_ZlJk"><button type="button" class="DocSearch DocSearch-Button" aria-label="Search"><span class="DocSearch-Button-Container"><svg width="20" height="20" class="DocSearch-Search-Icon" viewBox="0 0 20 20"><path d="M14.386 14.386l4.0877 4.0877-4.0877-4.0877c-2.9418 2.9419-7.7115 2.9419-10.6533 0-2.9419-2.9418-2.9419-7.7115 0-10.6533 2.9418-2.9419 7.7115-2.9419 10.6533 0 2.9419 2.9418 2.9419 7.7115 0 10.6533z" stroke="currentColor" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg><span class="DocSearch-Button-Placeholder">Search</span></span><span class="DocSearch-Button-Keys"></span></button></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0 docsWrapper_BCFX"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docPage__5DB"><aside class="theme-doc-sidebar-container docSidebarContainer_b6E3"><div class="sidebarViewport_Xe31"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG menuWithAnnouncementBar_GW3s"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/cn/Getting_Started/">矽递科技 Wiki 文档平台</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item sideboard_calss"><a class="menu__link" href="/cn/Grove_System/">Grove</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/cn/grove_vision_ai_v2/">Grove 传感器</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/cn/Grove_Accessories_Intro/">Grove 配件</a><button aria-label="Toggle the collapsible sidebar category &#x27;Grove 配件&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item sideboard_calss"><a class="menu__link" href="/cn/SeeedStudio_XIAO_Series_Introduction/">XIAO 拇指开发板</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/cn/Seeeduino-XIAO/">XIAO SAMD21</a><button aria-label="Toggle the collapsible sidebar category &#x27;XIAO SAMD21&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/cn/XIAO-RP2040/">XIAO RP2040</a><button aria-label="Toggle the collapsible sidebar category &#x27;XIAO RP2040&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/cn/XIAO_BLE/">XIAO nRF52840 (Sense)</a><button aria-label="Toggle the collapsible sidebar category &#x27;XIAO nRF52840 (Sense)&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/cn/XIAO_ESP32C3_Getting_Started/">XIAO ESP32C3</a><button aria-label="Toggle the collapsible sidebar category &#x27;XIAO ESP32C3&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/cn/xiao_esp32s3_getting_started/">XIAO ESP32S3 (Sense)</a><button aria-label="Toggle the collapsible sidebar category &#x27;XIAO ESP32S3 (Sense)&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/cn/get_start_round_display/">XIAO 的兼容扩展板</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/cn/XIAO-Kit-Courses/">基于 XIAO 的初学者套件</a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/cn/xiao_topic_page/">XIAO 系列教程和项目合集</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/cn/XIAO_FAQ/">XIAO 开发板常见问题</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item sideboard_calss"><a class="menu__link" href="/cn/reComputer_Intro/">NVIDIA Jetson 套件</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/cn/reComputer_Intro/">reComputer 英伟达系列</a><button aria-label="Toggle the collapsible sidebar category &#x27;reComputer 英伟达系列&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist" aria-expanded="false" href="/cn/Generative_AI_Intro/">生成式人工智能应用</a><button aria-label="Toggle the collapsible sidebar category &#x27;生成式人工智能应用&#x27;" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" aria-expanded="true" href="/cn/How_to_Train_and_Deploy_YOLOv8_on_reComputer/">计算机视觉应用</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/cn/How_to_Train_and_Deploy_YOLOv8_on_reComputer/">如何在reComputer上训练和部署YOLOv8</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/cn/Jetson-Nano-MaskCam/">口罩相机 - 基于Jetson Nano的人群口罩使用监测</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/cn/Security_Scan/">刀具检测：基于reComputer部署在Triton推理服务器上的物体检测模型</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/cn/reComputer_Jetson_Series_Projects/">英伟达 Jetson 官方项目</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/cn/Traffic-Management-DeepStream-SDK/">基于 DeepStream SDK的智能交通管理系统</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/cn/YOLOv5-Object-Detection-Jetson/">使用YOLOv5和Roboflow进行少样本目标检测</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/cn/YOLOv8-DeepStream-TRT-Jetson/">在NVIDIA Jetson上使用TensorRT和DeepStream SDK部署YOLOv8</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/cn/YOLOv8-TRT-Jetson/">在NVIDIA Jetson上使用TensorRT部署YOLOv8</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/cn/train_and_deploy_a_custom_classification_model_with_yolov8/">使用 YOLOv8 训练和部署自定义分类模型</a></li></ul></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item sideboard_calss"><a class="menu__link" href="/cn/Wio_Terminal_Intro/">Wio Terminal</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/cn/Wio-Terminal-Getting-Started-test/">Wio Terminal入门教程</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/cn/Wio-Terminal-CircuitPython/">Wio Terminal上的CircuitPython</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/cn/Software-FreeRTOS/">Wio Terminal上的FreeRTOS</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/cn/wio_terminal_faq/">Wio Terminal 常见问题解答</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/cn/Wio-Terminal-LCD-Overview/">硬件概述</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/cn/Connect-Wio-Terminal-to-Microsoft-Azure-IoT-Central/">应用</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/cn/Wio-Terminal-Battery-Chassis/">扩展板</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/cn/Wio-Terminal-TinyML-Kit-Course/">课程套件</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/cn/Wio-Terminal-Firmware/">教程</a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item sideboard_calss"><a class="menu__link" href="/cn/Quantum-Mini-Linux-Development-Kit/">夸克(Quark)迷你开发者套件</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item sideboard_calss"><a class="menu__link" href="/cn/mmwave_radar_Intro/">毫米波雷达传感器</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/cn/mmwave_for_xiao/">用于XIAO的毫米波</a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--sublist-caret" aria-expanded="false" href="/cn/mmwave_human_detection_kit/">毫米波套件</a></div></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/cn/Radar_MR24BSD1/">24GHz 毫米波传感器 - 睡眠呼吸监测</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/cn/Radar_MR24FDB1/">24GHz毫米波传感器 - 人体跌倒检测传感器</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/cn/Radar_MR24HPB1/">24GHz 毫米波传感器 - 人体静态存在模块</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/cn/Radar_MR24HPC1/">24GHz毫米波传感器 - 人体静态存在模块精简版</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/cn/Radar_MR60BHA1/">60GHz毫米波传感器 - 人体静态睡眠呼吸监测</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/cn/Radar_MR60FDA1/">60GHz毫米波传感器 - 跌倒检测模块专业版</a></li></ul></nav><button type="button" title="Collapse sidebar" aria-label="Collapse sidebar" class="button button--secondary button--outline collapseSidebarButton_PEFL"><svg width="20" height="20" aria-hidden="true" class="collapseSidebarButtonIcon_kv0_"><g fill="#7a7a7a"><path d="M9.992 10.023c0 .2-.062.399-.172.547l-4.996 7.492a.982.982 0 01-.828.454H1c-.55 0-1-.453-1-1 0-.2.059-.403.168-.551l4.629-6.942L.168 3.078A.939.939 0 010 2.528c0-.548.45-.997 1-.997h2.996c.352 0 .649.18.828.45L9.82 9.472c.11.148.172.347.172.55zm0 0"></path><path d="M19.98 10.023c0 .2-.058.399-.168.547l-4.996 7.492a.987.987 0 01-.828.454h-3c-.547 0-.996-.453-.996-1 0-.2.059-.403.168-.551l4.625-6.942-4.625-6.945a.939.939 0 01-.168-.55 1 1 0 01.996-.997h3c.348 0 .649.18.828.45l4.996 7.492c.11.148.168.347.168.55zm0 0"></path></g></svg></button></div></div></aside><main class="docMainContainer_gTbr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_z5aJ"><div class="docItemContainer_c0TR"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">计算机视觉应用</span><meta itemprop="position" content="1"></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">使用YOLOv5和Roboflow进行少样本目标检测</span><meta itemprop="position" content="2"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><h1>使用YOLOv5和Roboflow进行少样本目标检测</h1><h2 class="anchor anchorWithStickyNavbar_LWe7" id="介绍">介绍<a href="#介绍" class="hash-link" aria-label="Direct link to 介绍" title="Direct link to 介绍">​</a></h2><p><a href="https://docs.ultralytics.com" target="_blank" rel="noopener noreferrer">YOLO</a> 是现有最著名的目标检测算法之一。它只需要<strong>少量样本进行训练</strong>，同时提供<strong>更快的训练时间</strong>和<strong>高精度</strong>。我们将逐一演示这些特点，并逐步解释完整的机器学习流程，其中你可以通过在边缘设备（如<strong>NVIDIA Jetson平台</strong>）上运行训练模型来使用训练数据进行目标检测，具体流程其中包括 <strong>收集数据、标记数据、训练数据和检测对象</strong>。同时，我们还将比较使用自定义数据集和公共数据集之间的差异。 </p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="什么是-yolov5">什么是 YOLOv5?<a href="#什么是-yolov5" class="hash-link" aria-label="Direct link to 什么是 YOLOv5?" title="Direct link to 什么是 YOLOv5?">​</a></h2><p>YOLO 是 ‘You Only Look Once’的缩写。 它是一种实时检测和识别图像中各种对象的算法。。 Ultralytics的 <a href="https://ultralytics.com/yolov5" target="_blank" rel="noopener noreferrer">YOLOv5</a> 是YOLO的版本之一，其现在是基于PyTorch框架。</p><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOV5/YOLOv5_banner.jpg" class="img_ev3q"></div><h2 class="anchor anchorWithStickyNavbar_LWe7" id="什么是少样本目标检测">什么是少样本目标检测？<a href="#什么是少样本目标检测" class="hash-link" aria-label="Direct link to 什么是少样本目标检测？" title="Direct link to 什么是少样本目标检测？">​</a></h2><p>传统上，如果你想训练机器学习模型，你会使用像Pascal VOC 2012数据集之类的公共数据集，其中大约包含17112张图像。然而，我们将使用迁移学习来实现用YOLOv5进行少样本目标检测，只需要非常少的训练样本。我们将在本Wiki中演示这一点。</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="硬件支持">硬件支持<a href="#硬件支持" class="hash-link" aria-label="Direct link to 硬件支持" title="Direct link to 硬件支持">​</a></h2><p>YOLOv5受以下硬件支持：</p><ul><li><p>NVIDIA官方的开发套件：</p><ul><li>NVIDIA® Jetson Nano开发套件</li><li>NVIDIA® Jetson Xavier NX开发套件</li><li>NVIDIA® Jetson AGX Xavier开发套件</li><li>NVIDIA® Jetson TX2开发套件</li></ul></li><li><p>NVIDIA官方的SoMs:</p><ul><li>NVIDIA® Jetson Nano模块</li><li>NVIDIA® Jetson Xavier NX模块</li><li>NVIDIA® Jetson TX2 NX模块</li><li>NVIDIA® Jetson TX2模块</li><li>NVIDIA® Jetson AGX Xavier模块</li></ul></li><li><p>Seeed推出的载板产品：</p><ul><li>Jetson Mate</li><li>Jetson SUB Mini PC</li><li>Jetson Xavier AGX H01 Kit</li><li>A203载板</li><li>A203 (版本2)载板</li><li>A205载板</li><li>A206载板</li></ul></li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="先决条件">先决条件<a href="#先决条件" class="hash-link" aria-label="Direct link to 先决条件" title="Direct link to 先决条件">​</a></h2><ul><li><p>以上任何一款Jetson设备都可以安装最新的JetPack v4.6.1，包括所有的SDK组件 (点击 <a href="https://wiki.seeedstudio.com/reComputer_J1020_A206_Flash_JetPack/" target="_blank" rel="noopener noreferrer"> wiki</a> 参考进行安装)</p></li><li><p>主机 PC</p><ul><li>本地训练需要使用Linux PC（最好是Ubuntu）</li><li>云端训练可以在任何操作系统的PC上进行</li></ul></li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="入门">入门<a href="#入门" class="hash-link" aria-label="Direct link to 入门" title="Direct link to 入门">​</a></h2><p>在像Jetson平台这样的边缘设备上运行第一个物体检测项目只需要四个主要步骤！</p><ol><li><p>收集数据集或使用公开可用的数据集</p><ul><li>手动收集数据集</li><li>使用公开可用的数据集</li></ul></li><li><p>使用Roboflow进行数据集注释</p></li><li><p>在本地PC或云端训练</p><ul><li>在本地PC（Linux）上训练</li><li>在Google Colab上训练</li></ul></li><li><p>在Jetson设备上进行推理（inference）</p></li></ol><h2 class="anchor anchorWithStickyNavbar_LWe7" id="收集数据集或使用公开可用的数据集">收集数据集或使用公开可用的数据集<a href="#收集数据集或使用公开可用的数据集" class="hash-link" aria-label="Direct link to 收集数据集或使用公开可用的数据集" title="Direct link to 收集数据集或使用公开可用的数据集">​</a></h2><p>物体检测项目的第一步是获取训练数据。您可以从公开可用的数据集下载数据，或创建自己的数据集！通常公开数据集用于教育和研究目的。然而，如果您想构建特定的物体检测项目，而公开数据集中没有您想要检测的对象，那么您可能需要构建自己的数据集。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="手动收集数据集">手动收集数据集<a href="#手动收集数据集" class="hash-link" aria-label="Direct link to 手动收集数据集" title="Direct link to 手动收集数据集">​</a></h3><p>建议首先录制要识别的物体的视频镜头。您必须确保覆盖物体的所有角度（360度），将物体放置在不同的环境中，不同的光照和不同的天气条件下进行拍摄。
我们录制的总视频时长为9分钟，其中4.5分钟用于拍摄花朵，剩余的4.5分钟用于拍摄叶子。录制可以分如下：</p><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOV5/pink-flowers-2.gif" class="img_ev3q"></div><ol><li>早晨晴天</li><li>早晨有风天气</li><li>早晨雨天</li><li>中午晴天</li><li>中午有风天气</li><li>中午雨天</li><li>晚上晴天</li><li>晚上有风天气</li><li>晚上雨天</li></ol><p><strong>注意:</strong> 后续我们将把这段视频镜头转换为一系列图像，以组成训练数据集。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="使用公开可用的数据集">使用公开可用的数据集<a href="#使用公开可用的数据集" class="hash-link" aria-label="Direct link to 使用公开可用的数据集" title="Direct link to 使用公开可用的数据集">​</a></h3><p>您可以下载多个公开可用的数据集，例如  <a href="https://cocodataset.org" target="_blank" rel="noopener noreferrer">COCO 数据集</a>, <a href="http://host.robots.ox.ac.uk/pascal/VOC" target="_blank" rel="noopener noreferrer">Pascal VOC 数据集</a> 等。建议使用 <a href="https://universe.roboflow.com" target="_blank" rel="noopener noreferrer">Roboflow Universe</a> 平台该平台提供了广泛的数据集，可用于构建计算机视觉模型，包括 <a href="https://blog.roboflow.com/computer-vision-datasets-and-apis" target="_blank" rel="noopener noreferrer">90,000多个数据集，共计6600多万张图像</a> 。此外，您可以在Google上简单搜索<strong>开源数据集</strong>，并从可用的各种数据集中进行选择。</p><h2 class="anchor anchorWithStickyNavbar_LWe7" id="使用roboflow对数据集进行注释w">使用Roboflow对数据集进行注释w<a href="#使用roboflow对数据集进行注释w" class="hash-link" aria-label="Direct link to 使用Roboflow对数据集进行注释w" title="Direct link to 使用Roboflow对数据集进行注释w">​</a></h2><p>接下来，我们将转到对数据集进行注释。注释就是简单地在我们要检测的每个物体周围画一个矩形框，并为其分配标签。我们将说明如何使用Roboflow实现这一点。</p><p><a href="https://roboflow.com" target="_blank" rel="noopener noreferrer">Roboflow</a> 是一种基于在线的注释工具。在这里，我们可以直接将之前录制的视频镜头导入到Roboflow中，并将其导出为一系列图像。这个工具非常方便，因为它会让我们帮助将数据集划分为“训练、验证和测试”。此外，在标记图像之后，这个工具还允许我们添加更多的处理。此外，它还可以轻松地将带有标签的数据集导出为<strong>YOLOV5 PyTorch格式</strong>，这正是我们需要的！</p><ul><li><p><strong>步骤 1.</strong> 点击 <a href="https://app.roboflow.com/login" target="_blank" rel="noopener noreferrer">这里</a> 注册一个Roboflow账户</p></li><li><p><strong>步骤 2.</strong> 点击 <strong>创建新项目</strong>开始我们的项目。</p></li></ul><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOV5/2.jpg" class="img_ev3q"></div><ul><li><strong>步骤 3.</strong> 填写 <strong>Project Name</strong>，保留 <strong>License (CC BY 4.0)</strong> 和<strong>Project Type (Object Detection (Bounding Box))</strong> 作为默认设置。在 <strong>What will your model predict？</strong> 列下，填写一个注释组名称。例如，在我们的情况下，我们选择 <strong>plants</strong>。这个名称应该突出你数据集中的所有类别。最后，点击<strong>Create Public Project</strong>。</li></ul><div align="center"><img loading="lazy" width="360" src="https://files.seeedstudio.com/wiki/YOLOV5/20.jpg" class="img_ev3q"></div><ul><li><strong>步骤 4.</strong> 拖放你之前录制的视频镜头</li></ul><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOV5/4.jpg" class="img_ev3q"></div><ul><li><strong>步骤 5.</strong> 选择一个帧率，使得视频可以分割成一系列图像。在这里，我们将使用默认帧速率 <strong>1 frame/second</strong>，总共会生成542张图像。一旦您通过滑动滑块选择了帧速率，单击<strong>Choose Frame Rate</strong>。这个过程需要几秒钟到几分钟的时间（取决于视频长度）来完成。</li></ul><div align="center"><img loading="lazy" width="400" src="https://files.seeedstudio.com/wiki/YOLOV5/5.png" class="img_ev3q"></div><ul><li><strong>步骤 6.</strong> 图像处理完成后，单击<strong>Finish Uploading</strong>。请耐心等待直到图像完成上传。</li></ul><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOV5/6.jpg" class="img_ev3q"></div><ul><li><strong>步骤 7.</strong> 图像上传完成后，单击<strong>Assign Images</strong>。</li></ul><div align="center"><img loading="lazy" width="500" src="https://files.seeedstudio.com/wiki/YOLOV5/7.jpg" class="img_ev3q"></div><ul><li><strong>步骤 8.</strong> 选择一张图片，在花朵周围画一个矩形框，选择标签为<strong>pink flower</strong>，然后按下<strong>ENTER</strong>键。</li></ul><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOV5/21.jpg" class="img_ev3q"></div><ul><li><strong>步骤 9.</strong> 对于剩下的花朵，重复同样的操作。</li></ul><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOV5/22.jpg" class="img_ev3q"></div><ul><li><strong>步骤 10.</strong> 画一个矩形框在叶子周围，选择标签为<strong>leaf</strong>，然后按下<strong>ENTER</strong>键。</li></ul><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOV5/23.jpg" class="img_ev3q"></div><ul><li><strong>步骤 11.</strong> 对于剩下的叶子，重复同样的操作。</li></ul><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOV5/24.jpg" class="img_ev3q"></div><p><strong>注意:</strong> 尝试标记图像中所见到的所有对象。如果只有对象的一部分可见，也请尝试标记它。</p><ul><li><strong>步骤 12.</strong> 继续注释数据集中的所有图像。</li></ul><p>Roboflow有一个名为<strong>Label Assist</strong>的功能，它可以预测标签，使标注速度更快。然而，它不适用于所有类型的物体，而是适用于一种特定类型的物体。要使用此功能，您只需点击<strong>Label Assist</strong>按钮，然后<strong>select a model</strong>、<strong>select the classes</strong>，浏览图像，您将看到带有边界框的预测标签。</p><div align="center"><img loading="lazy" width="300" src="https://files.seeedstudio.com/wiki/YOLOV5/41.png" class="img_ev3q"></div><div align="center"><img loading="lazy" width="400" src="https://files.seeedstudio.com/wiki/YOLOV5/39.png" class="img_ev3q"></div><div align="center"><img loading="lazy" width="400" src="https://files.seeedstudio.com/wiki/YOLOV5/40.png" class="img_ev3q"></div><p>如上所述，它只能帮助预测上面列出的80个类别的标签。如果您的图像不包含上述对象类别，则不能使用标签辅助功能。</p><ul><li><strong>步骤 13.</strong> 一旦标注完成，单击 <strong>Add images to Dataset</strong></li></ul><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOV5/25.jpg" class="img_ev3q"></div><ul><li><strong>步骤 14.</strong> 接下来我们将根据“训练集、验证集和测试集”划分图像。保留默认比例来进行分配，然后单击 <strong>Add Images</strong></li></ul><div align="center"><img loading="lazy" width="330" src="https://files.seeedstudio.com/wiki/YOLOV5/26.png" class="img_ev3q"></div><ul><li><strong>步骤 15.</strong> 单击 <strong>Generate New Version</strong></li></ul><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOV5/27.jpg" class="img_ev3q"></div><ul><li><strong>步骤 16.</strong> 现在，如果你想的画可以添加 <strong>Preprocessing</strong> 和 <strong>Augmentation</strong> 。在这里我们将 <strong>删除</strong>  <strong>Resize</strong> 选项并保留原始图像大小。</li></ul><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOV5/28.jpg" class="img_ev3q"></div><ul><li><strong>步骤 17.</strong> 接下来，继续执行其余的默认设置，然后单击 <strong>Generate</strong>。</li></ul><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOV5/29.jpg" class="img_ev3q"></div><ul><li><strong>步骤 18.</strong> 单击 <strong>Export</strong></li></ul><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOV5/17.jpg" class="img_ev3q"></div><ul><li><strong>步骤 19.</strong> 选择 <strong>download zip to computer</strong>, 在 &quot;Select a Format&quot; 下选择 <strong>YOLO v5 PyTorch</strong> 并且单击 <strong>Continue</strong></li></ul><div align="center"><img loading="lazy" width="400" src="https://files.seeedstudio.com/wiki/YOLOV5/18.jpg" class="img_ev3q"></div><ul><li><strong>步骤 20.</strong> 之后一个 <strong>.zip 文件</strong> 会被下载到您的计算机上，我们稍后需要这个.zip文件进行训练。</li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="在本地pc或云端训练">在本地PC或云端训练<a href="#在本地pc或云端训练" class="hash-link" aria-label="Direct link to 在本地PC或云端训练" title="Direct link to 在本地PC或云端训练">​</a></h2><p>在对数据集进行注释后，我们需要对数据集进行训练。对于训练，我们将介绍两种方法。一种方法基于在线（Google Colab），另一种方法基于本地PC（Linux）。</p><p>对于Google Colab训练，我们将使用两种方法。在第一种方法中，我们将使用Ultralytics HUB上传数据集，在Colab上设置训练，监测训练并获取训练好的模型。在第二种方法中，我们将通过Roboflow api从Roboflow获取数据集，在Colab上进行训练并下载训练好的模型。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="使用ultralytics-hub和google-colab">使用Ultralytics HUB和Google Colab<a href="#使用ultralytics-hub和google-colab" class="hash-link" aria-label="Direct link to 使用Ultralytics HUB和Google Colab" title="Direct link to 使用Ultralytics HUB和Google Colab">​</a></h3><p>是一个平台，您可以在不需要编写任何代码的情况下训练模型。只需将数据上传到Ultralytics HUB，训练模型并将其部署到现实世界中！这是一个快速、简单和易于使用的平台。任何人都轻松上手！</p><ul><li><p><strong>步骤 1.</strong> 访问 <a href="https://hub.ultralytics.com" target="_blank" rel="noopener noreferrer">网页链接</a> 去注册一个免费的 Ultralytics HUB 账号</p></li><li><p><strong>步骤 2.</strong> 输入您的凭据并<strong>使用电子邮件进行注册</strong>或使用<strong>Google、GitHub或Apple账户</strong>进行注册。</p></li></ul><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOv5-2/1.png" class="img_ev3q"></div><p>在你登录Ultralytics HUB之后, 您会看到下面这样的仪表板：</p><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOv5-2/2.png" class="img_ev3q"></div><ul><li><p><strong>步骤 3.</strong> 解压之前从Roboflow下载并得到的zip文件，并将其中的所有文件放入一个新的文件夹中。</p></li><li><p><strong>步骤 4.</strong> 确保您的<strong>数据集yaml文件</strong>和<strong>根目录文件夹</strong>（之前创建的文件夹）拥有相同的名称。例如，如果您将yaml文件命名为<strong>pinkflowers.yaml</strong>，则根目录应该命名为<strong>pinkflowers</strong>。</p></li><li><p><strong>步骤 5.</strong> 打开 <strong>pinkflowers.yaml</strong> 文件并且编辑 <strong>train</strong> 和 <strong>val</strong> 目录结构，如下所示：</p></li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">train: train/images</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">val: valid/images</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>步骤 6.</strong> 将根目录文件夹压缩为 <strong>.zip</strong>文件，并与根目录文件夹名称相同（例如，本例中为<strong>pinkflowers.zip</strong>）。</li></ul><p>现在，我们已经准备好将该数据集上传到Ultralytics HUB上进行训练。</p><ul><li><strong>步骤 7.</strong> 单击<strong>数据集</strong>选项卡，然后单击<strong>上传数据集</strong>。</li></ul><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOv5-2/6.jpg" class="img_ev3q"></div><ul><li><strong>步骤 8.</strong> 输入数据集的<strong>名称</strong>。如果需要，输入<strong>描述</strong>。将我们之前创建的.zip文件拖放到<strong>数据集</strong>区域下，然后单击<strong>上传数据集</strong>。</li></ul><div align="center"><img loading="lazy" width="400" src="https://files.seeedstudio.com/wiki/YOLOv5-2/24.png" class="img_ev3q"></div><ul><li><strong>步骤 9.</strong> 数据集上传后，单击数据集以查看更多详细信息。</li></ul><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOv5-2/25.png" class="img_ev3q"></div><ul><li><strong>步骤 10.</strong> 单击 <strong>Projects</strong> 选项卡 然后单击 <strong>Create Project</strong></li></ul><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOv5-2/5.jpg" class="img_ev3q"></div><ul><li><strong>步骤 11.</strong> 为项目输入一个<strong>名称</strong>，如果需要，输入一个<strong>描述</strong>，如果需要添加一个<strong>封面图像</strong>，然后单击<strong>创建项目</strong>。</li></ul><div align="center"><img loading="lazy" width="350" src="https://files.seeedstudio.com/wiki/YOLOv5-2/26.png" class="img_ev3q"></div><ul><li><strong>步骤 12.</strong>  进入新创建的项目，点击 <strong>创建模型</strong>。</li></ul><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOv5-2/27.png" class="img_ev3q"></div><ul><li><strong>步骤 13.</strong>  输入 <strong>模型名称</strong> ，选择 <strong>YOLOv5n</strong> 作为预训练模型，然后点击 <strong>下一步</strong>。</li></ul><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOv5-2/28.png" class="img_ev3q"></div><p><strong>注意：</strong>通常情况下，首选的预训练模型是 <strong>YOLOv5n6</strong>，因为它适用于像Jetson平台这样的边缘计算设备。然而，Ultralytics HUB目前还没有支持它。因此，我们使用稍微相似的模型 <strong>YOLOv5n</strong>。</p><ul><li><strong>步骤 14.</strong> 选择我们之前上传的数据集，单击 <strong>Next</strong></li></ul><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOv5-2/29.png" class="img_ev3q"></div><ul><li><strong>步骤 15.</strong> 选择 <strong>Google Colab</strong> 作为训练平台然后单击<strong>Advanced Options</strong> 下拉菜单。 在这里，我们可以更改一些训练设置。例如，我们将把训练的epoch次数从300更改为100，并保持其它设置不变。然后点击 <strong>保存</strong>。</li></ul><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOv5-2/30.png" class="img_ev3q"></div><p><strong>注意：</strong> 如果您计划进行本地培训，还可以选择 <strong>Bring your own agent</strong></p><ul><li><strong>步骤 16.</strong> 复制 <strong>API key</strong> 并且点击 <strong>Open Colab</strong></li></ul><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOv5-2/31.png" class="img_ev3q"></div><ul><li><strong>步骤 17.</strong> 将 <strong>MODEL_KEY</strong> 替换为之前复制的 <strong>API密钥</strong>。</li></ul><div align="center"><img loading="lazy" width="700" src="https://files.seeedstudio.com/wiki/YOLOv5-2/16.jpg" class="img_ev3q"></div><ul><li><strong>步骤 18.</strong> 点击 <code>Runtime &gt; Rull All</code> 来运行所有代码单元格，开始训练过程。</li></ul><div align="center"><img loading="lazy" width="600" src="https://files.seeedstudio.com/wiki/YOLOv5-2/17.jpg" class="img_ev3q"></div><ul><li><strong>步骤 19.</strong> 当 Ultralytics HUB 的状态变为蓝色时，返回到 Ultralytics HUB 界面，然后点击 <strong>完成</strong> 。此时，您还会看到 Colab 的状态显示为 <strong>已连接</strong>。</li></ul><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOv5-2/32.png" class="img_ev3q"></div><p>现在你可以在HUB上看到训练过程</p><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOv5-2/33.png" class="img_ev3q"></div><ul><li><strong>步骤 20.</strong> 训练完成后，点击 PyTorch 按钮以下载以 PyTorch 格式保存的已训练模型。PyTorch 是在 Jetson 设备上进行推断所需的格式。</li></ul><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOv5-2/37.png" class="img_ev3q"></div><p><strong>注意：</strong> 您还可以将模型导出成其他在 <strong>格式</strong> 下显示的格式 。</p><p>如果您返回到谷歌 Colab，您可以看到更多详细信息，如下所示：</p><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOv5-2/36.png" class="img_ev3q"></div><p>这里的准确率 <code>mAP@.5</code> 叶子的大约为90％和花朵的大约为99.4％，而总体准确率的 <code>mAP@.5</code> 大约为94.7％。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="使用-google-colab-和-roboflow-api">使用 Google Colab 和 Roboflow api<a href="#使用-google-colab-和-roboflow-api" class="hash-link" aria-label="Direct link to 使用 Google Colab 和 Roboflow api" title="Direct link to 使用 Google Colab 和 Roboflow api">​</a></h3><p>在这里，我们使用谷歌 Colaboratory 环境在云端进行训练。此外，我们在 Colab 中使用 Roboflow api 轻松下载我们的数据集。</p><ul><li><strong>步骤 1.</strong> 单击 <a href="https://colab.research.google.com/gist/lakshanthad/645de50b7cc5870f4070b720be770f8b/yolov5-training-for-jetson.ipynb" target="_blank" rel="noopener noreferrer">这</a> 打开已准备好的谷歌 Colab 工作区，并按照工作区中提到的步骤进行操作。</li></ul><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOV5/82.png" class="img_ev3q"></div><p>训练玩之后, 你会看到如下输出:</p><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOV5/37.png" class="img_ev3q"></div><p>这里的准确率 <code>mAP@.5</code> 叶子的大约为91.6％和花朵的大约为99.4％，而总体准确率的 <code>mAP@.5</code> 大约为95.5％。</p><ul><li><strong>步骤 2.</strong> 在 <strong>文件</strong> 选项卡下, 如果您导航到 <code>runs/train/exp/weights</code> ，您会看到一个名为 <strong>best.pt</strong> 的文件。这是训练生成的模型。下载此文件并将其复制到 Jetson 设备上，因为这是我们稍后要在 Jetson 设备上进行推论所使用的模型。</li></ul><div align="center"><img loading="lazy" width="400" src="https://files.seeedstudio.com/wiki/YOLOV5/52.png" class="img_ev3q"></div><h3 class="anchor anchorWithStickyNavbar_LWe7" id="使用本地pc端">使用本地PC端<a href="#使用本地pc端" class="hash-link" aria-label="Direct link to 使用本地PC端" title="Direct link to 使用本地PC端">​</a></h3><p>在这里，您可以使用安装了 Linux 操作系统的个人电脑进行训练。我们在此示例中使用了 Ubuntu 20.04 个人电脑。</p><ul><li><strong>步骤 1.</strong> 克隆 <strong>YOLOv5 repo</strong> 并在<strong>Python&gt;=3.7.0</strong> 的环境下安装 <strong>requirements.txt</strong> 文件。</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">git clone https://github.com/ultralytics/yolov5 </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">cd yolov5</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">pip install -r requirements.txt</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>步骤 2.</strong> 将之前从 Roboflow 下载的 .zip 文件复制并粘贴到 <strong>yolov5</strong> 目录下，然后解压它。</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain"># example</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">cp ~/Downloads/pink-flowers.v1i.yolov5pytorch.zip ~/yolov5</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">unzip pink-flowers.v1i.yolov5pytorch.zip</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>步骤 3.</strong> 请打开 <strong>data.yaml</strong> 文件，并将 <strong>train</strong> 和 <strong>val</strong> 目录按如下所示进行编辑：</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">train: train/images</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">val: valid/images</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>步骤 4.</strong> 执行以下命令开始训练：</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">python3 train.py --data data.yaml --img-size 640 --batch-size -1 --epoch 100 --weights yolov5n6.pt</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>由于我们的数据集相对较小(约500张图像)，因此 <strong>迁移学习</strong> 有望比从头开始训练产生更好的结果。我们使用预训练的 COCO 模型的权重对模型进行了初始化，通过将模型名称（yolov5n6）传递给“权重”参数来实现。在此，我们使用了 <strong>yolov5n6</strong>，因为它非常适合边缘设备。这里将 <strong>image size</strong> 设置为 <strong>640x640</strong>。我们将 <strong>batch-size</strong> 设置为 <strong>-1</strong>，因为这将自动确定最佳的批大小。但是，如果出现“GPU内存不足”的错误，请选择批量大小为 <strong>32</strong>，甚至是 <strong>16</strong>。您也可以根据自己的喜好更改 <strong>迭代轮数</strong></p><p>训练完成之后, 你会看到如下输出:</p><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOV5/65.png" class="img_ev3q"></div><p>这里的准确率 <code>mAP@.5</code> 叶子的约为90.6% 而花的约为99.4% ， 并且总体准确率 <code>mAP@.5</code> 约为 95%.</p><ul><li><strong>步骤 5.</strong> 如果您导航到 <code>runs/train/exp/weights</code>，您会看到一个名为 <strong>best.pt</strong> 的文件。这是训练生成的模型。将此文件复制粘贴到 Jetson 设备上，因为这是我们稍后要在 Jetson 设备上进行推理所使用的模型。</li></ul><div align="center"><img loading="lazy" width="600" src="https://files.seeedstudio.com/wiki/YOLOV5/33.jpg" class="img_ev3q"></div><h2 class="anchor anchorWithStickyNavbar_LWe7" id="在jetson设备上进行推理">在Jetson设备上进行推理<a href="#在jetson设备上进行推理" class="hash-link" aria-label="Direct link to 在Jetson设备上进行推理" title="Direct link to 在Jetson设备上进行推理">​</a></h2><h3 class="anchor anchorWithStickyNavbar_LWe7" id="使用tensorrt">使用TensorRT<a href="#使用tensorrt" class="hash-link" aria-label="Direct link to 使用TensorRT" title="Direct link to 使用TensorRT">​</a></h3><p>现在，我们将使用Jetson设备，使用之前训练生成的模型来对图像进行推断（识别物体）。 这里将使用 <a href="https://developer.nvidia.com/tensorrt" target="_blank" rel="noopener noreferrer">NVIDIA TensorRT</a> 来增加 Jetson 平台上的推断性能。</p><ul><li><strong>步骤 1.</strong> 进入 Jetson 设备的终端，install pip 并update它。</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">sudo apt update</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">sudo apt install -y python3-pip</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">pip3 install --upgrade pip</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>步骤 2.</strong> 克隆如下 repo</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">git clone https://github.com/ultralytics/yolov5</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>步骤 3.</strong> 打开 <strong>requirements.txt</strong></li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">cd yolov5</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">vi requirements.txt</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>步骤 4.</strong> 编辑以下行。在这里，您需要先按下 <strong>i</strong> 进入可编辑模式。编辑完成后，按下 <strong>ESC</strong>，然后键入 <strong>:wq</strong> 以保存并退出。</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">matplotlib==3.2.2</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">numpy==1.19.4</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># torch&gt;=1.7.0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># torchvision&gt;=0.8.1</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p><strong>注意:</strong> 我们在这里包含了固定版本的 <strong>matplotlib</strong> 和 <strong>numpy</strong>，以确保稍后运行YOLOv5时不会出现错误。此外，因为稍后将安装它们，此时将排除 <strong>torch</strong> 和 <strong>torchvision</strong>。</p><ul><li><strong>步骤 5.</strong> 安装以下依赖项：</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">sudo apt install -y libfreetype6-dev</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>步骤 6.</strong> 安装必要的软件包</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">pip3 install -r requirements.txt</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>步骤 7.</strong> 安装 torch</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">cd ~</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">sudo apt-get install -y libopenblas-base libopenmpi-dev</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">wget https://nvidia.box.com/shared/static/fjtbno0vpo676a25cgvuqc1wty0fkkg6.whl -O torch-1.10.0-cp36-cp36m-linux_aarch64.whl</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">pip3 install torch-1.10.0-cp36-cp36m-linux_aarch64.whl</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>步骤 8.</strong> 安装 torchvision</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">sudo apt install -y libjpeg-dev zlib1g-dev</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">git clone --branch v0.9.0 https://github.com/pytorch/vision torchvision</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">cd torchvision</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">sudo python3 setup.py install </span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>步骤 9.</strong> 克隆如下 repo</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">cd ~</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">git clone https://github.com/wang-xinyu/tensorrtx</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><p><strong>步骤 10.</strong> 将之前训练生成的 <strong>best.pt</strong> 文件复制到 <strong>yolov5</strong> 目录中。</p></li><li><p><strong>步骤 11.</strong> 将 <strong>tensorrtx/yolov5</strong> 目录下的 <strong>gen_wts.py</strong> 文件复制到 <strong>yolov5</strong> 目录中。</p></li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">cp tensorrtx/yolov5/gen_wts.py yolov5</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>步骤 12.</strong> 使用 PyTorch <strong>.pt</strong> 文件生成 <strong>.wts</strong> 文件</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">cd yolov5</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">python3 gen_wts.py -w best.pt -o best.wts</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>步骤 13.</strong> 导航至 <strong>tensorrtx/yolov5</strong></li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">cd ~</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">cd tensorrtx/yolov5</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>步骤 14.</strong> 使用 <strong>vi text editor</strong>打开 <strong>yololayer.h</strong> </li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">vi yololayer.h</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>步骤 15.</strong> 将 <strong>CLASS_NUM</strong> 更改为您模型所训练的类别数。在我们的示例中，为2。</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">CLASS_NUM = 2</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>步骤 16.</strong> 创建一个新的 <strong>build</strong> 目录并进入其中：</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">mkdir build </span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">cd build</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>步骤 17.</strong> 将之前生成的 <strong>best.wts</strong> 文件复制到这个 <strong>build</strong> 目录中：</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">cp ~/yolov5/best.wts .</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>步骤 18.</strong> 编译它</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">cmake ..</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">make</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>步骤 19.</strong> 序列化模型</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">sudo ./yolov5 -s [.wts] [.engine] [n/s/m/l/x/n6/s6/m6/l6/x6 or c/c6 gd gw]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">#example</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">sudo ./yolov5 -s best.wts best.engine n6</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>在这里，我们使用 <strong>n6</strong>，因为它被推荐用于像 NVIDIA Jetson 平台这样的边缘设备。但是，如果您使用 Ultralytics HUB 来设置训练，那么您只能使用 <strong>n</strong>，因为 HUB 目前尚未支持 <strong>n6</strong>。</p><ul><li><p><strong>步骤 20.</strong> 将您希望模型检测到的图像复制到新文件夹中，例如 <strong>tensorrtx/yolov5/images</strong>。</p></li><li><p><strong>步骤 21.</strong> 以下是反序列化和对图像运行推理的命令：</p></li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">sudo ./yolov5 -d best.engine images</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>以下是在Jetson Nano和Jetson Xavier NX上运行推理的时间对比：</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="jetson-nano">Jetson Nano<a href="#jetson-nano" class="hash-link" aria-label="Direct link to Jetson Nano" title="Direct link to Jetson Nano">​</a></h4><p>在这里，量化设置为FP16</p><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOV5/58.png" class="img_ev3q"></div><p>从上面的结果中，我们可以取平均值约为 <strong>47ms</strong>。将此值转换为每秒帧数：1000/47 = 21.2766 = <strong>21fps</strong>。</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="jetson-xavier-nx">Jetson Xavier NX<a href="#jetson-xavier-nx" class="hash-link" aria-label="Direct link to Jetson Xavier NX" title="Direct link to Jetson Xavier NX">​</a></h4><p>在这里，量化设置为FP16</p><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOV5/59.jpg" class="img_ev3q"></div><p>从上面的结果中，我们可以取平均值约为 <strong>20ms</strong>。将此值转换为每秒帧数：1000 / 20 = <strong>50fps</strong>。</p><p>此外，输出图像将如下所示，显示检测到的对象：</p><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOV5/55.jpg" class="img_ev3q"></div><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOV5/56.jpg" class="img_ev3q"></div><h3 class="anchor anchorWithStickyNavbar_LWe7" id="使用-tensorrt-和-deepstream-sdk">使用 TensorRT 和 DeepStream SDK<a href="#使用-tensorrt-和-deepstream-sdk" class="hash-link" aria-label="Direct link to 使用 TensorRT 和 DeepStream SDK" title="Direct link to 使用 TensorRT 和 DeepStream SDK">​</a></h3><p>在这里，我们将使用  <a href="https://developer.nvidia.com/tensorrt" target="_blank" rel="noopener noreferrer">NVIDIA TensorRT</a> 和 <a href="https://developer.nvidia.com/deepstream-sdk" target="_blank" rel="noopener noreferrer">NVIDIA DeepStream SDK</a> 来对视频进行推理。</p><ul><li><strong>步骤 1.</strong> 确保您已正确地在 Jetson 设备上安装了所有 <strong>SDK组件</strong> 和 <strong>DeepStream SDK</strong>。(点击 <a href="https://wiki.seeedstudio.com/Tutorial-of-A20X-Carrier-Boards" target="_blank" rel="noopener noreferrer">此wiki</a> 参考安装)</li></ul><p><strong>注意:</strong> 建议使用 NVIDIA SDK 管理器安装所有 SDK 组件和 DeepStream SDK。</p><ul><li><strong>步骤 2.</strong> 进入 Jetson 设备的终端，安装 pip 并升级它</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">sudo apt update</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">sudo apt install -y python3-pip</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">pip3 install --upgrade pip</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>步骤 3.</strong> 克隆如下 repo</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">git clone https://github.com/ultralytics/yolov5</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>步骤 4.</strong> 打开 <strong>requirements.txt</strong></li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">cd yolov5</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">vi requirements.txt</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>步骤 5.</strong> 编辑以下行。在这里，您需要先按下 <strong>i</strong> 进入可编辑模式。编辑完成后，按下 <strong>ESC</strong>，然后键入 <strong>:wq</strong> 以保存并退出。</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">matplotlib==3.2.2</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">numpy==1.19.4</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># torch&gt;=1.7.0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># torchvision&gt;=0.8.1</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p><strong>注意:</strong> 我们在这里包含了固定版本的 <strong>matplotlib</strong> 和 <strong>numpy</strong>，以确保稍后运行 YOLOv5 时不会出现错误。此外，因为稍后将安装它们，此时将排除 <strong>torch</strong> 和 <strong>torchvision</strong>。</p><ul><li><strong>步骤 6.</strong> 安装如下依赖：</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">sudo apt install -y libfreetype6-dev</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>步骤 7.</strong> 安装必要的软件包</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">pip3 install -r requirements.txt</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>步骤 8.</strong> 安装 torch</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">cd ~</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">sudo apt-get install -y libopenblas-base libopenmpi-dev</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">wget https://nvidia.box.com/shared/static/fjtbno0vpo676a25cgvuqc1wty0fkkg6.whl -O torch-1.10.0-cp36-cp36m-linux_aarch64.whl</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">pip3 install torch-1.10.0-cp36-cp36m-linux_aarch64.whl</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>步骤 9.</strong> 安装 torchvision</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">sudo apt install -y libjpeg-dev zlib1g-dev</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">git clone --branch v0.9.0 https://github.com/pytorch/vision torchvision</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">cd torchvision</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">sudo python3 setup.py install </span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>步骤 10.</strong> 克隆如下 repo</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">cd ~</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">git clone https://github.com/marcoslucianops/DeepStream-Yolo</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>步骤 11.</strong> 将 <strong>DeepStream-Yolo/utils</strong> 目录下的 <strong>gen_wts_yoloV5.py</strong> 文件复制到 <strong>yolov5</strong> 目录中。</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">cp DeepStream-Yolo/utils/gen_wts_yoloV5.py yolov5</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>步骤 12.</strong> 在 yolov5 仓库中，从 YOLOv5 发布中下载 <strong>pt 文件</strong>（以 YOLOv5s 6.1 为例）：</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">cd yolov5</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">wget https://github.com/ultralytics/yolov5/releases/download/v6.1/yolov5s.pt</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>步骤 13.</strong> 生成 <strong>cfg</strong> 和 <strong>wts</strong> 文件</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">python3 gen_wts_yoloV5.py -w yolov5s.pt</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p><strong>注意</strong>: 要更改推理尺寸（默认为640）</p><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">-s SIZE</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">--size SIZE</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">-s HEIGHT WIDTH</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">--size HEIGHT WIDTH</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain" style="display:inline-block"></span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">Example for 1280:</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">-s 1280</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">or</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">-s 1280 1280</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>步骤 14.</strong> 将生成的 <strong>cfg</strong> 和 <strong>wts</strong> 文件复制到 <strong>DeepStream-Yolo</strong> 文件夹中。</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">cp yolov5s.cfg ~/DeepStream-Yolo</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">cp yolov5s.wts ~/DeepStream-Yolo</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>步骤 15.</strong> 在打开 <strong>DeepStream-Yolo</strong> 文件夹之后，编译库</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">cd ~/DeepStream-Yolo</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># For DeepStream 6.1</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">CUDA_VER=11.4 make -C nvdsinfer_custom_impl_Yolo</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># For DeepStream 6.0.1 / 6.0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">CUDA_VER=10.2 make -C nvdsinfer_custom_impl_Yolo</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>步骤 16.</strong> 根据您的模型编辑 <strong>config_infer_primary_yoloV5.txt</strong> 文件。</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">[property]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">...</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">custom-network-config=yolov5s.cfg</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">model-file=yolov5s.wts</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">...</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>步骤 17.</strong> 编辑 <strong>deepstream_app_config</strong> 文件</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">...</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">[primary-gie]</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">...</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">config-file=config_infer_primary_yoloV5.txt</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>步骤 18.</strong> 运行推理</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">deepstream-app -c deepstream_app_config.txt</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOV5/FP32-yolov5s.gif" class="img_ev3q"></div><p>上面的结果在 <strong>Jetson Xavier NX</strong> 上使用 <strong>FP32</strong> 和 <strong>YOLOv5s 640x640</strong> 进行推理。我们可以看到 <strong>FPS</strong> 约为 <strong>30</strong>。</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="int8-校准">INT8 校准<a href="#int8-校准" class="hash-link" aria-label="Direct link to INT8 校准" title="Direct link to INT8 校准">​</a></h4><p>如果您想在推理过程中使用INT8精度，则需要按照以下步骤操作：</p><ul><li><strong>步骤 1.</strong> 安装 OpenCV</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">sudo apt-get install libopencv-dev</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>步骤 2.</strong> 使用 OpenCV 支持编译 / 重新编译的 <strong>nvdsinfer_custom_impl_Yolo</strong> 库</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">cd ~/DeepStream-Yolo</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># For DeepStream 6.1</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">CUDA_VER=11.4 OPENCV=1 make -C nvdsinfer_custom_impl_Yolo</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain"># For DeepStream 6.0.1 / 6.0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">CUDA_VER=10.2 OPENCV=1 make -C nvdsinfer_custom_impl_Yolo</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><p><strong>步骤 3.</strong> 对于 COCO 数据集，请下载  <a href="https://drive.google.com/file/d/1gbvfn7mcsGDRZ_luJwtITL-ru2kK99aK/view?usp=sharing" target="_blank" rel="noopener noreferrer">val2017</a>, 然后将其解压并移动到 <strong>DeepStream-Yolo</strong> 文件夹中。</p></li><li><p><strong>步骤 4.</strong> 为校准图像创建一个新目录：</p></li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">mkdir calibration</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>步骤 5.</strong> 运行以下命令，从 COCO 数据集中选择1000张随机图像来运行校准：</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">for jpg in $(ls -1 val2017/*.jpg | sort -R | head -1000); do \</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">    cp ${jpg} calibration/; \</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">done</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p><strong>注意：</strong> NVIDIA 建议至少使用 500 张图像来获取良好的准确性。在此示例中，选择 1000 张图像以获得更好的准确度（图像越多 = 准确度越高）。更高的 INT8_CALIB_BATCH_SIZE 值将导致更高的准确率和更快的校准速度。请根据您的 GPU 内存设置它。您可以将其设置为 <strong>head -1000</strong>。例如，对于 2000 张图像，使用 <strong>head -2000</strong>。此过程可能需要很长时间。</p><ul><li><strong>步骤 6.</strong> 创建包含所有选定图像的 <strong>calibration.txt</strong> 文件：</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">realpath calibration/*jpg &gt; calibration.txt</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>步骤 7.</strong> 设置环境变量：</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">export INT8_CALIB_IMG_PATH=calibration.txt</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">export INT8_CALIB_BATCH_SIZE=1</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>步骤 8.</strong> 更新 <strong>config_infer_primary_yoloV5.txt</strong> 文件</li></ul><p>从</p><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">...</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">model-engine-file=model_b1_gpu0_fp32.engine</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">#int8-calib-file=calib.table</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">...</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">network-mode=0</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">...</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><p>到</p><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">...</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">model-engine-file=model_b1_gpu0_int8.engine</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">int8-calib-file=calib.table</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">...</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">network-mode=1</span><br></span><span class="token-line" style="color:#F8F8F2"><span class="token plain">...</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><ul><li><strong>步骤 9.</strong> 运行推理</li></ul><div class="language-sh codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#F8F8F2;--prism-background-color:#282A36"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-sh codeBlock_bY9V thin-scrollbar"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#F8F8F2"><span class="token plain">deepstream-app -c deepstream_app_config.txt</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOV5/INT8-yolov5s.gif" class="img_ev3q"></div><p>上述结果在 <strong>Jetson Xavier NX</strong> 上使用 <strong>INT8</strong> 和 <strong>YOLOv5s 640x640</strong> 进行推理。我们可以看到 <strong>FPS</strong> 约为 <strong>60</strong>。</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="基准测试结果">基准测试结果：<a href="#基准测试结果" class="hash-link" aria-label="Direct link to 基准测试结果：" title="Direct link to 基准测试结果：">​</a></h4><p>下表总结了在 <strong>Jetson Xavier NX</strong> 上不同模型的表现。 </p><table><thead><tr><th>模型名字</th><th>精度</th><th>推理尺寸</th><th>推理时间 (ms)</th><th>FPS</th></tr></thead><tbody><tr><td rowspan="3">YOLOv5s</td><td>FP32</td><td>320x320</td><td>16.66</td><td>60</td></tr><tr><td>FP32</td><td>640x640</td><td>33.33</td><td>30</td></tr><tr><td>INT8</td><td>640x640</td><td>16.66</td><td>60</td></tr><tr><td>YOLOv5n</td><td>FP32</td><td>640x640</td><td>16.66</td><td>60</td></tr></tbody></table><h2 class="anchor anchorWithStickyNavbar_LWe7" id="使用公共数据集与自定义数据集的比较">使用公共数据集与自定义数据集的比较：<a href="#使用公共数据集与自定义数据集的比较" class="hash-link" aria-label="Direct link to 使用公共数据集与自定义数据集的比较：" title="Direct link to 使用公共数据集与自定义数据集的比较：">​</a></h2><p>现在我们将比较使用公共数据集和自己定制数据集时，训练样本数量和训练时间之间的差异。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="训练样本数量">训练样本数量<a href="#训练样本数量" class="hash-link" aria-label="Direct link to 训练样本数量" title="Direct link to 训练样本数量">​</a></h3><h4 class="anchor anchorWithStickyNavbar_LWe7" id="自定义数据集">自定义数据集<a href="#自定义数据集" class="hash-link" aria-label="Direct link to 自定义数据集" title="Direct link to 自定义数据集">​</a></h4><p>在这篇文章中，我们首先将植物数据集以视频的形式收集起来，然后使用Roboflow将视频转化为一系列图像。这样，我们得到了542张图片，与公共数据集相比，这是一个非常小的数据集。</p><div align="center"><img loading="lazy" width="400" src="https://files.seeedstudio.com/wiki/YOLOV5/62.jpg" class="img_ev3q"></div><h4 class="anchor anchorWithStickyNavbar_LWe7" id="公共数据集">公共数据集<a href="#公共数据集" class="hash-link" aria-label="Direct link to 公共数据集" title="Direct link to 公共数据集">​</a></h4><p>公共数据集例如<strong>Pascal VOC 2012</strong>和<strong>Microsoft COCO 2017</strong>数据集中分别包含约<strong>17112</strong>张和<strong>121408</strong>张图像。</p><h5 class="anchor anchorWithStickyNavbar_LWe7" id="pascal-voc-2012-数据集">Pascal VOC 2012 数据集<a href="#pascal-voc-2012-数据集" class="hash-link" aria-label="Direct link to Pascal VOC 2012 数据集" title="Direct link to Pascal VOC 2012 数据集">​</a></h5><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOV5/63.png" class="img_ev3q"></div><h5 class="anchor anchorWithStickyNavbar_LWe7" id="microsoft-coco-2017-数据集">Microsoft COCO 2017 数据集<a href="#microsoft-coco-2017-数据集" class="hash-link" aria-label="Direct link to Microsoft COCO 2017 数据集" title="Direct link to Microsoft COCO 2017 数据集">​</a></h5><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOV5/64.png" class="img_ev3q"></div><h3 class="anchor anchorWithStickyNavbar_LWe7" id="训练时间">训练时间<a href="#训练时间" class="hash-link" aria-label="Direct link to 训练时间" title="Direct link to 训练时间">​</a></h3><h4 class="anchor anchorWithStickyNavbar_LWe7" id="本地训练">本地训练<a href="#本地训练" class="hash-link" aria-label="Direct link to 本地训练" title="Direct link to 本地训练">​</a></h4><p>该训练是在一张搭载有6GB显存的NVIDIA GeForce GTX 1660 Super显卡上完成的。</p><h5 class="anchor anchorWithStickyNavbar_LWe7" id="自定义数据集的本地训练">自定义数据集的本地训练<a href="#自定义数据集的本地训练" class="hash-link" aria-label="Direct link to 自定义数据集的本地训练" title="Direct link to 自定义数据集的本地训练">​</a></h5><h6 class="anchor anchorWithStickyNavbar_LWe7" id="540-张图片数据集">540 张图片数据集<a href="#540-张图片数据集" class="hash-link" aria-label="Direct link to 540 张图片数据集" title="Direct link to 540 张图片数据集">​</a></h6><p>根据我们之前针对植物数据集进行的本地训练，我们得到了以下结果：</p><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOV5/65.png" class="img_ev3q"></div><p>在这次本地训练中，我们只花费了<strong>2.2小时</strong>训练了100个epochs，相对于使用公共数据集训练而言，训练速度较快。</p><h6 class="anchor anchorWithStickyNavbar_LWe7" id="240-张图片数据集">240 张图片数据集<a href="#240-张图片数据集" class="hash-link" aria-label="Direct link to 240 张图片数据集" title="Direct link to 240 张图片数据集">​</a></h6><p>我们将数据集缩减为240张图片，再次进行了训练，并获得了以下结果：</p><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOV5/83.png" class="img_ev3q"></div><p>在这次训练中，只花费了约<strong>1小时</strong>训练了100个epochs，相对于使用公共数据集训练而言，训练速度较快。</p><h5 class="anchor anchorWithStickyNavbar_LWe7" id="使用pascal-voc-2012数据集进行本地训练">使用Pascal VOC 2012数据集进行本地训练<a href="#使用pascal-voc-2012数据集进行本地训练" class="hash-link" aria-label="Direct link to 使用Pascal VOC 2012数据集进行本地训练" title="Direct link to 使用Pascal VOC 2012数据集进行本地训练">​</a></h5><p>在这个场景中，我们使用Pascal VOC 2012数据集进行训练，同时保持相同的训练参数。我们发现每个epoch需要大约 <strong>50分钟（0.846小时*60）</strong>，因此我们在训练1个epoch后停止了训练。</p><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOV5/66.png" class="img_ev3q"></div><p>如果我们计算100个epochs的训练时间，大约需要<strong>50 * 100分钟 = 5000分钟= 83小时</strong>，这比训练自定义数据集所需的时间要长得多。</p><h5 class="anchor anchorWithStickyNavbar_LWe7" id="使用microsoft-coco-2017数据集进行本地训练">使用Microsoft COCO 2017数据集进行本地训练<a href="#使用microsoft-coco-2017数据集进行本地训练" class="hash-link" aria-label="Direct link to 使用Microsoft COCO 2017数据集进行本地训练" title="Direct link to 使用Microsoft COCO 2017数据集进行本地训练">​</a></h5><p>在这个场景中，我们使用Microsoft COCO 2017数据集进行训练，并保持相同的训练参数。我们发现每个epoch大约需要<strong>7.5小时</strong>的时间，因此我们在完成一个epoch之前就停止了训练。</p><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOV5/68.png" class="img_ev3q"></div><p>如果我们计算100个epochs的训练时间，大约需要<strong>7.5小时*100 = 750小时</strong>，这比训练自定义数据集所需的时间要长得多。</p><h4 class="anchor anchorWithStickyNavbar_LWe7" id="google-colab-训练">Google Colab 训练<a href="#google-colab-训练" class="hash-link" aria-label="Direct link to Google Colab 训练" title="Direct link to Google Colab 训练">​</a></h4><p>这次训练是在一张拥有12GB显存的NVIDIA Tesla K80显卡上进行的。</p><h5 class="anchor anchorWithStickyNavbar_LWe7" id="自定义数据集-1">自定义数据集<a href="#自定义数据集-1" class="hash-link" aria-label="Direct link to 自定义数据集" title="Direct link to 自定义数据集">​</a></h5><h6 class="anchor anchorWithStickyNavbar_LWe7" id="540-张图像数据集">540 张图像数据集<a href="#540-张图像数据集" class="hash-link" aria-label="Direct link to 540 张图像数据集" title="Direct link to 540 张图像数据集">​</a></h6><p>根据我们之前在Google Colab平台上使用540张图像进行的植物训练，我们得到了以下结果：</p><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOV5/37.png" class="img_ev3q"></div><p>在这次使用Google Colab平台进行的540张图像的植物训练中，只花费了约<strong>1.3小时</strong>训练了100个epochs，相对于使用公共数据集训练而言，训练速度较快。</p><h6 class="anchor anchorWithStickyNavbar_LWe7" id="240-张图像数据集">240 张图像数据集<a href="#240-张图像数据集" class="hash-link" aria-label="Direct link to 240 张图像数据集" title="Direct link to 240 张图像数据集">​</a></h6><p>我们将数据集缩减为240张图片，再次进行了训练，并获得了以下结果：</p><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOV5/79.png" class="img_ev3q"></div><p>在这次使用Google Colab平台进行的240张图像的植物训练中，只花费了约<strong>42分钟</strong>训练了100个epochs，相对于使用公共数据集训练而言，训练速度较快。</p><h5 class="anchor anchorWithStickyNavbar_LWe7" id="使用google-colab平台进行pascal-voc-2012数据集训练">使用Google Colab平台进行Pascal VOC 2012数据集训练<a href="#使用google-colab平台进行pascal-voc-2012数据集训练" class="hash-link" aria-label="Direct link to 使用Google Colab平台进行Pascal VOC 2012数据集训练" title="Direct link to 使用Google Colab平台进行Pascal VOC 2012数据集训练">​</a></h5><p>在这个场景中，我们使用Pascal VOC 2012数据集进行训练，并保持相同的训练参数。我们发现每个epoch大约需要<strong>9 分钟 (0.148 小时 * 60)</strong> 的时间，因此我们在完成1个epoch后停止了训练。</p><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOV5/67.png" class="img_ev3q"></div><p>如果我们计算100个epochs的训练时间，大约需要<strong>9 * 100分钟 = 900分钟 = 15小时</strong>，这比训练自定义数据集所需的时间要长得多。但相比在本地环境或使用GPU较弱的云计算平台上训练，使用Google Colab进行训练可大大缩短训练时间。</p><h5 class="anchor anchorWithStickyNavbar_LWe7" id="使用google-colab平台进行microsoft-coco-2017数据集训练">使用Google Colab平台进行Microsoft COCO 2017数据集训练<a href="#使用google-colab平台进行microsoft-coco-2017数据集训练" class="hash-link" aria-label="Direct link to 使用Google Colab平台进行Microsoft COCO 2017数据集训练" title="Direct link to 使用Google Colab平台进行Microsoft COCO 2017数据集训练">​</a></h5><p>在这个场景中，我们使用Microsoft COCO 2017数据集进行训练，并保持相同的训练参数。我们发现每个epoch预计需要大约<strong>1.25个小时</strong>的时间，因此我们在完成一个epoch之前就停止了训练。</p><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOV5/69.png" class="img_ev3q"></div><p>如果我们计算100个epochs的训练时间，大约需要<strong>1.25小时*100 = 125小时</strong>，这比训练自定义数据集所需的时间要长得多。但相比在本地环境或使用GPU配置较弱的云计算平台上训练，使用Google Colab进行训练可大幅缩短训练时间。</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="训练样本数量和训练时间总结">训练样本数量和训练时间总结<a href="#训练样本数量和训练时间总结" class="hash-link" aria-label="Direct link to 训练样本数量和训练时间总结" title="Direct link to 训练样本数量和训练时间总结">​</a></h3><table><thead><tr><th>数据集</th><th>训练样本数量</th><th>本地PC训练时长 (GTX 1660 Super)</th><th>Google Colab的训练时间 (NVIDIA Tesla K80)</th></tr></thead><tbody><tr><td>Custom</td><td>542</td><td>2.2 hours</td><td>1.3 hours</td></tr><tr><td></td><td>240</td><td>1 hour</td><td>42 minutes</td></tr><tr><td>Pascal VOC 2012</td><td>17112</td><td>83 hours</td><td>15 hours</td></tr><tr><td>Microsoft COCO 2017</td><td>121408</td><td>750 hours</td><td>125 hours</td></tr></tbody></table><h2 class="anchor anchorWithStickyNavbar_LWe7" id="预训练模型的比较">预训练模型的比较<a href="#预训练模型的比较" class="hash-link" aria-label="Direct link to 预训练模型的比较" title="Direct link to 预训练模型的比较">​</a></h2><p>可以从以下表格中了解更多关于预训练模型的信息。在我们的场景中，我们在<strong>Google Colab平台</strong>上训练了模型，并在<strong>Jetson Nano</strong>和<strong>Jetson Xavier NX</strong>上进行了推理，并使用<strong>YOLOv5n6</strong>作为预训练模型。</p><table><thead><tr><th>模型</th><th>size (pixels)</th><th>mAPval 0.5:0.95</th><th>mAPval 0.5</th><th>Speed CPU b1 (ms)</th><th>Speed V100 b1 (ms)</th><th>Speed V100 b32 (ms)</th><th>Speed Jetson  Nano FP16 (ms)</th><th>Speed Jetson Xavier NX FP16 (ms)</th><th>params (M)</th><th>FLOPs @640 (B)</th></tr></thead><tbody><tr><td>YOLOv5n</td><td>640</td><td>28.0</td><td>45.7</td><td>45</td><td>6.3</td><td>0.6</td><td></td><td></td><td>1.9</td><td>4.5</td></tr><tr><td>YOLOv5s</td><td>640</td><td>37.4</td><td>56.8</td><td>98</td><td>6.4</td><td>0.9</td><td></td><td></td><td>7.2</td><td>16.5</td></tr><tr><td>YOLOv5m</td><td>640</td><td>45.4</td><td>64.1</td><td>224</td><td>8.2</td><td>1.7</td><td></td><td></td><td>21.2</td><td>49.0</td></tr><tr><td>YOLOv5l</td><td>640</td><td>49.0</td><td>67.3</td><td>430</td><td>10.1</td><td>2.7</td><td></td><td></td><td>46.5</td><td>109.1</td></tr><tr><td>YOLOv5x</td><td>640</td><td>50.7</td><td>68.9</td><td>766</td><td>12.1</td><td>4.8</td><td></td><td></td><td>86.7</td><td>205.7</td></tr><tr><td><strong>YOLOv5n6</strong></td><td><strong>640</strong></td><td><strong>71.7</strong></td><td><strong>95.5</strong></td><td><strong>153</strong></td><td><strong>8.1</strong></td><td><strong>2.1</strong></td><td><strong>47</strong></td><td><strong>20</strong></td><td><strong>3.1</strong></td><td><strong>4.6</strong></td></tr><tr><td>YOLOv5s6</td><td>1280</td><td>44.8</td><td>63.7</td><td>385</td><td>8.2</td><td>3.6</td><td></td><td></td><td>12.6</td><td>16.8</td></tr><tr><td>YOLOv5m6</td><td>1280</td><td>51.3</td><td>69.3</td><td>887</td><td>11.1</td><td>6.8</td><td></td><td></td><td>35.7</td><td>50.0</td></tr><tr><td>YOLOv5l6</td><td>1280</td><td>53.7</td><td>71.3</td><td>1784</td><td>15.8</td><td>10.5</td><td></td><td></td><td>76.8</td><td>111.4</td></tr><tr><td>YOLOv5x6 + <!-- -->[TTA]</td><td>1280 1536</td><td>55.0 55.8</td><td>72.7 72.7</td><td>3136 -</td><td>26.2 -</td><td>19.4 -</td><td></td><td></td><td>140.7 -</td><td>209.8 -</td></tr></tbody></table><blockquote><p>参考: <a href="https://github.com/ultralytics/yolov5" target="_blank" rel="noopener noreferrer">YOLOv5 GitHub</a></p></blockquote><h2 class="anchor anchorWithStickyNavbar_LWe7" id="额外应用">额外应用<a href="#额外应用" class="hash-link" aria-label="Direct link to 额外应用" title="Direct link to 额外应用">​</a></h2><p>由于上述所解释的所有步骤对于任何类型的目标检测应用程序都是通用的，因此您只需要针对您自己的目标检测应用程序更改数据集即可！</p><h3 class="anchor anchorWithStickyNavbar_LWe7" id="路标识别">路标识别<a href="#路标识别" class="hash-link" aria-label="Direct link to 路标识别" title="Direct link to 路标识别">​</a></h3><p>这里我们使用了来自Roboflow的<a href="https://universe.roboflow.com/usmanchaudhry622-gmail-com/traffic-and-road-signs/1" target="_blank" rel="noopener noreferrer">路标数据集</a> 并在NVIDIA Jetson上进行了推断！</p><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/YOLOv5-2/thumb-2.png" class="img_ev3q"></div><h3 class="anchor anchorWithStickyNavbar_LWe7" id="野火烟雾检测">野火烟雾检测<a href="#野火烟雾检测" class="hash-link" aria-label="Direct link to 野火烟雾检测" title="Direct link to 野火烟雾检测">​</a></h3><p>我们在这里使用了来自Roboflow的 <a href="https://public.roboflow.com/object-detection/wildfire-smoke" target="_blank" rel="noopener noreferrer">野火烟雾数据集</a> ，并在NVIDIA Jetson上进行了推断！</p><div align="center"><img loading="lazy" width="1000" src="https://files.seeedstudio.com/wiki/Roboflow/20.jpg" class="img_ev3q"></div><h2 class="anchor anchorWithStickyNavbar_LWe7" id="来源">来源：<a href="#来源" class="hash-link" aria-label="Direct link to 来源：" title="Direct link to 来源：">​</a></h2><ul><li><p><strong>[网页]</strong> <a href="https://docs.ultralytics.com" target="_blank" rel="noopener noreferrer">YOLOv5 Documentation</a></p></li><li><p><strong>[网页]</strong> <a href="https://ultralytics.com/hub" target="_blank" rel="noopener noreferrer">Ultralytics HUB</a></p></li><li><p><strong>[网页]</strong> <a href="https://docs.roboflow.com" target="_blank" rel="noopener noreferrer">Roboflow Documentation</a></p></li></ul><h2 class="anchor anchorWithStickyNavbar_LWe7" id="技术支持与项目讨论">技术支持与项目讨论<a href="#技术支持与项目讨论" class="hash-link" aria-label="Direct link to 技术支持与项目讨论" title="Direct link to 技术支持与项目讨论">​</a></h2><p>非常感谢您选择我们的产品！我们提供不同的支持方式，以确保您在使用我们的产品时拥有尽可能流畅的体验。我们提供多种沟通渠道，以适应不同的偏好和需求。</p><div class="button_tech_support_container"><a href="https://forum.seeedstudio.com/" target="_blank" rel="noopener noreferrer" class="button_forum"></a><a href="https://www.seeedstudio.com/contacts" target="_blank" rel="noopener noreferrer" class="button_email"></a></div><div class="button_tech_support_container"><a href="https://discord.gg/eWkprNDMU7" target="_blank" rel="noopener noreferrer" class="button_discord"></a><a href="https://github.com/Seeed-Studio/wiki-documents/discussions/69" target="_blank" rel="noopener noreferrer" class="button_discussion"></a></div></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-tags-row row margin-bottom--sm"><div class="col"><b>Tags:</b><ul class="tags_jXut padding--none margin-left--sm"><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/tags/data-label/">Data Label</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/tags/ai-model-train/">AI model train</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/tags/ai-model-deploy/">AI model deploy</a></li><li class="tag_QGVx"><a class="tag_zVej tagRegular_sFm0" href="/tags/roboflow/">Roboflow</a></li></ul></div></div><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/Seeed-Studio/wiki-documents/blob/docusaurus-version/docs/zh-CN/Edge/NVIDIA_Jetson/Application/Computer_Vision/YOLOv5-Object-Detection-Jetson.md" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_vwxv"><span class="theme-last-updated">Last updated<!-- --> on <b><time datetime="2023-01-04T00:00:00.000Z">Jan 4, 2023</time></b> by <b>w0x7ce</b></span></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/cn/Traffic-Management-DeepStream-SDK/"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">基于 DeepStream SDK的智能交通管理系统</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/cn/YOLOv8-DeepStream-TRT-Jetson/"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">在NVIDIA Jetson上使用TensorRT和DeepStream SDK部署YOLOv8</div></a></nav></div><div>Loading Comments...</div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#介绍" class="table-of-contents__link toc-highlight">介绍</a></li><li><a href="#什么是-yolov5" class="table-of-contents__link toc-highlight">什么是 YOLOv5?</a></li><li><a href="#什么是少样本目标检测" class="table-of-contents__link toc-highlight">什么是少样本目标检测？</a></li><li><a href="#硬件支持" class="table-of-contents__link toc-highlight">硬件支持</a></li><li><a href="#先决条件" class="table-of-contents__link toc-highlight">先决条件</a></li><li><a href="#入门" class="table-of-contents__link toc-highlight">入门</a></li><li><a href="#收集数据集或使用公开可用的数据集" class="table-of-contents__link toc-highlight">收集数据集或使用公开可用的数据集</a><ul><li><a href="#手动收集数据集" class="table-of-contents__link toc-highlight">手动收集数据集</a></li><li><a href="#使用公开可用的数据集" class="table-of-contents__link toc-highlight">使用公开可用的数据集</a></li></ul></li><li><a href="#使用roboflow对数据集进行注释w" class="table-of-contents__link toc-highlight">使用Roboflow对数据集进行注释w</a></li><li><a href="#在本地pc或云端训练" class="table-of-contents__link toc-highlight">在本地PC或云端训练</a><ul><li><a href="#使用ultralytics-hub和google-colab" class="table-of-contents__link toc-highlight">使用Ultralytics HUB和Google Colab</a></li><li><a href="#使用-google-colab-和-roboflow-api" class="table-of-contents__link toc-highlight">使用 Google Colab 和 Roboflow api</a></li><li><a href="#使用本地pc端" class="table-of-contents__link toc-highlight">使用本地PC端</a></li></ul></li><li><a href="#在jetson设备上进行推理" class="table-of-contents__link toc-highlight">在Jetson设备上进行推理</a><ul><li><a href="#使用tensorrt" class="table-of-contents__link toc-highlight">使用TensorRT</a><ul><li><a href="#jetson-nano" class="table-of-contents__link toc-highlight">Jetson Nano</a></li><li><a href="#jetson-xavier-nx" class="table-of-contents__link toc-highlight">Jetson Xavier NX</a></li></ul></li><li><a href="#使用-tensorrt-和-deepstream-sdk" class="table-of-contents__link toc-highlight">使用 TensorRT 和 DeepStream SDK</a><ul><li><a href="#int8-校准" class="table-of-contents__link toc-highlight">INT8 校准</a></li><li><a href="#基准测试结果" class="table-of-contents__link toc-highlight">基准测试结果：</a></li></ul></li></ul></li><li><a href="#使用公共数据集与自定义数据集的比较" class="table-of-contents__link toc-highlight">使用公共数据集与自定义数据集的比较：</a><ul><li><a href="#训练样本数量" class="table-of-contents__link toc-highlight">训练样本数量</a><ul><li><a href="#自定义数据集" class="table-of-contents__link toc-highlight">自定义数据集</a></li><li><a href="#公共数据集" class="table-of-contents__link toc-highlight">公共数据集</a><ul><li><a href="#pascal-voc-2012-数据集" class="table-of-contents__link toc-highlight">Pascal VOC 2012 数据集</a></li><li><a href="#microsoft-coco-2017-数据集" class="table-of-contents__link toc-highlight">Microsoft COCO 2017 数据集</a></li></ul></li></ul></li><li><a href="#训练时间" class="table-of-contents__link toc-highlight">训练时间</a><ul><li><a href="#本地训练" class="table-of-contents__link toc-highlight">本地训练</a><ul><li><a href="#自定义数据集的本地训练" class="table-of-contents__link toc-highlight">自定义数据集的本地训练</a></li><li><a href="#使用pascal-voc-2012数据集进行本地训练" class="table-of-contents__link toc-highlight">使用Pascal VOC 2012数据集进行本地训练</a></li><li><a href="#使用microsoft-coco-2017数据集进行本地训练" class="table-of-contents__link toc-highlight">使用Microsoft COCO 2017数据集进行本地训练</a></li></ul></li><li><a href="#google-colab-训练" class="table-of-contents__link toc-highlight">Google Colab 训练</a><ul><li><a href="#自定义数据集-1" class="table-of-contents__link toc-highlight">自定义数据集</a></li><li><a href="#使用google-colab平台进行pascal-voc-2012数据集训练" class="table-of-contents__link toc-highlight">使用Google Colab平台进行Pascal VOC 2012数据集训练</a></li><li><a href="#使用google-colab平台进行microsoft-coco-2017数据集训练" class="table-of-contents__link toc-highlight">使用Google Colab平台进行Microsoft COCO 2017数据集训练</a></li></ul></li></ul></li><li><a href="#训练样本数量和训练时间总结" class="table-of-contents__link toc-highlight">训练样本数量和训练时间总结</a></li></ul></li><li><a href="#预训练模型的比较" class="table-of-contents__link toc-highlight">预训练模型的比较</a></li><li><a href="#额外应用" class="table-of-contents__link toc-highlight">额外应用</a><ul><li><a href="#路标识别" class="table-of-contents__link toc-highlight">路标识别</a></li><li><a href="#野火烟雾检测" class="table-of-contents__link toc-highlight">野火烟雾检测</a></li></ul></li><li><a href="#来源" class="table-of-contents__link toc-highlight">来源：</a></li><li><a href="#技术支持与项目讨论" class="table-of-contents__link toc-highlight">技术支持与项目讨论</a></li></ul></div></div></div></div></main></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Navigation</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/Getting_Started/">Getting Started</a></li><li class="footer__item"><a class="footer__link-item" href="/Sensor_Network/">Sensor and Sensing</a></li><li class="footer__item"><a class="footer__link-item" href="/Network/">Network</a></li><li class="footer__item"><a class="footer__link-item" href="/Edge_Computing/">Edge Computing</a></li><li class="footer__item"><a class="footer__link-item" href="/Cloud/">Cloud</a></li><li class="footer__item"><a class="footer__link-item" href="/Solutions/">Solutions</a></li></ul></div><div class="col footer__col"><div class="footer__title">Ecosystem</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://discord.com/invite/QqMgVwHT3X" target="_blank" rel="noopener noreferrer" class="footer__link-item">Discord</a></li><li class="footer__item"><a href="https://project.seeedstudio.com/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Project Hub</a></li><li class="footer__item"><a href="https://www.seeedstudio.com/ecosystem/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Partners</a></li><li class="footer__item"><a href="https://www.seeedstudio.com/distributors.html" target="_blank" rel="noopener noreferrer" class="footer__link-item">Distributors</a></li></ul></div><div class="col footer__col"><div class="footer__title">Quick Guide</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://www.seeedstudio.com/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Bazzar</a></li><li class="footer__item"><a href="https://www.seeedstudio.com/get_help/HowToGetHelp" target="_blank" rel="noopener noreferrer" class="footer__link-item">How to get help</a></li><li class="footer__item"><a href="https://support.seeedstudio.com/knowledgebase" target="_blank" rel="noopener noreferrer" class="footer__link-item">FAQs</a></li><li class="footer__item"><a href="https://forum.seeedstudio.com/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Forum</a></li><li class="footer__item"><a href="https://www.seeedstudio.com/get_help/TechnicalSupport" target="_blank" rel="noopener noreferrer" class="footer__link-item">Technical Support</a></li></ul></div><div class="col footer__col"><div class="footer__title">Company</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://www.seeedstudio.com/about-us/" target="_blank" rel="noopener noreferrer" class="footer__link-item">About Seeed</a></li><li class="footer__item"><a href="https://www.seeedstudio.com/join-us/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Join us</a></li><li class="footer__item"><a href="https://www.seeedstudio.com/contacts" target="_blank" rel="noopener noreferrer" class="footer__link-item">Contact Us</a></li><li class="footer__item"><a href="https://www.seeedstudio.com/blog/2020/04/22/seeed-in-the-news/" target="_blank" rel="noopener noreferrer" class="footer__link-item">Press</a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright © 2024 Seeed Studio, Inc. Built with Docusaurus.</div></div></div></footer></div>
<script src="/assets/js/runtime~main.b0a22fb9.js"></script>
<script src="/assets/js/main.df7d386f.js"></script>
</body>
</html>